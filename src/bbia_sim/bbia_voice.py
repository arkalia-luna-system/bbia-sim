"""Module bbia_voice.py.

Synth√®se et reconnaissance vocale pour BBIA.
Compatible macOS, simple, portable, test√©.

Voix : s√©lection automatique de la voix la plus proche de
Reachy Mini Wireless (f√©minine, fran√ßaise si possible).
"""

import contextlib
import io
import logging
import os
import queue
import sys
import tempfile
import threading
import time
import unicodedata
import wave
from pathlib import Path
from typing import Any

import numpy as np
import pyttsx3
import speech_recognition as sr

# Import conditionnel soundfile (optionnel)
try:
    import soundfile as sf

    SOUNDFILE_AVAILABLE = True
except ImportError:
    SOUNDFILE_AVAILABLE = False
    sf = None  # type: ignore[assignment]

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
try:
    # S√©lecteurs IA optionnels (TTS local type KittenTTS)
    from .ai_backends import get_tts_backend
except ImportError:  # pragma: no cover - non critique si absent
    get_tts_backend = None  # type: ignore[assignment]

# Import conditionnel voice_whisper (une seule fois)
try:
    from .voice_whisper import WHISPER_AVAILABLE, WhisperSTT
except ImportError:
    WHISPER_AVAILABLE = False
    WhisperSTT = None  # type: ignore[assignment,misc]

# Liste des voix f√©minines douces/enfantines √† privil√©gier sur macOS
# (ordre de pr√©f√©rence)
VOIX_FEMMES_MAC = [
    "Amelie",  # enfantine, douce
    "Audrey",  # douce
    "Virginie",  # douce
    "Julie",  # classique
]

# ‚ö° OPTIMISATION PERFORMANCE: Cache global pour √©viter r√©initialisation r√©p√©t√©e
_pyttsx3_engine_cache: Any | None = None
_bbia_voice_id_cache: str | None = None
_pyttsx3_lock = threading.Lock()


def _get_pyttsx3_engine() -> Any:
    """Retourne le moteur pyttsx3 en cache ou le cr√©e si absent.

    ‚ö° OPTIMISATION PERFORMANCE: Cache pour √©viter r√©initialisation (0.8s par appel).

    Returns:
        Moteur pyttsx3 r√©utilisable

    """
    global _pyttsx3_engine_cache
    if _pyttsx3_engine_cache is None:
        with _pyttsx3_lock:
            # Double check apr√®s lock (thread-safe)
            if _pyttsx3_engine_cache is None:
                # V√©rifier si audio est d√©sactiv√© (CI, tests)
                if os.environ.get("BBIA_DISABLE_AUDIO", "0") == "1":
                    logging.debug("‚ö†Ô∏è Audio d√©sactiv√©, pyttsx3 non initialis√©")
                    return None
                try:
                    _pyttsx3_engine_cache = pyttsx3.init()
                    logging.debug("‚úÖ Moteur pyttsx3 initialis√© (cache cr√©√©)")
                except (RuntimeError, OSError) as e:
                    # eSpeak non install√© ou autre erreur syst√®me
                    # Log en debug en CI (warning attendu sans eSpeak)
                    if os.environ.get("CI", "false").lower() == "true":
                        logging.debug(f"pyttsx3 non disponible: {e}")
                    else:
                        logging.warning(f"‚ö†Ô∏è pyttsx3 non disponible: {e}")
                    _pyttsx3_engine_cache = None
                    return None
    return _pyttsx3_engine_cache


def _get_cached_voice_id() -> str:
    """Retourne l'ID de voix BBIA en cache.

    ‚ö° OPTIMISATION PERFORMANCE: Cache pour √©viter recherche r√©p√©t√©e des voix.

    Returns:
        ID de voix BBIA (Amelie)

    """
    global _bbia_voice_id_cache
    if _bbia_voice_id_cache is None:
        engine = _get_pyttsx3_engine()
        if engine is None:
            # Audio d√©sactiv√© ou eSpeak non disponible
            # Log en debug en CI (warning attendu sans eSpeak)
            if os.environ.get("CI", "false").lower() == "true":
                logging.debug("pyttsx3 non disponible, utilisation voix par d√©faut")
            else:
                logging.warning(
                    "‚ö†Ô∏è pyttsx3 non disponible, utilisation voix par d√©faut"
                )
            _bbia_voice_id_cache = (
                "com.apple.speech.voice.Amelie.fr-FR"  # Fallback macOS
            )
        else:
            _bbia_voice_id_cache = get_bbia_voice(engine)
            logging.debug("‚úÖ Voice ID mis en cache: %s", _bbia_voice_id_cache)
    return _bbia_voice_id_cache


# Constantes pour la s√©lection de voix
_MALE_VOICE_INDICATORS = frozenset(
    ["thomas", "jacques", "reed", "rocko", "eddy", "grandpa", "daniel"]
)
_FEMALE_FR_VOICES = frozenset(
    ["audrey", "virginie", "julie", "flo", "sandy", "shelley"]
)
_VOICE_PRIORITY_KEYS = [
    "aurelie_enhanced_fr",
    "amelie_enhanced_fr",
    "aurelie_fr_FR",
    "aurelie_fr_CA",
    "amelie_fr_FR",
    "amelie_fr_CA",
    "aurelie_any",
    "amelie_any",
    "femme_fr",
]


def _normalize_voice_name(s: str) -> str:
    """Normalise un nom de voix pour comparaison."""
    return (
        unicodedata.normalize("NFKD", s)
        .encode("ASCII", "ignore")
        .decode("ASCII")
        .lower()
    )


def _categorize_voice(v: Any) -> tuple[str | None, str]:
    """Cat√©gorise une voix selon la priorit√©.

    Returns:
        Tuple (cat√©gorie, voice_id) ou (None, "") si non cat√©goris√©e

    """
    v_id = str(v.id)
    v_id_lower = v_id.lower()
    v_name_lower = _normalize_voice_name(v.name)

    is_aurelie = "aurelie" in v_name_lower or "aur√©lie" in v_name_lower
    is_amelie = "amelie" in v_name_lower
    has_enhanced = "enhanced" in v_id_lower
    is_fr = "fr" in v_id_lower
    is_fr_FR = "fr_FR" in v_id or "fr-FR" in v_id
    is_fr_CA = "fr_CA" in v_id or "fr-CA" in v_id
    is_male = any(ind in v_name_lower for ind in _MALE_VOICE_INDICATORS)

    if is_aurelie and has_enhanced and is_fr:
        return "aurelie_enhanced_fr", v_id
    if is_amelie and has_enhanced and is_fr:
        return "amelie_enhanced_fr", v_id
    if is_aurelie and is_fr_FR:
        return "aurelie_fr_FR", v_id
    if is_aurelie and is_fr_CA:
        return "aurelie_fr_CA", v_id
    if is_amelie and is_fr_FR:
        return "amelie_fr_FR", v_id
    if is_amelie and is_fr_CA:
        return "amelie_fr_CA", v_id
    if is_aurelie:
        return "aurelie_any", v_id
    if is_amelie:
        return "amelie_any", v_id
    if not is_male and is_fr:
        if any(nom in v_name_lower for nom in _FEMALE_FR_VOICES):
            return "femme_fr", v_id

    return None, ""


def get_bbia_voice(engine: Any) -> str:
    """Force l'utilisation d'une voix f√©minine fran√ßaise de qualit√© sur macOS.

    Priorit√© de s√©lection :
    1. Aurelie Enhanced (fr-FR) - Meilleure qualit√©
    2. Amelie Enhanced (si disponible)
    3. Aurelie standard (fr-FR, fr-CA)
    4. Amelie (fr_FR, fr_CA, puis toute variante)
    5. Autres voix f√©minines fran√ßaises (Audrey, Virginie, Julie)

    Si aucune voix f√©minine fran√ßaise n'est trouv√©e, l√®ve une erreur explicite.
    """
    if engine is None:
        return "com.apple.speech.voice.Amelie.fr-FR"

    voices = engine.getProperty("voices")
    candidates: dict[str, str | None] = dict.fromkeys(_VOICE_PRIORITY_KEYS, None)

    # Une seule passe sur toutes les voix
    for v in voices:
        category, voice_id = _categorize_voice(v)
        if category and candidates[category] is None:
            candidates[category] = voice_id

    # Retourner le premier candidat selon priorit√©
    for key in _VOICE_PRIORITY_KEYS:
        if candidates[key] is not None:
            return candidates[key]  # type: ignore[return-value]

    msg = (
        "Aucune voix fran√ßaise f√©minine n'est install√©e sur ce Mac. "
        "Va dans Pr√©f√©rences Syst√®me > Accessibilit√© > Parole > "
        "Voix du syst√®me et installe une voix fran√ßaise f√©minine "
        "(ex: Aur√©lie Enhanced, Am√©lie)."
    )
    raise RuntimeError(msg)


def _play_wav_via_sdk(
    wav_path: str,
    robot_api: Any | None,
) -> bool:
    """Tente de jouer un WAV via le SDK.

    Returns:
        True si succ√®s, False sinon

    """
    if not robot_api or not hasattr(robot_api, "media") or not robot_api.media:
        return False

    try:
        media = robot_api.media
        with open(wav_path, "rb") as f:
            audio_bytes = f.read()

        if hasattr(media, "play_audio"):
            try:
                media.play_audio(audio_bytes, volume=1.0)
            except TypeError:
                media.play_audio(audio_bytes)
            return True

        speaker = getattr(media, "speaker", None)
        if speaker is not None:
            if hasattr(speaker, "play_file"):
                speaker.play_file(wav_path)
                return True
            if hasattr(speaker, "play"):
                speaker.play(audio_bytes)
                return True
    except (AttributeError, RuntimeError, OSError, TypeError) as e:
        logger.debug("Erreur lecture audio via SDK speaker: %s", e)

    return False


def _play_wav_via_sounddevice(wav_path: str) -> bool:
    """Tente de jouer un WAV via sounddevice.

    Returns:
        True si succ√®s, False sinon

    """
    try:
        import sounddevice as _sd

        with wave.open(wav_path, "rb") as wf:
            sr = wf.getframerate()
            frames = wf.readframes(wf.getnframes())
            data = np.frombuffer(frames, dtype=np.int16)
            _sd.play(data, sr)
            _sd.wait()
        return True
    except (OSError, RuntimeError, ImportError) as e:
        logger.debug("Erreur lecture audio sounddevice: %s", e)
    except (TypeError, IndexError, KeyError) as e:
        logger.debug("Erreur lecture audio sounddevice (type/index/key): %s", e)
    except Exception as e:  # noqa: BLE001
        logger.debug("Erreur inattendue lecture audio sounddevice: %s", e)

    return False


def _synthesize_via_tts_backend(
    texte: str,
    robot_api: Any | None,
) -> bool:
    """Synth√©tise via backend TTS externe si configur√©.

    Returns:
        True si succ√®s, False sinon

    """
    tts_backend_name = os.environ.get("BBIA_TTS_BACKEND")
    if not tts_backend_name or get_tts_backend is None:
        return False

    try:
        backend = get_tts_backend()
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            wav_path = tmp.name

        if not backend.synthesize_to_wav(texte, wav_path):
            return False

        # Essayer SDK puis sounddevice
        if _play_wav_via_sdk(wav_path, robot_api):
            return True
        if _play_wav_via_sounddevice(wav_path):
            return True

    except (ImportError, RuntimeError, OSError) as e:
        logger.debug("Erreur synth√®se vocale avanc√©e, fallback pyttsx3: %s", e)
    except Exception as e:  # noqa: BLE001
        import traceback

        tb_str = "".join(traceback.format_exception(type(e), e, e.__traceback__))
        if "_get_pyttsx3_engine" in tb_str:
            logger.debug("Erreur _get_pyttsx3_engine, pas de fallback pyttsx3: %s", e)
            raise
        logger.debug("Erreur inattendue synth√®se vocale avanc√©e: %s", e)

    return False


def _generate_silence_wav() -> bytes:
    """G√©n√®re un court WAV de silence (100ms).

    Returns:
        Bytes du fichier WAV ou bytes vide si erreur

    """
    import struct as _struct

    try:
        sr = 16000
        num_samples = int(0.1 * sr)
        silence = b"".join(_struct.pack("<h", 0) for _ in range(num_samples))

        wav_buf = io.BytesIO()
        with wave.open(wav_buf, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(sr)
            wf.writeframes(silence)
        return wav_buf.getvalue()
    except (ValueError, RuntimeError, TypeError):
        return b""


def _play_via_sdk_media(robot_api: Any | None) -> bool:
    """Tente de jouer via robot.media.* (SDK).

    Returns:
        True si succ√®s, False sinon

    """
    if not robot_api or not hasattr(robot_api, "media") or not robot_api.media:
        return False

    media = robot_api.media
    try:
        sdk_audio_bytes = _generate_silence_wav()
        if not sdk_audio_bytes:
            return False

        # Priorit√© 1: media.play_audio
        if hasattr(media, "play_audio"):
            try:
                try:
                    media.play_audio(sdk_audio_bytes, volume=1.0)
                except TypeError:
                    media.play_audio(sdk_audio_bytes)
                return True
            except (TypeError, IndexError, KeyError, OSError) as e:
                logging.debug("media.play_audio a √©chou√©: %s", e)
            except Exception as e:  # noqa: BLE001
                logging.debug("media.play_audio a √©chou√©: %s", e)

        # Priorit√© 2: media.speaker
        speaker = getattr(media, "speaker", None)
        if speaker is not None:
            return _play_via_speaker(speaker, sdk_audio_bytes)

    except (TypeError, ValueError, AttributeError) as e:
        logging.debug("Erreur synth√®se SDK: %s", e)
    except Exception as e:  # noqa: BLE001
        logging.debug("Erreur synth√®se SDK (fallback pyttsx3): %s", e)

    return False


def _play_via_speaker(speaker: Any, audio_bytes: bytes) -> bool:
    """Tente de jouer via speaker."""
    try:
        if hasattr(speaker, "play"):
            speaker.play(audio_bytes)
            return True
    except (TypeError, IndexError, KeyError, OSError) as e:
        logging.debug("speaker.play a √©chou√©: %s", e)
    except Exception as e:  # noqa: BLE001
        logging.debug("speaker.play a √©chou√©: %s", e)

    # Essayer play_file
    tmp_path = None
    try:
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            tmp_path = tmp.name
            with open(tmp_path, "wb") as f:
                f.write(audio_bytes)
        if hasattr(speaker, "play_file"):
            speaker.play_file(tmp_path)
            return True
    finally:
        if tmp_path:
            try:
                Path(tmp_path).unlink(missing_ok=True)
            except (OSError, PermissionError) as e:
                logger.debug("Erreur nettoyage fichier temporaire: %s", e)

    return False


def _play_via_pyttsx3(texte: str) -> None:
    """Joue le texte via pyttsx3 (fallback)."""
    logging.info("Synth√®se vocale : %s", texte)

    engine = _get_pyttsx3_engine()
    if engine is None:
        is_ci = os.environ.get("CI", "false").lower() == "true"
        if is_ci:
            logging.debug("pyttsx3 non disponible, synth√®se vocale ignor√©e")
        else:
            logging.warning("‚ö†Ô∏è pyttsx3 non disponible, synth√®se vocale ignor√©e")
        return

    voice_id = _get_cached_voice_id()
    if engine is None:
        logging.warning("‚ö†Ô∏è pyttsx3 non disponible apr√®s r√©cup√©ration voice_id")
        return

    engine.setProperty("voice", voice_id)
    engine.setProperty("rate", 170)
    engine.setProperty("volume", 1.0)
    engine.say(texte)
    engine.runAndWait()


def dire_texte(texte: str, robot_api: Any | None = None) -> None:
    """Lit un texte √† voix haute (TTS) avec la voix la plus fid√®le √† Reachy Mini Wireless.

    Utilise robot.media.speaker si disponible (haut-parleur 5W optimis√© SDK),
    sinon utilise pyttsx3 pour compatibilit√©.

    Args:
        texte: Texte √† prononcer
        robot_api: Interface RobotAPI (optionnel) pour acc√®s robot.media.speaker

    """
    # V√©rifier flag d'environnement
    if os.environ.get("BBIA_DISABLE_AUDIO", "0") == "1":
        logging.debug("Audio d√©sactiv√© (BBIA_DISABLE_AUDIO=1): '%s' ignor√©", texte)
        return

    # Essayer backend TTS externe
    if _synthesize_via_tts_backend(texte, robot_api):
        return

    # Essayer SDK media
    if _play_via_sdk_media(robot_api):
        return

    # Fallback pyttsx3
    try:
        _play_via_pyttsx3(texte)
    except (RuntimeError, AttributeError, OSError) as e:
        logging.error("Erreur de synth√®se vocale (runtime/attr/os): %s", e)
    except Exception as e:  # noqa: BLE001
        logging.error("Erreur de synth√®se vocale: %s", e)
        raise


def _convert_audio_to_wav_bytes(
    audio_data: bytes | np.ndarray | Any,
    frequence: int,
) -> io.BytesIO:
    """Convertit les donn√©es audio en format WAV en m√©moire."""
    audio_io = io.BytesIO()
    with wave.open(audio_io, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(frequence)
        if isinstance(audio_data, bytes):
            wf.writeframes(audio_data)
        elif isinstance(audio_data, np.ndarray):
            wf.writeframes((audio_data.astype(np.int16)).tobytes())
        else:
            wf.writeframes(bytes(audio_data))
    audio_io.seek(0)
    return audio_io


def _recognize_from_sdk_microphone(
    duree: int,
    frequence: int,
    robot_api: Any,
) -> str | None:
    """Reconnaissance vocale via SDK microphone."""
    if not hasattr(robot_api.media, "record_audio"):
        return None

    logging.info(
        "üé§ Enregistrement via SDK (4 microphones) (%ds) pour reconnaissance...",
        duree,
    )
    audio_data = robot_api.media.record_audio(duration=duree, sample_rate=frequence)
    audio_io = _convert_audio_to_wav_bytes(audio_data, frequence)

    r = sr.Recognizer()
    with sr.AudioFile(audio_io) as source:
        audio = r.record(source)
        texte = r.recognize_google(audio, language="fr-FR")
        logging.info("‚úÖ Texte reconnu (SDK 4 microphones) : %s", texte)
        return str(texte)


def _recognize_from_local_microphone(
    duree: int,
    frequence: int,
) -> str | None:
    """Reconnaissance vocale via microphone local (speech_recognition)."""
    r = sr.Recognizer()
    with sr.Microphone(sample_rate=frequence) as source:
        logging.info("√âcoute du micro pour la reconnaissance vocale...")
        audio = r.listen(source, phrase_time_limit=duree)
        texte = r.recognize_google(audio, language="fr-FR")
        logging.info("Texte reconnu : %s", texte)
        return str(texte)


def reconnaitre_parole(
    duree: int = 3,
    frequence: int = 16000,
    robot_api: Any | None = None,
) -> str | None:
    """Reconna√Æt la parole via le micro (STT, fran√ßais par d√©faut).

    Utilise robot.media.microphone (4 microphones SDK) si disponible,
    sinon utilise speech_recognition pour compatibilit√©.

    Args:
        duree: Dur√©e d'enregistrement en secondes
        frequence: Fr√©quence d'√©chantillonnage
        robot_api: Interface RobotAPI (optionnel) pour acc√®s robot.media.microphone

    Returns:
        Texte reconnu ou None

    """
    # Essayer SDK microphone
    if robot_api and hasattr(robot_api, "media") and robot_api.media:
        try:
            result = _recognize_from_sdk_microphone(duree, frequence, robot_api)
            if result is not None:
                return result
        except (RuntimeError, AttributeError, OSError) as e:
            logging.debug("Erreur reconnaissance SDK (runtime/attr/os): %s", e)
        except Exception as e:  # noqa: BLE001
            logging.debug(
                "Erreur reconnaissance SDK (fallback speech_recognition): %s", e
            )

    # Fallback: speech_recognition local
    try:
        return _recognize_from_local_microphone(duree, frequence)
    except sr.UnknownValueError:
        logging.warning("Aucune parole reconnue.")
        return None
    except (RuntimeError, AttributeError, OSError) as e:
        logging.debug("Erreur de reconnaissance vocale (runtime/attr/os): %s", e)
        return None
    except Exception as e:  # noqa: BLE001
        logging.debug("Erreur d'acc√®s au microphone: %s", e)
        logging.debug(
            "La reconnaissance vocale n√©cessite pyaudio. "
            "Installez-le avec : pip install pyaudio",
        )
        return None


def lister_voix_disponibles() -> list[Any]:
    """Retourne la liste des voix TTS disponibles avec leurs propri√©t√©s."""
    # ‚ö° OPTIMISATION PERFORMANCE: Utiliser cache au lieu de pyttsx3.init()
    engine = _get_pyttsx3_engine()
    if engine is None:
        logging.warning("‚ö†Ô∏è pyttsx3 non disponible, aucune voix list√©e")
        return []
    voices = engine.getProperty("voices")
    result = []
    for _idx, v in enumerate(voices):
        try:
            # G√©rer le cas o√π languages est vide ou None
            if hasattr(v, "languages") and v.languages and len(v.languages) > 0:
                try:
                    if hasattr(v.languages[0], "decode"):
                        _ = v.languages[0].decode(errors="ignore")
                    else:
                        _ = str(v.languages[0])
                except (
                    AttributeError,
                    TypeError,
                    ValueError,
                    UnicodeDecodeError,
                    Exception,
                ):
                    _ = str(v.languages[0]) if v.languages[0] else ""
            else:
                _ = ""
        except (AttributeError, TypeError, ValueError, IndexError, Exception):
            _ = str(v.languages) if hasattr(v, "languages") and v.languages else ""
        result.append(v)
    return result


# OPTIMISATION PERFORMANCE: Threading asynchrone pour transcription audio
# Utiliser Union pour permettre None comme signal d'arr√™t

_transcribe_queue: queue.Queue[dict[str, Any] | None] = queue.Queue(maxsize=5)
_transcribe_thread: threading.Thread | None = None
_transcribe_active = False
_transcribe_lock = threading.Lock()
_last_transcribe_result: str | None = None


def _transcribe_thread_worker() -> None:
    """Worker thread pour transcriptions asynchrones en arri√®re-plan."""
    global _last_transcribe_result
    logger.debug("üé§ Thread transcription asynchrone d√©marr√©")

    while _transcribe_active:
        task = None
        task_retrieved = False
        task_done_called = False
        try:
            # Attendre t√¢che de transcription
            task = _transcribe_queue.get(timeout=0.5)
            task_retrieved = True  # Marquer que la t√¢che a √©t√© r√©cup√©r√©e

            if task is None:  # Signal d'arr√™t
                _transcribe_queue.task_done()
                task_done_called = True
                break

            audio_data = task["audio_data"]
            sample_rate = task.get("sample_rate", 16000)
            model_size = task.get("model_size", "tiny")

            # Transcription synchrone dans le thread
            result = _transcribe_audio_sync(audio_data, sample_rate, model_size)
            _last_transcribe_result = result

            _transcribe_queue.task_done()
            task_done_called = True
        except queue.Empty:
            continue
        except (RuntimeError, AttributeError, OSError) as e:
            # Utiliser error au lieu de exception pour √©viter traces compl√®tes dans tests
            logger.error(
                "Erreur thread transcription asynchrone (runtime/attr/os): %s", e
            )
        except (
            Exception
        ) as e:  # noqa: BLE001 - Fallback final pour erreurs vraiment inattendues
            # Utiliser error au lieu de exception pour √©viter traces compl√®tes dans tests
            logger.error("Erreur thread transcription asynchrone: %s", e)
            # Appeler task_done() seulement si la t√¢che a √©t√© r√©cup√©r√©e
            # et qu'on ne l'a pas d√©j√† appel√©
            if task_retrieved and task is not None and not task_done_called:
                _transcribe_queue.task_done()

    logger.debug("üé§ Thread transcription asynchrone arr√™t√©")


def start_async_transcription() -> bool:
    """D√©marre le thread de transcription asynchrone.

    Returns:
        True si d√©marr√© avec succ√®s, False sinon

    """
    global _transcribe_thread, _transcribe_active

    with _transcribe_lock:
        if _transcribe_active:
            logger.debug("Transcription asynchrone d√©j√† active")
            return True

        _transcribe_active = True
        _transcribe_thread = threading.Thread(
            target=_transcribe_thread_worker,
            daemon=True,
            name="BBIAVoice-TranscribeThread",
        )
        _transcribe_thread.start()
        logger.info("‚úÖ Transcription asynchrone d√©marr√©e")
        return True


def stop_async_transcription() -> None:
    """Arr√™te le thread de transcription asynchrone."""
    global _transcribe_thread, _transcribe_active

    with _transcribe_lock:
        if not _transcribe_active:
            return

        _transcribe_active = False

        # Envoyer signal d'arr√™t
        with contextlib.suppress(queue.Full):
            _transcribe_queue.put_nowait(None)

        if _transcribe_thread and _transcribe_thread.is_alive():
            _transcribe_thread.join(timeout=2.0)
            if _transcribe_thread.is_alive():
                logger.warning(
                    "Thread transcription asynchrone n'a pas pu √™tre arr√™t√© proprement",
                )

        logger.info("‚úÖ Transcription asynchrone arr√™t√©e")


def transcribe_audio_async(
    audio_data: Any,
    sample_rate: int = 16000,
    model_size: str = "tiny",
    timeout: float | None = None,
) -> str | None:
    """Transcrit audio de mani√®re asynchrone (non-bloquant).

    Args:
        audio_data: Donn√©es audio (numpy array ou bytes)
        sample_rate: Fr√©quence d'√©chantillonnage (d√©faut: 16000)
        model_size: Taille du mod√®le Whisper (d√©faut: "tiny")
        timeout: Timeout en secondes (d√©faut: None = pas de timeout)

    Returns:
        Texte transcrit ou None si erreur/timeout

    """
    global _last_transcribe_result

    # D√©marrer thread si n√©cessaire
    if not _transcribe_active:
        start_async_transcription()

    # Si transcription asynchrone active, ajouter √† la queue
    if _transcribe_active:
        try:
            task = {
                "audio_data": audio_data,
                "sample_rate": sample_rate,
                "model_size": model_size,
            }
            _transcribe_queue.put_nowait(task)

            # Attendre r√©sultat avec timeout
            if timeout:
                start_time = time.time()
                while time.time() - start_time < timeout:
                    if _last_transcribe_result is not None:
                        result = _last_transcribe_result
                        _last_transcribe_result = None
                        return result
                    time.sleep(0.1)
                return None

            # Pas de timeout, retourner dernier r√©sultat disponible
            return _last_transcribe_result
        except queue.Full:
            logger.warning("Queue transcription pleine, fallback synchrone")
            # Fallback synchrone
            return _transcribe_audio_sync(audio_data, sample_rate, model_size)

    # Fallback: transcription synchrone si asynchrone non actif
    return _transcribe_audio_sync(audio_data, sample_rate, model_size)


def _transcribe_audio_sync(
    audio_data: Any,
    sample_rate: int = 16000,
    model_size: str = "tiny",
) -> str | None:
    """Version synchrone interne de transcribe_audio (utilis√©e par thread)."""
    # V√©rifier flag d'environnement pour d√©sactiver audio (CI/headless)
    if os.environ.get("BBIA_DISABLE_AUDIO", "0") == "1":
        logging.debug("Audio d√©sactiv√© (BBIA_DISABLE_AUDIO=1): transcription ignor√©e")
        return None

    try:
        if not WHISPER_AVAILABLE:
            logging.debug("Whisper non disponible pour transcription")
            return None

        # OPTIMISATION PERFORMANCE: Utiliser WhisperSTT avec cache global
        # Le cache est g√©r√© automatiquement par WhisperSTT
        stt = WhisperSTT(model_size=model_size, language="fr")

        # Charger le mod√®le (utilise cache si disponible)
        if not stt.is_loaded and not stt.load_model():
            logging.warning("Impossible de charger le mod√®le Whisper")
            return None

        # Convertir audio_data en fichier temporaire si n√©cessaire
        # Cr√©er fichier temporaire
        temp_file = tempfile.NamedTemporaryFile(
            suffix=".wav",
            delete=False,
        )
        temp_path = temp_file.name
        temp_file.close()

        try:
            # Sauvegarder audio_data dans fichier temporaire
            if not SOUNDFILE_AVAILABLE:
                raise ImportError("soundfile non disponible")

            if isinstance(audio_data, np.ndarray):
                sf.write(temp_path, audio_data, sample_rate)
            elif isinstance(audio_data, bytes):
                # Convertir bytes en numpy array si n√©cessaire
                audio_array = (
                    np.frombuffer(audio_data, dtype=np.int16).astype(np.float32)
                    / 32768.0
                )
                sf.write(temp_path, audio_array, sample_rate)
            else:
                logging.warning(f"Format audio non support√©: {type(audio_data)}")
                return None

            # Transcrit avec Whisper (utilise cache mod√®le)
            result = stt.transcribe_audio(temp_path)

            return str(result) if result is not None else None

        finally:
            # Nettoyer fichier temporaire
            try:
                os.unlink(temp_path)
            except (OSError, PermissionError) as cleanup_error:
                logging.debug(
                    "Nettoyage fichier Whisper (os/permission): %s", cleanup_error
                )
            except (
                Exception
            ) as cleanup_error:  # noqa: BLE001 - Fallback final pour erreurs vraiment inattendues
                logging.debug(
                    "Nettoyage fichier Whisper (erreur inattendue): %s", cleanup_error
                )

    except ImportError:
        logging.debug("Whisper non disponible (import √©chou√©)")
        return None
    except Exception as e:
        logging.warning(f"Erreur transcription Whisper: {e}")
        return None


# OPTIMISATION PERFORMANCE: Fonction wrapper pour transcription audio avec Whisper
# Utilise le cache global pour √©viter rechargement du mod√®le
# NOTE: Pour version asynchrone, utiliser transcribe_audio_async()
def transcribe_audio(
    audio_data: Any,
    sample_rate: int = 16000,
    model_size: str = "tiny",
) -> str | None:
    """Transcrit des donn√©es audio en texte avec Whisper (utilise cache).

    Args:
        audio_data: Donn√©es audio (numpy array ou bytes)
        sample_rate: Fr√©quence d'√©chantillonnage (d√©faut: 16000)
        model_size: Taille du mod√®le Whisper ("tiny", "base", etc.) - d√©faut: "tiny"

    Returns:
        Texte transcrit ou None si erreur

    """
    # V√©rifier flag d'environnement pour d√©sactiver audio (CI/headless)
    if os.environ.get("BBIA_DISABLE_AUDIO", "0") == "1":
        logging.debug("Audio d√©sactiv√© (BBIA_DISABLE_AUDIO=1): transcription ignor√©e")
        return None

    try:
        if not WHISPER_AVAILABLE:
            logging.debug("Whisper non disponible pour transcription")
            return None

        # OPTIMISATION PERFORMANCE: Utiliser WhisperSTT avec cache global
        # Le cache est g√©r√© automatiquement par WhisperSTT
        stt = WhisperSTT(model_size=model_size, language="fr")

        # Charger le mod√®le (utilise cache si disponible)
        if not stt.is_loaded and not stt.load_model():
            logging.warning("Impossible de charger le mod√®le Whisper")
            return None

        # Convertir audio_data en fichier temporaire si n√©cessaire
        # Cr√©er fichier temporaire
        temp_file = tempfile.NamedTemporaryFile(
            suffix=".wav",
            delete=False,
        )
        temp_path = temp_file.name
        temp_file.close()

        try:
            # Sauvegarder audio_data dans fichier temporaire
            if not SOUNDFILE_AVAILABLE:
                raise ImportError("soundfile non disponible")

            if isinstance(audio_data, np.ndarray):
                sf.write(temp_path, audio_data, sample_rate)
            elif isinstance(audio_data, bytes):
                # Convertir bytes en numpy array si n√©cessaire
                audio_array = (
                    np.frombuffer(audio_data, dtype=np.int16).astype(np.float32)
                    / 32768.0
                )
                sf.write(temp_path, audio_array, sample_rate)
            else:
                logging.warning(f"Format audio non support√©: {type(audio_data)}")
                return None

            # Transcrit avec Whisper (utilise cache mod√®le)
            result = stt.transcribe_audio(temp_path)

            return str(result) if result is not None else None

        finally:
            # Nettoyer fichier temporaire
            try:
                os.unlink(temp_path)
            except (OSError, PermissionError) as cleanup_error:
                logging.debug(
                    "Nettoyage fichier Whisper (os/permission): %s", cleanup_error
                )
            except (
                Exception
            ) as cleanup_error:  # noqa: BLE001 - Fallback final pour erreurs vraiment inattendues
                logging.debug(
                    "Nettoyage fichier Whisper (erreur inattendue): %s", cleanup_error
                )

    except ImportError:
        logging.debug("Whisper non disponible (import √©chou√©)")
        return None
    except Exception as e:
        logging.warning(f"Erreur transcription Whisper: {e}")
        return None


if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "list-voices":
        lister_voix_disponibles()
        # Optionnel : d√©mo d'√©coute de chaque voix
        if len(sys.argv) > 2 and sys.argv[2] == "demo":
            # ‚ö° OPTIMISATION PERFORMANCE: Utiliser cache au lieu de pyttsx3.init()
            engine = _get_pyttsx3_engine()
            if engine is None:
                logging.warning("‚ö†Ô∏è pyttsx3 non disponible, d√©mo impossible")
                sys.exit(1)
            voices = engine.getProperty("voices")
            for v in voices:
                engine.setProperty("voice", v.id)
                engine.setProperty("rate", 170)
                engine.setProperty("volume", 1.0)
                engine.say(f"Bonjour, je suis la voix {v.name}.")
                engine.runAndWait()
        sys.exit(0)

    # ‚ö° OPTIMISATION PERFORMANCE: Utiliser cache au lieu de pyttsx3.init()
    engine = _get_pyttsx3_engine()
    if engine is None:
        logging.warning("‚ö†Ô∏è pyttsx3 non disponible, d√©mo impossible")
        sys.exit(1)
    voice_id = _get_cached_voice_id()
    engine.setProperty("voice", voice_id)
    engine.setProperty("rate", 170)
    engine.setProperty("volume", 1.0)
    demo_texte = (
        "Bonjour, je suis BBIA. Je fonctionne sur votre Mac. "
        "Ceci est la voix la plus proche de Reachy Mini Wireless."
    )
    engine.say(demo_texte)
    engine.runAndWait()

    sys.stdout.flush()
    time.sleep(0.5)
    # Note: robot_api non disponible dans __main__, donc fallback automatique
    texte = reconnaitre_parole(duree=3, frequence=16000, robot_api=None)
    if texte:
        dire_texte(f"Vous avez dit : {texte}")
    else:
        dire_texte("Je n'ai rien compris.")
