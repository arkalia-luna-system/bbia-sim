#!/usr/bin/env python3
"""
BBIA Integration - Module d'int√©gration BBIA ‚Üî Robot Reachy Mini
Connecte tous les modules BBIA au simulateur MuJoCo pour cr√©er une simulation compl√®te
"""

import asyncio
import logging
from typing import Optional

from .bbia_audio import detecter_son, enregistrer_audio, lire_audio
from .bbia_behavior import BBIABehaviorManager
from .bbia_emotions import BBIAEmotions
from .bbia_vision import BBIAVision
from .bbia_voice import dire_texte, reconnaitre_parole
from .daemon.simulation_service import SimulationService

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BBIAIntegration:
    """
    Module d'int√©gration principal qui connecte tous les modules BBIA au robot Reachy Mini.

    Fonctionnalit√©s :
    - Mapping √©motions ‚Üí articulations du robot
    - R√©actions visuelles ‚Üí mouvements
    - Synchronisation audio ‚Üî mouvements
    - Gestion des comportements complexes
    """

    def __init__(self, simulation_service: Optional[SimulationService] = None):
        """Initialise l'int√©gration BBIA avec le service de simulation."""

        # Service de simulation
        self.simulation_service = simulation_service or SimulationService()

        # Modules BBIA
        self.emotions = BBIAEmotions()
        self.vision = BBIAVision()
        self.behavior = BBIABehaviorManager()

        # Fonctions audio et voice (pas de classes)
        self.audio_functions = {
            "enregistrer": enregistrer_audio,
            "lire": lire_audio,
            "detecter": detecter_son,
        }
        self.voice_functions = {"dire": dire_texte, "reconnaitre": reconnaitre_parole}

        # √âtat de l'int√©gration
        self.is_active = False
        self.current_emotion = "neutral"
        self.emotion_intensity = 0.5

        # Mapping √©motions ‚Üí articulations
        self.emotion_mappings = self._create_emotion_mappings()

        # Configuration des r√©actions
        self.reaction_config = {
            "face_detection": {"head_turn_speed": 0.5, "tracking_active": True},
            "object_detection": {"point_speed": 0.3, "focus_duration": 2.0},
            "sound_detection": {"turn_speed": 0.4, "reaction_delay": 0.2},
        }

        logger.info("üé≠ BBIA Integration initialis√©e")
        logger.info(f"   ‚Ä¢ √âmotions disponibles : {len(self.emotions.emotions)}")
        logger.info("   ‚Ä¢ Articulations contr√¥lables : 16")
        logger.info(
            f"   ‚Ä¢ Service simulation : {'‚úÖ' if self.simulation_service else '‚ùå'}"
        )

    def _create_emotion_mappings(self) -> dict[str, dict[str, float]]:
        """Cr√©e le mapping des √©motions vers les positions d'articulations."""

        return {
            "neutral": {
                "yaw_body": 0.0,
                "right_antenna": 0.0,
                "left_antenna": 0.0,
                "stewart_1": 0.0,
                "stewart_2": 0.0,
                "stewart_3": 0.0,
                "stewart_4": 0.0,
                "stewart_5": 0.0,
                "stewart_6": 0.0,
            },
            "happy": {
                "yaw_body": 0.1,
                "right_antenna": 0.3,
                "left_antenna": 0.3,
                "stewart_1": 0.2,
                "stewart_2": 0.1,
                "stewart_3": 0.1,
                "stewart_4": 0.1,
                "stewart_5": 0.2,
                "stewart_6": 0.1,
            },
            "sad": {
                "yaw_body": -0.1,
                "right_antenna": -0.2,
                "left_antenna": -0.2,
                "stewart_1": -0.1,
                "stewart_2": -0.2,
                "stewart_3": -0.2,
                "stewart_4": -0.2,
                "stewart_5": -0.1,
                "stewart_6": -0.2,
            },
            "angry": {
                "yaw_body": 0.0,
                "right_antenna": 0.5,
                "left_antenna": 0.5,
                "stewart_1": 0.3,
                "stewart_2": 0.3,
                "stewart_3": 0.3,
                "stewart_4": 0.3,
                "stewart_5": 0.3,
                "stewart_6": 0.3,
            },
            "surprised": {
                "yaw_body": 0.2,
                "right_antenna": 0.4,
                "left_antenna": 0.4,
                "stewart_1": 0.4,
                "stewart_2": 0.4,
                "stewart_3": 0.4,
                "stewart_4": 0.4,
                "stewart_5": 0.4,
                "stewart_6": 0.4,
            },
            "curious": {
                "yaw_body": 0.15,
                "right_antenna": 0.2,
                "left_antenna": 0.2,
                "stewart_1": 0.25,
                "stewart_2": 0.15,
                "stewart_3": 0.15,
                "stewart_4": 0.15,
                "stewart_5": 0.25,
                "stewart_6": 0.15,
            },
            "excited": {
                "yaw_body": 0.3,
                "right_antenna": 0.6,
                "left_antenna": 0.6,
                "stewart_1": 0.5,
                "stewart_2": 0.4,
                "stewart_3": 0.4,
                "stewart_4": 0.4,
                "stewart_5": 0.5,
                "stewart_6": 0.4,
            },
            "fearful": {
                "yaw_body": -0.2,
                "right_antenna": -0.3,
                "left_antenna": -0.3,
                "stewart_1": -0.2,
                "stewart_2": -0.3,
                "stewart_3": -0.3,
                "stewart_4": -0.3,
                "stewart_5": -0.2,
                "stewart_6": -0.3,
            },
        }

    async def start_integration(self) -> bool:
        """D√©marre l'int√©gration BBIA avec le simulateur."""

        try:
            logger.info("üöÄ D√©marrage de l'int√©gration BBIA...")

            # D√©marrer la simulation si n√©cessaire
            if not self.simulation_service.is_running:
                logger.info("üì¶ D√©marrage du service de simulation...")
                await self.simulation_service.start_simulation(headless=False)

                # Attendre que la simulation soit pr√™te
                await asyncio.sleep(2)

            # V√©rifier que la simulation est pr√™te
            if not self.simulation_service.is_simulation_ready():
                logger.error("‚ùå Service de simulation non pr√™t")
                return False

            # Initialiser l'√©tat BBIA
            self.is_active = True
            self.current_emotion = "neutral"

            # Appliquer l'√©motion neutre initiale
            await self.apply_emotion_to_robot("neutral", 0.5)

            logger.info("‚úÖ Int√©gration BBIA d√©marr√©e avec succ√®s")
            logger.info(f"   ‚Ä¢ √âmotion initiale : {self.current_emotion}")
            logger.info(f"   ‚Ä¢ Intensit√© : {self.emotion_intensity}")

            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur d√©marrage int√©gration : {e}")
            return False

    async def stop_integration(self):
        """Arr√™te l'int√©gration BBIA."""

        logger.info("üõë Arr√™t de l'int√©gration BBIA...")

        self.is_active = False

        # Remettre le robot en position neutre
        await self.apply_emotion_to_robot("neutral", 0.5)

        logger.info("‚úÖ Int√©gration BBIA arr√™t√©e")

    async def apply_emotion_to_robot(
        self, emotion: str, intensity: float = 0.5
    ) -> bool:
        """
        Applique une √©motion au robot via les articulations.

        Args:
            emotion: Nom de l'√©motion √† appliquer
            intensity: Intensit√© de l'√©motion (0.0 √† 1.0)

        Returns:
            True si l'√©motion a √©t√© appliqu√©e avec succ√®s
        """

        if not self.is_active:
            logger.warning("‚ö†Ô∏è Int√©gration BBIA non active")
            return False

        if emotion not in self.emotion_mappings:
            logger.error(f"‚ùå √âmotion inconnue : {emotion}")
            return False

        try:
            logger.info(f"üé≠ Application √©motion '{emotion}' (intensit√©: {intensity})")

            # Mettre √† jour l'√©tat BBIA
            self.emotions.set_emotion(emotion, intensity)
            self.current_emotion = emotion
            self.emotion_intensity = intensity

            # R√©cup√©rer le mapping de l'√©motion
            emotion_mapping = self.emotion_mappings[emotion]

            # Appliquer les positions d'articulations avec l'intensit√©
            for joint_name, base_position in emotion_mapping.items():
                # Ajuster la position selon l'intensit√©
                adjusted_position = base_position * intensity

                # Appliquer la position au robot
                self.simulation_service.set_joint_position(
                    joint_name, adjusted_position
                )

            logger.info(f"‚úÖ √âmotion '{emotion}' appliqu√©e au robot")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur application √©motion : {e}")
            return False

    async def react_to_vision_detection(self, detection_data: dict) -> bool:
        """
        R√©agit aux d√©tections visuelles en contr√¥lant le robot.

        Args:
            detection_data: Donn√©es de d√©tection (objets, visages, etc.)

        Returns:
            True si la r√©action a √©t√© appliqu√©e
        """

        if not self.is_active:
            return False

        try:
            # R√©action √† la d√©tection de visage
            if "faces" in detection_data and detection_data["faces"]:
                logger.info("üë§ Visage d√©tect√© - R√©action de curiosit√©")
                await self.apply_emotion_to_robot("curious", 0.7)

                # Tourner la t√™te vers le visage (simulation)
                face_position = detection_data["faces"][0].get("position", (0, 0))
                head_turn = face_position[0] * 0.3  # Ajuster selon la position
                self.simulation_service.set_joint_position("yaw_body", head_turn)

                return True

            # R√©action √† la d√©tection d'objet int√©ressant
            if "objects" in detection_data and detection_data["objects"]:
                logger.info("üì¶ Objet d√©tect√© - R√©action de surprise")
                await self.apply_emotion_to_robot("surprised", 0.6)

                return True

            return False

        except Exception as e:
            logger.error(f"‚ùå Erreur r√©action visuelle : {e}")
            return False

    async def sync_voice_with_movements(
        self, text: str, emotion: str = "neutral"
    ) -> bool:
        """
        Synchronise la voix avec les mouvements du robot.

        Args:
            text: Texte √† prononcer
            emotion: √âmotion √† exprimer pendant la parole

        Returns:
            True si la synchronisation a √©t√© appliqu√©e
        """

        if not self.is_active:
            return False

        try:
            logger.info(f"üó£Ô∏è Synchronisation voix + mouvements : '{text[:30]}...'")

            # Appliquer l'√©motion pendant la parole
            await self.apply_emotion_to_robot(emotion, 0.6)

            # Simuler des mouvements subtils pendant la parole
            words = text.split()
            for i, _word in enumerate(words):
                # Petit mouvement de t√™te pour chaque mot important
                if i % 3 == 0:  # Tous les 3 mots
                    head_movement = 0.1 if i % 6 == 0 else -0.1
                    self.simulation_service.set_joint_position(
                        "yaw_body", head_movement
                    )

                # Petite pause entre les mots
                await asyncio.sleep(0.1)

            # Retour √† l'√©motion normale apr√®s la parole
            await self.apply_emotion_to_robot(
                self.current_emotion, self.emotion_intensity
            )

            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur synchronisation voix : {e}")
            return False

    async def execute_behavior_sequence(self, behavior_name: str) -> bool:
        """
        Ex√©cute une s√©quence de comportement compl√®te.

        Args:
            behavior_name: Nom du comportement √† ex√©cuter

        Returns:
            True si la s√©quence a √©t√© ex√©cut√©e
        """

        if not self.is_active:
            return False

        try:
            logger.info(f"üé¨ Ex√©cution s√©quence comportement : {behavior_name}")

            # Ex√©cuter le comportement BBIA
            self.behavior.add_to_queue(behavior_name)

            # Appliquer les √©motions correspondantes au robot
            if behavior_name == "greeting":
                await self.apply_emotion_to_robot("happy", 0.8)
                await asyncio.sleep(1.0)
                await self.apply_emotion_to_robot("neutral", 0.5)

            elif behavior_name == "hide":
                await self.apply_emotion_to_robot("fearful", 0.7)
                await asyncio.sleep(2.0)
                await self.apply_emotion_to_robot("neutral", 0.5)

            elif behavior_name == "antenna_animation":
                await self.apply_emotion_to_robot("excited", 0.9)
                await asyncio.sleep(1.5)
                await self.apply_emotion_to_robot("neutral", 0.5)

            logger.info(f"‚úÖ S√©quence '{behavior_name}' ex√©cut√©e")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur ex√©cution comportement : {e}")
            return False

    def get_integration_status(self) -> dict:
        """Retourne le statut de l'int√©gration BBIA."""

        return {
            "is_active": self.is_active,
            "current_emotion": self.current_emotion,
            "emotion_intensity": self.emotion_intensity,
            "simulation_ready": self.simulation_service.is_simulation_ready(),
            "available_emotions": list(self.emotion_mappings.keys()),
            "reaction_config": self.reaction_config,
        }


# Fonction utilitaire pour cr√©er une instance d'int√©gration
async def create_bbia_integration(model_path: Optional[str] = None) -> BBIAIntegration:
    """
    Cr√©e et initialise une instance d'int√©gration BBIA.

    Args:
        model_path: Chemin vers le mod√®le MJCF (optionnel)

    Returns:
        Instance d'int√©gration BBIA pr√™te √† utiliser
    """

    # Cr√©er le service de simulation
    simulation_service = SimulationService(model_path)

    # Cr√©er l'int√©gration BBIA
    integration = BBIAIntegration(simulation_service)

    # D√©marrer l'int√©gration
    success = await integration.start_integration()

    if not success:
        raise RuntimeError("Impossible de d√©marrer l'int√©gration BBIA")

    return integration
