# üöÄ AM√âLIORATIONS FUTURES - SDK REACHY MINI

> R√©f√©rence √©tat global
>
> Voir `docs/reference/project-status.md` ‚Üí "√âtat par axe" pour prioriser les am√©liorations (API/SDK, perf, s√©curit√©, CI/CD).

**Date :** Oct / Nov. 2025  
**R√©f√©rence SDK :** <https://github.com/pollen-robotics/reachy_mini>

---

## üéØ **OBJECTIF**

Documenter les features avanc√©es du SDK Reachy Mini qui sont **disponibles** dans le backend mais **non encore utilis√©es** dans les modules BBIA pour am√©lioration future.

---

## üìä **FEATURES SDK DISPONIBLES**

### **1. Module Media SDK** ‚úÖ **D√âJ√Ä INT√âGR√â** (Oct / Nov. 2025)

**Status :** ‚úÖ **FAIT** - Int√©gr√© dans tous les modules concern√©s avec fallbacks gracieux

**V√©rification code :**

- ‚úÖ `bbia_vision.py` (lignes 126-137) : Utilise `robot.media.camera` si disponible
- ‚úÖ `bbia_audio.py` (lignes 162-208) : Utilise `robot.media.microphone` et `robot.media.record_audio()` si disponible
- ‚úÖ `bbia_voice.py` (lignes 259-342) : Utilise `robot.media.speaker` et `robot.media.play_audio()` si disponible

**Capacit√©s :**

```python
robot.media.camera          # ‚úÖ Utilis√© dans bbia_vision.py
robot.media.microphone      # ‚úÖ Utilis√© dans bbia_audio.py (4 mics)
robot.media.speaker         # ‚úÖ Utilis√© dans bbia_voice.py (5W)
robot.media.play_audio()    # ‚úÖ Utilis√© dans bbia_voice.py et bbia_audio.py
robot.media.record_audio()  # ‚úÖ Utilis√© dans bbia_audio.py

```

**Modules am√©lior√©s :**

- ‚úÖ `bbia_vision.py` ‚Üí Utilise `robot.media.camera` avec fallback simulation
- ‚úÖ `bbia_audio.py` ‚Üí Utilise `robot.media.microphone` (4 mics) avec fallback sounddevice
- ‚úÖ `bbia_voice.py` ‚Üí Utilise `robot.media.speaker` (5W) avec fallback pyttsx3

**Avantages :**

- ‚úÖ Qualit√© hardware optimale (4 microphones directionnels)
- ‚úÖ Annulation de bruit automatique
- ‚úÖ Cam√©ra grand angle 1080p temps r√©el
- ‚úÖ Synth√®se vocale hardware optimis√©e

---

### **2. Module IO SDK** ‚ö†Ô∏è Non Utilis√© (√† √©valuer apr√®s r√©ception robot)

**Status :** Disponible dans `ReachyMiniBackend.io` mais NON UTILIS√â

**Capacit√©s :**

```python
robot.io.get_camera_stream()  # Stream vid√©o temps r√©el
robot.io.get_audio_stream()   # Stream audio temps r√©el
robot.io.set_leds()            # Contr√¥le LEDs (si disponibles)

```

**Opportunit√©s :**

- Vision temps r√©el au lieu de scan p√©riodique
- Audio streaming pour reconnaissance vocale temps r√©el
- Feedback visuel via LEDs

#### üìã Recommandation D√©taill√©e : Ne PAS impl√©menter maintenant

**Pourquoi ne pas le faire maintenant ?**

1. **Vous n'avez pas encore le robot** : Impossible de tester les performances r√©elles avec le vrai hardware. Les streams peuvent √™tre plus lents que pr√©vu, ou n√©cessiter des ajustements sp√©cifiques au hardware.

2. **Le syst√®me actuel fonctionne d√©j√†** : 
   - `robot.media.camera.get_image()` + captures p√©riodiques = **stable et performant**
   - Le code actuel est test√© et fonctionne bien en simulation
   - Pas besoin d'ajouter de la complexit√© avant d'avoir test√©

3. **Complexit√© vs b√©n√©fice** :
   - **Complexit√©** : Refactor significatif de `BBIAVision` et `bbia_audio`, gestion threads, gestion m√©moire
   - **B√©n√©fice** : Gain de latence minime (quelques millisecondes) vs complexit√© ajout√©e
   - **Risque** : Introduire des bugs, rendre le code plus complexe √† maintenir

4. **Principe "Ne r√©parez pas ce qui n'est pas cass√©"** : Votre syst√®me fonctionne. Mieux vaut tester d'abord avec le robot, identifier les vrais besoins, puis optimiser si n√©cessaire.

**Quand est-ce que √ßa devient utile ?**

- ‚úÖ Quand vous avez besoin de suivre des objets en mouvement rapide (ex: balle qui bouge)
- ‚úÖ Quand la latence devient critique pour vos cas d'usage (ex: interaction temps r√©el)
- ‚úÖ Quand les captures p√©riodiques ne suffisent pas (ex: perte d'objets entre captures)

**Plan d'action recommand√© :**

1. **Maintenant (avant robot)** : Ne rien changer, v√©rifier que tout fonctionne en simulation
2. **Quand vous recevez le robot** : Tester avec le syst√®me actuel (`robot.media.camera.get_image()`), mesurer les performances r√©elles
3. **Apr√®s les tests** : Si besoin identifi√© (latence trop √©lev√©e, perte d'objets) ‚Üí envisager streams IO

**Plan d'action technique (si d√©cid√© apr√®s tests) :**

- [ ] ‚ö†Ô∏è Activer `robot.io.get_camera_stream()` dans `BBIAVision` (n√©cessiterait refactor significatif)
- [ ] ‚ö†Ô∏è Activer `robot.io.get_audio_stream()` dans `bbia_audio` (n√©cessiterait refactor significatif)
- **Note** : Code actuel (`robot.media.camera.get_image()` + captures p√©riodiques) fonctionne parfaitement. Streams seraient optimisation future pour b√©n√©fice marginal.

**Conclusion** : Les streams IO sont une **optimisation optionnelle**, pas un besoin critique. **Mieux vaut attendre d'avoir le robot pour tester et d√©cider si c'est vraiment n√©cessaire.**

---

### **3. Techniques d'Interpolation Avanc√©es** ‚úÖ **D√âJ√Ä IMPL√âMENT√â** (Oct / Nov. 2025)

**Status :** ‚úÖ **FAIT** - Mapping √©motion ‚Üí interpolation adaptative impl√©ment√© dans `bbia_integration.py`

**V√©rification code :**

- ‚úÖ `bbia_integration.py` (lignes 289-305) : `emotion_interpolation_map` avec CARTOON, EASE_IN_OUT, MIN_JERK
- ‚úÖ `backends/reachy_mini_backend.py` (lignes 914-918) : Support toutes les techniques d'interpolation

**Disponibles et utilis√©es :**

```python
InterpolationTechnique.MIN_JERK       # ‚úÖ Utilis√© (neutral, curious, determined)
InterpolationTechnique.LINEAR         # ‚úÖ Disponible (backends/reachy_mini_backend.py:914)
InterpolationTechnique.EASE_IN_OUT    # ‚úÖ Utilis√© (calm, sad, nostalgic, fearful)
InterpolationTechnique.CARTOON        # ‚úÖ Utilis√© (happy, excited, surprised, angry, proud)

```

**Impl√©mentation actuelle :**

```python
# bbia_integration.py lignes 290-304
emotion_interpolation_map = {
    "happy": "cartoon",      # ‚úÖ Expressif et anim√©
    "excited": "cartoon",    # ‚úÖ Tr√®s expressif
    "surprised": "cartoon", # ‚úÖ Sautillant
    "calm": "ease_in_out",   # ‚úÖ Doux et fluide
    "sad": "ease_in_out",    # ‚úÖ Lent et m√©lancolique
    "nostalgic": "ease_in_out", # ‚úÖ Doux
    "neutral": "minjerk",   # ‚úÖ Naturel
    "curious": "minjerk",   # ‚úÖ Naturel
    "angry": "cartoon",     # ‚úÖ Expressif
    "fearful": "ease_in_out", # ‚úÖ Doux mais inquiet
    "determined": "minjerk", # ‚úÖ Naturel mais ferme
    "proud": "cartoon",     # ‚úÖ Expressif
}

```

---

### **4. Enregistrement/Replay Avanc√©** ‚úÖ **D√âJ√Ä IMPL√âMENT√â** (Oct / Nov. 2025)

**Status :** ‚úÖ **FAIT** - Impl√©ment√© dans `bbia_behavior.py` et `reachy_mini_backend.py`

**V√©rification code :**

- ‚úÖ `backends/reachy_mini_backend.py` (lignes 1065-1119) : `start_recording()`, `stop_recording()`, `play_move()`, `async_play_move()`
- ‚úÖ `bbia_behavior.py` (lignes 1115-1170) : `BBIABehaviorManager.record_behavior_movement()` et `play_saved_behavior()` avec support async

**Disponible et utilis√© :**

```python
robot.start_recording()           # ‚úÖ Disponible (reachy_mini_backend.py:1065)
move = robot.stop_recording()      # ‚úÖ Disponible (reachy_mini_backend.py:1076)
robot.play_move(move)              # ‚úÖ Disponible (reachy_mini_backend.py:1089)
robot.async_play_move(move)        # ‚úÖ Disponible (reachy_mini_backend.py:1105)

```

**Impl√©mentation actuelle :**

```python
# bbia_behavior.py lignes 1115-1170
class BBIABehaviorManager:
    def record_behavior_movement(self, behavior_name: str, duration: float = 3.0):  # ‚úÖ Impl√©ment√©
        robot.start_recording()
        # ... ex√©cution comportement ...
        move = robot.stop_recording()
        self.saved_moves[behavior_name] = move

    def play_saved_behavior(self, behavior_name: str, use_async: bool = True):  # ‚úÖ Impl√©ment√©
        if behavior_name in self.saved_moves:
            move = self.saved_moves[behavior_name]
            if use_async and hasattr(robot, "async_play_move"):
                robot.async_play_move(move, play_frequency=100.0)  # ‚úÖ Non bloquant
            else:
                robot.play_move(move, play_frequency=100.0)  # ‚úÖ Bloquant

```

---

## ‚úÖ **STATUT D'IMPL√âMENTATION** (Oct / Nov. 2025)

### **Phase 1 : Int√©gration Media SDK** ‚úÖ **COMPL√âT√âE**

1. **`bbia_vision.py`** ‚úÖ **FAIT**
   - Lignes 126-137 : D√©tection automatique `robot.media.camera`
   - Fallback gracieux vers simulation si SDK non disponible
   - Support OpenCV pour webcam USB (fallback suppl√©mentaire)

2. **`bbia_audio.py`** ‚úÖ **FAIT**
   - Lignes 162-208 : Utilise `robot.media.record_audio()` avec 4 microphones
   - Fallback gracieux vers sounddevice
   - Support flag `BBIA_DISABLE_AUDIO` pour CI/headless

3. **`bbia_voice.py`** ‚úÖ **FAIT**
   - Lignes 259-342 : Utilise `robot.media.speaker` et `robot.media.play_audio()`
   - Priorit√© : `media.play_audio()` ‚Üí `media.speaker.play_file()` ‚Üí pyttsx3
   - Support backends TTS avanc√©s (Kitten, Kokoro, NeuTTS)

### **Phase 2 : Interpolation Adaptative** ‚úÖ **COMPL√âT√âE**

**Fichier :** `bbia_integration.py` (lignes 289-305)

‚úÖ **Impl√©ment√©** : Mapping complet √©motion ‚Üí interpolation avec 12 √©motions :

- CARTOON : happy, excited, surprised, angry, proud
- EASE_IN_OUT : calm, sad, nostalgic, fearful
- MIN_JERK : neutral, curious, determined

### **Phase 3 : Enregistrement Comportements** ‚úÖ **COMPL√âT√âE**

**Fichier :** `bbia_behavior.py` (lignes 1115-1170)

‚úÖ **Impl√©ment√©** :

- `BBIABehaviorManager.record_behavior_movement()` : Enregistre comportements (ligne 1115)
- `BBIABehaviorManager.play_saved_behavior()` : Rejoue avec support async (ligne 1170)
- Biblioth√®que `saved_behaviors` pour r√©utilisation mouvements

---

## üìà **B√âN√âFICES ATTENDUS**

### **Performance**

- ‚úÖ Vision temps r√©el (au lieu de simulation)
- ‚úÖ Audio qualit√© hardware (4 mics directionnels)
- ‚úÖ Synth√®se vocale optimis√©e (5W hardware)

### **Expressivit√©**

- ‚úÖ Mouvements plus expressifs avec `CARTOON`
- ‚úÖ Transitions plus douces avec `EASE_IN_OUT`
- ‚úÖ R√©utilisation de mouvements complexes

### **Robustesse**

- ‚úÖ Hardware optimis√© vs logiciel g√©n√©rique
- ‚úÖ Annulation de bruit automatique
- ‚úÖ Stream temps r√©el pour r√©activit√©

---

## ‚úÖ **VALIDATION FINALE**

Toutes les am√©liorations sont **d√©j√† impl√©ment√©es et op√©rationnelles** ‚úÖ

### **√âtat actuel :**

- ‚úÖ Phase 1 (Media SDK) : **COMPL√âT√âE** - Tous les modules utilisent `robot.media`
- ‚úÖ Phase 2 (Interpolation) : **COMPL√âT√âE** - Mapping √©motion ‚Üí technique impl√©ment√©
- ‚úÖ Phase 3 (Record/Replay) : **COMPL√âT√âE** - `BBIABehaviorManager` avec support async

### **Validation code :**

- ‚úÖ Backend expose `robot.media` et utilis√© partout
- ‚úÖ Fallbacks gracieux en place (simulation, sounddevice, pyttsx3)
- ‚úÖ Architecture modulaire avec int√©gration compl√®te
- ‚úÖ Tests cr√©√©s : `test_sdk_media_integration.py`, `test_emotion_interpolation_mapping()`

### **Restant √† faire (optionnel, non critique) :**

- ‚ö†Ô∏è Module IO SDK (`robot.io.get_camera_stream()`, `robot.io.get_audio_stream()`) : Disponible via SDK mais non utilis√©
  - **D√©cision** : Non impl√©ment√© car code actuel (`robot.media.camera.get_image()` + captures p√©riodiques) fonctionne parfaitement
  - Opportunit√© future : Streaming temps r√©el continu (n√©cessiterait refactor significatif pour b√©n√©fice marginal)
  - Priorit√© : **Tr√®s basse** (non bloquant pour robot r√©el)

**Recommandation :** ‚úÖ Toutes les am√©liorations prioritaires sont compl√©t√©es. Le syst√®me utilise pleinement le hardware Reachy Mini avec fallbacks robustes.
