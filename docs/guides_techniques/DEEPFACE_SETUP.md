# Guide DeepFace - Reconnaissance Visage Personnalis√©e + √âmotions

**Date** : 2025-01-30  
**Compatibilit√©** : ‚úÖ SDK Reachy Mini officiel, open-source, gratuit

---

## üéØ Qu'est-ce que DeepFace ?

**DeepFace** permet √† BBIA de :
- ‚úÖ **Reconna√Ætre des personnes sp√©cifiques** (famille, amis) - "Bonjour Alice !"
- ‚úÖ **D√©tecter les √©motions** sur visages (happy, sad, angry, etc.)
- ‚úÖ **Compatible SDK Reachy Mini** (pas de conflit)
- ‚úÖ **Open-source et gratuit** (100% gratuit)

---

## üì¶ Installation

### Option 1 : Dans venv-vision-py310 (recommand√©)

```bash
# Activer venv vision
source venv-vision-py310/bin/activate

# Installer DeepFace
pip install -r requirements/requirements-deepface.txt

# Ou directement
pip install deepface onnxruntime
```

### Option 2 : Dans venv principal (si pas de conflit)

```bash
source venv/bin/activate
pip install deepface onnxruntime
```

**Note** : `onnxruntime` est recommand√© pour Raspberry Pi 5 (plus rapide que TensorFlow)

---

## üöÄ Utilisation Rapide

### 1. Enregistrer une personne (famille, ami)

```bash
# Prendre une photo claire (visage bien visible)
python scripts/test_deepface.py --register photo_alice.jpg --name Alice
```

**R√©sultat** : La photo est copi√©e dans `faces_db/Alice/`

### 2. Reconna√Ætre une personne

```bash
# Avec webcam ou image
python scripts/test_deepface.py --recognize frame.jpg
```

**R√©sultat** :
```
‚úÖ Personne reconnue:
   ‚Ä¢ Nom: Alice
   ‚Ä¢ Confiance: 87%
   ‚Ä¢ Distance: 0.132
```

### 3. D√©tecter l'√©motion

```bash
python scripts/test_deepface.py --emotion photo.jpg
```

**R√©sultat** :
```
‚úÖ √âmotion d√©tect√©e:
   ‚Ä¢ √âmotion dominante: happy
   ‚Ä¢ Confiance: 94%

   Scores d√©taill√©s:
      ‚Ä¢ happy: 94.2%
      ‚Ä¢ neutral: 3.1%
      ‚Ä¢ sad: 1.2%
      ‚Ä¢ ...
```

---

## üîß Int√©gration dans BBIA

### Automatique avec BBIAVision

DeepFace est **automatiquement int√©gr√©** dans `BBIAVision` :

```python
from bbia_sim.bbia_vision import BBIAVision

vision = BBIAVision()

# Scan environnement (avec DeepFace automatique si disponible)
result = vision.scan_environment()

for face in result["faces"]:
    print(f"Personne: {face['name']}")  # "Alice" au lieu de "humain"
    print(f"√âmotion: {face['emotion']}")  # "happy", "sad", etc.
    print(f"Confiance √©motion: {face['emotion_confidence']}")
```

**Ce qui se passe** :
1. MediaPipe d√©tecte le visage (rapide)
2. DeepFace reconna√Æt la personne (si enregistr√©e)
3. DeepFace d√©tecte l'√©motion
4. R√©sultat enrichi retourn√©

---

## ‚öôÔ∏è Configuration

### Variables d'environnement

```bash
# Chemin base de donn√©es visages (d√©faut: faces_db)
export BBIA_FACES_DB="faces_db"

# Mod√®le DeepFace (d√©faut: VGG-Face)
# Options: VGG-Face, Facenet, OpenFace, DeepID, ArcFace
export BBIA_DEEPFACE_MODEL="VGG-Face"
```

### Mod√®les DeepFace

**VGG-Face** (d√©faut) :
- ‚úÖ Bon √©quilibre vitesse/pr√©cision
- ‚úÖ Compatible Raspberry Pi 5 (avec ONNX)

**ArcFace** (plus pr√©cis) :
- ‚ö†Ô∏è Plus lent, mais meilleure pr√©cision
- ‚ö†Ô∏è N√©cessite plus de RAM

**Recommandation RPi 5** : Garder `VGG-Face` + backend `opencv` + ONNX

---

## üìÅ Structure Base de Donn√©es

```
faces_db/
‚îú‚îÄ‚îÄ Alice/
‚îÇ   ‚îú‚îÄ‚îÄ photo_alice.jpg
‚îÇ   ‚îî‚îÄ‚îÄ photo_alice_2.jpg
‚îú‚îÄ‚îÄ Maman/
‚îÇ   ‚îî‚îÄ‚îÄ photo_maman.jpg
‚îî‚îÄ‚îÄ Papa/
    ‚îî‚îÄ‚îÄ photo_papa.jpg
```

**Format** : Un dossier par personne, photos √† l'int√©rieur

---

## üéØ Cas d'Usage

### Exemple 1 : BBIA reconna√Æt la famille

```python
from bbia_sim.bbia_vision import BBIAVision
from bbia_sim.bbia_voice import dire_texte

vision = BBIAVision()
result = vision.scan_environment()

for face in result["faces"]:
    if face["name"] != "humain":  # Personne reconnue
        dire_texte(f"Bonjour {face['name']} !", robot_api=None)
        
        # Adapter comportement selon √©motion
        if face["emotion"] == "happy":
            dire_texte("Tu as l'air heureux aujourd'hui !", robot_api=None)
        elif face["emotion"] == "sad":
            dire_texte("Tu as l'air triste, veux-tu parler ?", robot_api=None)
```

### Exemple 2 : Enregistrer depuis webcam

```python
import cv2
from bbia_sim.face_recognition import create_face_recognition

face_rec = create_face_recognition()

# Capturer photo depuis webcam
cap = cv2.VideoCapture(0)
ret, frame = cap.read()
cap.release()

# Sauvegarder temporairement
cv2.imwrite("temp_face.jpg", frame)

# Enregistrer
face_rec.register_person("temp_face.jpg", "Alice")
```

---

## üêõ D√©pannage

### Erreur : "DeepFace non disponible"

**Solution** :
```bash
source venv-vision-py310/bin/activate
pip install deepface onnxruntime
```

### Erreur : "No face detected"

**Solutions** :
- Photo trop petite ou floue
- Visage de profil
- √âclairage insuffisant
- Utiliser `--enforce-detection=False` (par d√©faut)

### Performance lente sur RPi 5

**Solutions** :
- Utiliser backend `opencv` (plus rapide que `retinaface`)
- Utiliser mod√®le `VGG-Face` (plus l√©ger)
- Installer `onnxruntime` (plus rapide que TensorFlow)

---

## üìö R√©f√©rences

- **DeepFace GitHub** : https://github.com/serengil/deepface
- **Documentation** : https://github.com/serengil/deepface/blob/master/README.md
- **Mod√®les disponibles** : VGG-Face, Facenet, OpenFace, DeepID, ArcFace

---

## ‚úÖ Checklist Installation

- [ ] DeepFace install√© (`pip install deepface`)
- [ ] ONNX backend install√© (`pip install onnxruntime`) - optionnel mais recommand√©
- [ ] Base de donn√©es cr√©√©e (`faces_db/`)
- [ ] Au moins une personne enregistr√©e (`--register`)
- [ ] Test reconnaissance OK (`--recognize`)
- [ ] Test √©motion OK (`--emotion`)

**Une fois tout √ßa fait, BBIA peut reconna√Ætre ta famille et leurs √©motions !** üéâ

