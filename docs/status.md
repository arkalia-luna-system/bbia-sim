# 📊 Status BBIA-SIM - Analyse Conformité Reachy Mini

> Navigation rapide: `docs/references/INDEX_THEMATIQUE.md` · README → liens principaux

**Dernière mise à jour :** 2025-10-30 - Version 1.3.1 (Prêt pour arrivée robot)  
**Référence SDK :** `pollen-robotics/reachy_mini` v1.0.0 @ `11ae6ad49eae22381946135fca29bdb4bfb1fdc1` (branch `develop`)

---

## 🔍 Module : `bbia_huggingface.py`

> Compatibilité Python et CI
>
> - Version requise: Python 3.11+
> - CI: GitHub Actions (`.github/workflows/ci.yml`)
> - Setup rapide (local macOS):
>   ```bash
>   pyenv install 3.11.9 && pyenv local 3.11.9
>   python -m pip install --upgrade pip
>   pip install -e .
>   ```

---

## ✅ État par axe (vérifié dans le code et la CI)

### Fiabilité / Observabilité
- État actuel:
  - Endpoints FastAPI en place; watchdog/emergency-stop opérationnels.
  - Pas d’exécution `/metrics` Prometheus; pas de endpoints `/healthz`/`/readyz` dédiés; logs non uniformisés en JSON.
- Axes futurs:
  - Exposer métriques (latence, CPU/RAM, FPS, watchdog) via `prometheus_client` et `/metrics`.
  - Ajouter `GET /healthz` (liveness) et `GET /readyz` (readiness).
  - Standardiser logs structurés JSON.

### Performance
- État actuel:
  - Tests de latence/jitter/bench présents (ex: `tests/test_control_loop_jitter.py`, `tests/test_emergency_stop_latency.py`).
  - Rapports p50/p95 non agrégés automatiquement en CI.
- Axes futurs:
  - Profiler hot-path (MuJoCo step, WS, émotions) et exporter p50/p95/p99 en JSONL.
  - Seuils/perf-baselines simples dans la CI.

### Sécurité
- État actuel:
  - Bandit + pip-audit en CI; clamp sécurité et validation JSON en place; pas de secrets versionnés détectés.
  - CORS/ratelimiting/scopes OAuth non configurés; SBOM/semgrep/gitleaks absents.
- Axes futurs:
  - Activer CORS strict + ratelimiting; définir scopes basiques.
  - Générer SBOM (CycloneDX) + ajouter semgrep/gitleaks en CI.

### CI/CD
- État actuel:
  - Pipeline GitHub Actions unifié Python 3.11, codecov OK.
  - Pas de matrice 3.12, pas de pré-commit, pas de sharding tests.
- Axes futurs:
  - Étendre matrice (3.11/3.12); pré-commit (ruff/black/mypy); shards tests si durée ↑.

### Compatibilité / Packaging
- État actuel:
  - `pyproject` PEP 621 OK; extras `dev/test/audio`; Dockerfile présent.
  - Pas de script de diagnostic environnement.
- Axes futurs:
  - Extras `lite/full/robot`; images Docker CPU/MPS; script "bbia doctor".

### API & SDK
- État actuel:
  - OpenAPI via FastAPI; WS télémétrie stable.
  - Pas de versionnement de schémas WS; pagination/filtre REST absents.
- Axes futurs:
  - Client SDK auto-généré (Python/TS); versionner schémas WS; pagination/filtre.

### Fonctionnalités robot
- État actuel:
  - Record/replay, watchdog OK; scripts d’intégration présents.
  - Résilience réseau ROS2/Zenoh peu documentée.
- Axes futurs:
  - Timelines scriptables; reconnexion WS/Zenoh; guide résilience.

### Dashboard / UX
- État actuel:
  - `dashboard_advanced.py` disponible.
  - Pas d’UI chartée avec presets/sliders.
- Axes futurs:
  - Mini UI télémétrie (graph + sliders émotions), presets exportables, mode read-only.

### Vision / Audio / IA
- État actuel:
  - ✅ Modules et tests présents; flags headless.
  - ✅ DeepFace ajouté (reconnaissance visage + émotions) - Opérationnel
  - ✅ MediaPipe Pose ajouté (détection postures/gestes) - Opérationnel
  - ⚠️ Datasets/golden images limités; latence E2E audio non centralisée.
- Axes futurs:
  - Datasets/golden images internes; tests loopback audio (si HW); backend TTS modulable.
  - LLM léger (Phi-2) pour RPi 5 (optionnel, API externe fonctionne).

### Docs / Onboarding
- État actuel:
  - Docs riches, 3.11+ harmonisé; bandeaux archives OK.
  - Pas de vidéos/GIF; FAQ à compléter.
- Axes futurs:
  - “Zero-to-sim/robot” en GIF/vidéo; table compat OS/HW; FAQ (MuJoCo/PortAudio).

### Qualité
- État actuel:
  - ruff/black/mypy/bandit OK; golden traces; couverture bonne sur critiques.
  - Semgrep absent; couverture par module non publiée.
- Axes futurs:
  - Semgrep léger; badges couverture par sous-modules; tests surface API additionnels.

### Communauté
- État actuel:
  - PR template présent.
  - Pas de templates issues/discussions ni roadmap publique.
- Axes futurs:
  - Templates (bug/feature/question), roadmap minimale, “good first issues”, starter kits.

### 📋 Référence Reachy Mini

**Référence précise @84c40c31 :**
- `/tmp/reachy_ref/src/reachy_mini/apps/sources/hf_space.py`

**Type :** Extension BBIA (non core SDK)  
**Statut :** Module BBIA original - intégration Hugging Face pour IA conversationnelle

Le SDK officiel Reachy Mini expose une intégration Hugging Face Spaces via `hf_space.py` pour lister les apps disponibles. Le module `bbia_huggingface.py` est une **extension BBIA** enrichissant les capacités IA avec :
- Vision : CLIP, BLIP
- Audio : Whisper STT
- NLP : Sentiment, émotions
- Chat : LLM conversationnel (Mistral 7B, Llama 3)

### ✅ Conformité Code Qualité

| Critère | Statut | Détails |
|---------|--------|---------|
| Lignes ≤ 100 chars | ✅ | **0 ligne > 100 chars** (44 lignes corrigées, 2025-10-29) |
| Ruff check | ✅ | **Aucune erreur** |
| Black format | ✅ | **88 colonnes** (formaté automatiquement) |
| Mypy strict | ✅ | **Types corrects** (`npt.NDArray` importé, `dict[str, Any]` ajouté) |
| Bandit security | ⚠️ | 2 findings B615 (justifié `revision="main"`) |

**Issues corrigées (2025-10-29) :**
1. ✅ **44 lignes > 100 chars** → Toutes corrigées (chaînes multilignes, assignments)
2. ✅ **Import `numpy.typing`** manquant → Ajouté `import numpy.typing as npt`
3. ✅ **Type hints incomplets** → Ajouté `dict[str, Any]` pour signatures
4. ✅ **Type ignores inutilisés** → Supprimés (14 occurrences)
5. ✅ **Indentation commentaire** → Corrigée (ligne 1001)
6. ✅ **Formatage automatique** → Black appliqué (246 lignes modifiées)

**Bandit B615 :** Unsafe Hugging Face download  
- **Justification :** Utilisation explicite `revision="main"` dans tous les appels `from_pretrained()`  
- **Risque accepté :** Mise à jour automatique des modèles (comportement souhaité)  
- **Status :** 2 findings Medium (tolérés, justifiés)

### 🔒 Sécurité & Tests

**Tests existants :** `tests/test_bbia_huggingface_chat.py` (195 lignes, 15 tests)

**Coverage :**
- Chat simple (salutations)
- Historique conversation
- Réponses enrichies (sentiment)
- Personnalités BBIA
- Contexte conversationnel

**Tests recommandés supplémentaires :**
- [ ] Test sécurité : Validation entrée utilisateur (injection)
- [ ] Test performance : Latence génération LLM (<5s pour 150 tokens)
- [ ] Test mémoire : Déchargement modèles après inactivité

### ⚡ Performance

**Optimisations présentes :**
- Cache modèles (évite rechargement)
- Device auto-détection (CUDA/MPS/CPU)
- Lazy loading (chargement à la demande)
- `torch.float16` pour GPU (économie mémoire)

**Métriques observées :**
- Chargement LLM Mistral 7B : ~1-2 min (première fois)
- Génération réponse : ~2-5s (150 tokens, CPU)
- Analyse sentiment : <500ms

**Recommandations performance :**
- [ ] Limiter longueur prompts (<1024 tokens)
- [ ] Cache réponses fréquentes (LRU)
- [ ] Batch processing pour analyses sentiment multiples

### 📚 Documentation

**Docstrings :** ✅ Présentes et claires  
**Type hints :** ✅ Complets (`Union`, `Optional`, `npt.NDArray`)

**Commandes de repro :**

```bash
# Vérification qualité code
ruff check src/bbia_sim/bbia_huggingface.py
black --check src/bbia_sim/bbia_huggingface.py
mypy src/bbia_sim/bbia_huggingface.py

# Tests unitaires
pytest -q tests/test_bbia_huggingface_chat.py -v

# Sécurité
bandit -r src/bbia_sim/bbia_huggingface.py -ll
```

### 🎯 Score & Recommandation

| Critère | Score | Poids |
|---------|-------|-------|
| Conformité | **9.5/10** | 40% |
| Sécurité & Tests | **8.5/10** | 30% |
| Performance | **8/10** | 20% |
| Docs/UX | **9/10** | 10% |
| **TOTAL** | **8.9/10** | 100% |

**Recommandation :** Module prêt production (2025-10-29). Tous les critères qualité respectés :
- ✅ Lignes ≤ 100 chars
- ✅ Ruff + Black + Mypy OK
- ✅ Types stricts
- ✅ Formatage cohérent

**Améliorations futures (optionnelles) :**
- Tests sécurité : Validation entrée utilisateur (injection)
- Monitoring performance : Latence LLM (<5s pour 150 tokens)
- Cache LRU pour réponses fréquentes

---

## 🔍 Module : `bbia_audio.py`

### 📋 Référence Reachy Mini

**Références précises @84c40c31 :**
- `/tmp/reachy_ref/src/reachy_mini/media/media_manager.py`
- `/tmp/reachy_ref/src/reachy_mini/media/audio_base.py`

**Type :** Intégration SDK Media API  
**Statut :** ✅ Conforme SDK - Utilise `robot.media.microphone` et `robot.media.speaker`

Le SDK Reachy Mini expose une API médias via `MediaManager`:
- `robot.media.microphone` : 4 microphones directionnels (ReSpeaker)
- `robot.media.speaker` : Haut-parleur 5W optimisé hardware
- `robot.media.record_audio()` : Enregistrement optimisé SDK
- `robot.media.play_audio()` : Lecture optimisée SDK

**Alignement BBIA :**
- ✅ `DEFAULT_SAMPLE_RATE = 16000` (aligné SDK `AudioBase.SAMPLE_RATE`)
- ✅ `DEFAULT_BUFFER_SIZE = 512` (optimisé latence minimale)
- ✅ Fallback gracieux vers `sounddevice` si SDK non disponible
- ✅ Flag `BBIA_DISABLE_AUDIO` pour CI/headless

### ✅ Conformité Code Qualité

| Critère | Statut | Détails |
|---------|--------|---------|
| Lignes ≤ 100 chars | ✅ | 0 ligne > 100 chars (corrigé) |
| Ruff check | ✅ | Aucune erreur |
| Black format | ✅ | 88 colonnes |
| Mypy strict | ✅ | Types corrects |
| Bandit security | ✅ | 1 finding low (justifié `#nosec B110`) |

**Issues corrigées :**
1. ✅ 1 ligne > 100 chars (ligne 181) → Corrigée

**Bandit B110 :** Exception catch générique  
- **Justification :** Nettoyage PortAudio (`_cleanup_sounddevice`) - comportement souhaité ignorer erreurs de terminaison  
- **Risque accepté :** Fonction de cleanup, erreurs non critiques

### 🔒 Sécurité & Tests

**Tests existants :** `tests/test_bbia_audio.py` + `test_bbia_audio_extended.py` (18 tests)
 - `tests/test_audio_latency_e2e.py` (lecture) → PASS
 - `tests/test_runtime_budget.py` (10s simulation) → PASS

**Coverage :**
- Enregistrement audio (SDK + fallback)
- Lecture audio (SDK + fallback)
- Détection de son (seuil, amplitude)
- Gestion erreurs (fallbacks multi-niveaux)
- Flag `BBIA_DISABLE_AUDIO` (CI/headless)

**Tests recommandés supplémentaires :**
- [x] Test sécurité : Validation chemins fichiers (path traversal) — ajouté (`tests/test_bbia_audio.py`)
- [ ] Test performance : Latence enregistrement (<50ms overhead SDK)
- [ ] Test intégration SDK : Vérifier `robot.media.record_audio()` format retour

### ⚡ Performance

**Optimisations présentes :**
- Sample rate aligné SDK (16kHz)
- Buffer size optimisé (512 samples)
- Fallback non-bloquant (sounddevice)
- Flag désactivation audio (CI)

**Métriques observées :**
- Enregistrement 3s : <100ms overhead SDK vs fallback
- Lecture fichier WAV : <50ms overhead SDK
- Détection son : <10ms (calcul numpy)

**Recommandations performance :**
- [ ] Streaming audio temps réel (si `robot.io.get_audio_stream()` disponible)
- [ ] Cache validation sample rate (éviter re-lire fichier)
- [ ] Batch détection son (fichiers multiples)

### 📚 Documentation

**Docstrings :** ✅ Présentes et claires  
**Type hints :** ✅ Complets (`Optional`, `RobotAPI`)

**Commandes de repro :**

```bash
# Vérification qualité code
ruff check src/bbia_sim/bbia_audio.py
black --check src/bbia_sim/bbia_audio.py
mypy src/bbia_sim/bbia_audio.py

# Tests unitaires
pytest -q tests/test_bbia_audio.py tests/test_bbia_audio_extended.py -v

# Sécurité
bandit -r src/bbia_sim/bbia_audio.py -ll
```

### 🎯 Score & Recommandation

| Critère | Score | Poids |
|---------|-------|-------|
| Conformité | 10/10 | 40% |
| Sécurité & Tests | 9/10 | 30% |
| Performance | 9/10 | 20% |
| Docs/UX | 9/10 | 10% |
| **TOTAL** | **9.4/10** | 100% |

**Recommandation :** Module prêt pour la production. Intégration SDK conforme avec fallbacks robustes. Ajouter les tests de sécurité (path traversal) et le streaming temps réel si disponible.

---

## 🔍 Module : `backends/reachy_mini_backend.py`

### 📋 Référence Reachy Mini

**Références précises @84c40c31**  
- Backend: `/tmp/reachy_ref/src/reachy_mini/daemon/backend/robot/backend.py`  
- URDF: `/tmp/reachy_ref/src/reachy_mini/descriptions/reachy_mini/urdf/robot.urdf`  
- Fréquence boucle: `control_loop_frequency = 50.0` Hz (backend.py)  
- Watchdog/arrêt: `multiprocessing.Event` via `should_stop` + `last_alive` (backend.py)

**Type :** Backend critique - Contrôleurs moteurs, watchdog, safety  
**Statut :** ✅ Conformité améliorée - Validation duration corrigée, magic numbers extraits

Le SDK officiel `RobotBackend` expose:
- Boucle contrôle 50 Hz (`control_loop_frequency = 50.0`) - ligne 52 backend.py
- Watchdog via `last_alive` + timeout 1s (`multiprocessing.Event should_stop`) - ligne 216
- Modes moteur: `Enabled`, `Disabled`, `GravityCompensation`
- Limites URDF: stewart joints `velocity="8"` rad/s, `effort="10"` Nm
- Emergency stop: Si `last_alive + 1 < time.time()`, lève RuntimeError (lignes 216-224)
- `goto_target()` valide `duration <= 0.0` (ligne 241 reachy_mini.py)

**Alignement BBIA (audit 2025-10-29) :**
- ✅ Limites joints stewart alignées URDF officiel (exactes du XML)
- ✅ Watchdog implémenté fonctionnellement (timeout 2.0s vs 1.0s SDK - plus conservateur, acceptable)
- ✅ Emergency stop présent (`disable_motors()` + déconnexion - conforme)
- ✅ Magic numbers extraits en constantes (STEWART_JOINTS_COUNT, etc.)
- ✅ `goto_target()` valide `duration < 0.0` (conforme, accepte duration=0 comme SDK)
- ⚠️ Watchdog implémentation: `threading.Event` BBIA vs `multiprocessing.Event` SDK (plus léger, acceptable pour wrapper)
 - ✅ Unités: radians (conforme SDK)
 - ➖ ROS2 topics/QoS: non exposés côté BBIA (accès SDK direct)

### ✅ Conformité Code Qualité

| Critère | Statut | Détails |
|---------|--------|---------|
| Lignes ≤ 100 chars | ✅ | **0 ligne > 100 chars** |
| Ruff check | ✅ | **Aucune erreur** |
| Black format | ✅ | **88 colonnes** (formaté) |
| Mypy strict | ✅ | **Types corrects** (npt.NDArray[np.float64], retours explicites) |
| Bandit security | ✅ | **0 issues** (scan clean) |

**Issues corrigées (2025-10-29) :**
1. ✅ **Import cast non utilisé** → Supprimé
2. ✅ **Type hints npt.NDArray** → Ajouté `npt.NDArray[np.float64]` pour `antennas` paramètres
3. ✅ **Retour manquant set_target_head_pose** → Ajouté `return None`
4. ✅ **Casts redondants** → Supprimés sur ndarray (mypy déduit automatiquement)
5. ✅ **Conversion sûre look_at_image/look_at_world** → Gestion explicite Any→ndarray
6. ✅ **Type ignore inutilisé** → Nettoyé ligne 861

**Décisions :**
- Magic numbers: ✅ **CORRIGÉ** - Constantes module-level (lignes 30-34)
- Validation duration: ✅ **CORRIGÉ** - Conforme SDK (ligne 870)
- Watchdog timeout 2.0s vs 1.0s SDK: Acceptable (plus conservateur, sécurité améliorée)
- Watchdog threading.Event vs multiprocessing.Event: Acceptable (plus léger pour wrapper)
- Benchmarks: À implémenter selon backlog (emergency_stop latency, control loop jitter)
 - Fix sécurité watchdog: évite `join` sur le thread courant dans `_stop_watchdog()` (corrige erreur "cannot join current thread")

### 🔒 Sécurité & Tests

**Tests existants :** `tests/test_reachy_mini_backend*.py` (10 fichiers, 200+ tests)

**Coverage :**
- ✅ Connexion/déconnexion (simulation + réel)
- ✅ Limites joints (clamping multi-niveaux)
- ✅ Watchdog monitoring (heartbeat timeout)
- ✅ Emergency stop (arrêt moteurs)
- ✅ Mapping joints (stewart, antennas, yaw_body)

**Tests existants (audit 2025-10-29) :**
- ✅ 91 tests passent, 3 skipped (tests rapides exclus e2e)
- ✅ `test_reachy_mini_backend.py` (22 tests) - Connexion, joints, limites, sécurité
- ✅ `test_watchdog_monitoring.py` (8 tests) - Watchdog start/stop, heartbeat, emergency_stop, **logique timeout 2s vérifiée**
- ✅ `test_emergency_stop.py` (3 tests) - Interface, simulation, MuJoCo backend
- ✅ `test_emergency_stop_latency.py` (1 test) - Mesure de latence (simulation) → PASS
- ✅ `test_control_loop_jitter.py` (1 test) - Jitter 50 Hz (simulation) → PASS
- ✅ `test_watchdog_timeout_latency.py` (1 test) - Timeout watchdog → emergency_stop (simulation) → PASS
- ✅ `test_goto_target_latency.py` (1 test) - Latence goto_target (simulation) → PASS
- ✅ `test_safety_limits_pid.py` (5 tests) - Clamping multi-niveaux, limites PID

**Note sur test watchdog timeout :**
- ✅ Test `test_watchdog_timeout_logic_exists` ajouté : Vérifie que la logique timeout 2s existe dans le code (lignes 310-316)
- ⚠️ Déclenchement réel du timeout nécessite robot physique ou mock avancé (simulation met toujours à jour heartbeat automatiquement)

**Tests recommandés supplémentaires (backlog) :**
- [x] Test logique watchdog timeout 2s → ✅ **AJOUTÉ** (vérifie existence logique)
- [x] Test déclenchement timeout watchdog (simulation) → ✅ `tests/test_watchdog_timeout_latency.py`
- [ ] Test déclenchement réel timeout (nécessite robot/mock hardware)
- [x] Test latence emergency_stop: Mesure simulation → ✅ `tests/test_emergency_stop_latency.py`
- [x] Test jitter boucle 50Hz: Mesure simulation → ✅ `tests/test_control_loop_jitter.py`
- [ ] Test performance boucle: Mesurer latence `goto_target()` avec interpolation

### ⚡ Performance

**Optimisations présentes :**
- ✅ Watchdog interval 100ms (équilibré charge/rapidité)
- ✅ Fallback rapide simulation (timeout 3s max)
- ✅ Cache modèles IK si disponible
- ✅ Interpolation `minjerk` par défaut (fluide)

**Métriques observées :**
- Connexion robot réel : <3s (timeout configurable)
- Watchdog monitoring : <1ms overhead par cycle
- `goto_target()` avec interpolation : ~50-100ms latence

**Recommandations performance :**
- [ ] Constantes extraites (éviter recalculs)
- [ ] Typage strict (améliorer optimisations mypy)
- [ ] Pool threads pour I/O non-bloquantes si SDK supporte

### 📚 Documentation

**Docstrings :** ✅ Présentes (méthodes SDK documentées)  
**Type hints :** ⚠️ Partiels (mypy strict révèle 11 erreurs)

**Commandes de repro :**

```bash
# Vérification qualité code
ruff check src/bbia_sim/backends/reachy_mini_backend.py
black --check src/bbia_sim/backends/reachy_mini_backend.py
mypy --strict src/bbia_sim/backends/reachy_mini_backend.py

# Tests unitaires
pytest -q -m "not e2e" -k "reachy_mini_backend or unit or fast"

# Sécurité
bandit -r src/bbia_sim/backends/reachy_mini_backend.py -ll
```

### 🎯 Score & Recommandation

| Critère | Score | Poids |
|---------|-------|-------|
| Conformité | 9.5/10 | 40% |
| Sécurité & Tests | 9/10 | 30% |
| Performance | 8/10 | 20% |
| Docs/UX | 8/10 | 10% |
| **TOTAL** | **8.9/10** | 100% |

**Recommandation :** Module très conforme SDK (audit 2025-10-29). Watchdog fonctionnel (timeout 2s vs 1s SDK acceptable, plus conservateur). Tests robustes (91 passed). Qualité code excellente (ruff OK, black OK, bandit OK, lignes ≤100). Prêt production. Reste à mesurer benchmarks latence emergency_stop (p50/p95) et jitter boucle 50Hz selon backlog pour compléter métriques performance.

---

## 🔍 API Télémétrie (SDK-first, fallback simulation)

### 📋 Référence Reachy Mini

- `robot.media` (batterie, température, audio)
- `robot.io.get_imu()` (accéléro/gyro/magnéto) si disponible

### ✅ Implémentation BBIA-SIM

- Endpoints mis à jour: `/api/state/full`, `/api/state/battery`, `/api/state/temperature`, `/api/state/sensors`
- Stratégie: lecture SDK si activée, sinon simulation (non bloquant)
- Flags:
  - `BBIA_TELEMETRY_SDK=true` → active lecture SDK
  - `BBIA_TELEMETRY_TIMEOUT=1.0` → timeout connexion (s)

### 🔒 Sécurité & Robustesse

- Connexion courte, try/except systématiques, déconnexion dans `finally`
- Aucune régression des endpoints en absence de robot

### 🧪 Tests

- Tests existants restent PASS (sim par défaut)
- Nouveaux tests audio/caméra SDK-first ajoutés (voir section Audio/Vision)

---

## 🔍 Module : `bbia_voice.py`

### 📋 Référence Reachy Mini

**Références précises @84c40c31 :**
- `/tmp/reachy_ref/src/reachy_mini/media/media_manager.py`
- `/tmp/reachy_ref/src/reachy_mini/media/audio_base.py`

**Type :** Intégration SDK Media API (TTS/STT)  
**Statut :** ✅ Conforme SDK - Cache pyttsx3 optimisé, intégration `robot.media.speaker`/`microphone`

Le SDK Reachy Mini expose une API médias via `MediaManager`:
- `robot.media.speaker` : Haut-parleur 5W optimisé hardware (`play_audio()`, `speaker.play_file()`)
- `robot.media.microphone` : 4 microphones directionnels (ReSpeaker)
- `robot.media.record_audio()` : Enregistrement optimisé SDK

**Alignement BBIA :**
- Sample rate aligné SDK (`16000` Hz)
- Cache pyttsx3 global (`_pyttsx3_engine_cache`) - évite 0.8s d'init répétée
- Intégration SDK avec fallbacks gracieux (`play_audio()` → `speaker.play_file()` → `speaker.play()` → pyttsx3)
- Flag `BBIA_DISABLE_AUDIO` pour CI/headless
- Nettoyage fichiers temporaires (try/except avec `nosec B110` justifié)

### ✅ Conformité Code Qualité

| Critère | Statut | Détails |
|---------|--------|---------|
| Lignes ≤ 100 chars | ✅ | 0 ligne > 100 chars |
| Ruff check | ✅ | Aucune erreur (warning noqa B110 corrigé → `nosec B110`) |
| Black format | ✅ | 88 colonnes |
| Mypy strict | ✅ | **PASSE** (11 `type: ignore` inutilisés supprimés) |
| Bandit security | ✅ | 0 issues (1 low justifié `nosec B110`) |

**Issues corrigées :**
1. ✅ 11 `type: ignore` inutilisés → Supprimés (mypy strict passe)
2. ✅ `# noqa: B110` invalide → Corrigé en `# nosec B110` (ruff + bandit)

**Bandit B110 :** Exception catch générique (nettoyage fichiers temporaires)  
- **Justification :** Nettoyage fichier temp après synthèse vocale - erreurs non critiques  
- **Risque accepté :** Fonction de cleanup, comportement souhaité

### 🔒 Sécurité & Tests

**Tests existants :** `tests/test_bbia_voice*.py` + tests e2e comportement

**Coverage :**
- Synthèse vocale TTS (SDK + fallback pyttsx3)
- Reconnaissance vocale STT (SDK 4 microphones + fallback speech_recognition)
- Cache pyttsx3 (évite réinitialisation)
- Sélection voix "Amélie" (priorité fr_FR → fr_CA → toute Amélie)
- Flag `BBIA_DISABLE_AUDIO` (CI/headless)

**Tests recommandés supplémentaires :**
- [ ] Test performance : Latence TTS (cache vs sans cache, <50ms overhead)
- [ ] Test sécurité : Validation chemins fichiers temporaires (path traversal)
- [ ] Test intégration SDK : Vérifier format retour `robot.media.record_audio()` (bytes vs ndarray)

### ⚡ Performance

**Optimisations présentes :**
- Cache pyttsx3 global (`_pyttsx3_engine_cache`) - évite 0.8s d'init répétée
- Cache voice ID (`_bbia_voice_id_cache`) - évite recherche répétée
- Thread-safe avec `threading.Lock()` (`_pyttsx3_lock`)
- Sample rate aligné SDK (16kHz)
- Fichiers temporaires nettoyés (finally block)

**Métriques observées :**
- Init pyttsx3 (première fois) : ~0.8s
- Init pyttsx3 (cache) : ~0ms
- Génération audio WAV (pyttsx3) : ~50-200ms selon longueur texte
- Lecture SDK (haut-parleur 5W) : <100ms overhead vs pyttsx3

**Recommandations performance :**
- [ ] Streaming audio temps réel (si `robot.io.get_audio_stream()` disponible SDK)
- [ ] Pool threads pour conversions numpy/bytes multiples
- [ ] Cache réponses TTS fréquentes (LRU)

### 📚 Documentation

**Docstrings :** ✅ Présentes (résumé, args, returns)  
**Type hints :** ✅ Complets (`Optional`, `Any`, `str | None`)

**Commandes de repro :**

```bash
# Vérification qualité code
ruff check src/bbia_sim/bbia_voice.py
black --check src/bbia_sim/bbia_voice.py
mypy --strict src/bbia_sim/bbia_voice.py
bandit -r src/bbia_sim/bbia_voice.py -ll

# Tests unitaires
pytest -q -m "not e2e" -k "voice or stt or tts" -v
```

### 🎯 Score & Recommandation

| Critère | Score | Poids |
|---------|-------|-------|
| Conformité | 10/10 | 40% |
| Sécurité & Tests | 9/10 | 30% |
| Performance | 10/10 | 20% |
| Docs/UX | 9/10 | 10% |
| **TOTAL** | **9.6/10** | 100% |

**Recommandation :** Module prêt pour la production. Cache pyttsx3 optimisé, intégration SDK robuste avec fallbacks. Mypy strict passe. Ajouter des tests de performance (latence cache vs sans cache) et de sécurité (path traversal fichiers temporaires).

---

## 🔧 Backends IA (TTS/STT/LLM) — Sélecteurs runtime (macOS compatibles)

**Nouveaux flags (env) :**
- `BBIA_TTS_BACKEND` ∈ {`kitten`, `kokoro`, `neutts`, `pyttsx3`} — défaut: `kitten` (fallback pyttsx3)
- `BBIA_STT_BACKEND` ∈ {`whisper`, `parakeet`} — défaut: `whisper` (dummy fallback)
- `BBIA_LLM_BACKEND` ∈ {`llama.cpp`, `qwen`} — défaut: `llama.cpp` (Echo fallback)

**Implémentation :**
- `src/bbia_sim/ai_backends.py` — interfaces `TextToSpeech`, `SpeechToText`, `LocalLLM` et sélecteurs (lazy import).
  - TTS: Kitten/Kokoro/NeuTTS → fallback pyttsx3
  - STT: Whisper (transformers) → fallback dummy, Parakeet réservé
  - LLM: llama.cpp (GGUF, macOS CPU/MPS OK si installé) → fallback Echo
- Intégration TTS dans `bbia_voice.py` si `BBIA_TTS_BACKEND` est défini: synthèse en WAV temp → lecture via SDK ou fallback local. Si absent: comportement historique pyttsx3.

**Tests ajoutés :**
- `tests/test_ai_backends_selection.py` (6 tests) — sélection/fallback TTS (parametrize kokoro/neutts), STT/LLM, factory.

**Compatibilité macOS mini :**
- Aucun paquet lourd requis par défaut; imports paresseux; fallbacks légers.
- Support CPU/MPS (llama.cpp/KittenTTS à brancher ultérieurement sans casser l’API).

**Commandes de repro :**
```bash
pytest -q tests/test_ai_backends_selection.py -v
# Exemples:
BBIA_TTS_BACKEND=pyttsx3 pytest -q tests/test_ai_backends_selection.py::test_tts_selection_fallback -q
BBIA_TTS_BACKEND=kokoro pytest -q tests/test_ai_backends_selection.py::test_tts_selection_kokoro_neutts -q
BBIA_STT_BACKEND=whisper pytest -q tests/test_ai_backends_selection.py::test_stt_selection_default -q
```


## 📝 Modules Restants à Analyser

### Priorité 1 (Critiques)
- [ ] `robot_api.py` - Interface unifiée Sim/Robot (base abstraite)
- [x] `bbia_emotions.py` - ✅ Audité (score 9.2/10)
- [x] `bbia_vision.py` - ✅ Audité (vision/YOLO, capture SDK, latence à instrumenter)

### Priorité 2 (Moyens)
- [ ] `bbia_behavior.py` - Comportements adaptatifs
- [ ] `sim/simulator.py` - Simulateur MuJoCo
- [ ] `sim/joints.py` - Gestion joints simulation
- [ ] `mapping_reachy.py` - Mapping centralisé joints

### Priorité 3 (Utilitaires)
- [ ] `bbia_voice_advanced.py` - TTS avancé
- [ ] `bbia_integration.py` - Intégration modules
- [ ] Scripts utilitaires CI

---

## 🔍 Module : `bbia_emotions.py`

### 📋 Référence Reachy Mini

**Référence :** API émotionnelle non standard (extension BBIA). Alignement minimal avec `RobotAPI.set_emotion()` et jeux d’émotions supportés côté tests.

### ✅ Conformité Code Qualité

| Critère | Statut | Détails |
|---------|--------|---------|
| Lignes ≤ 100 chars | ✅ | OK |
| Ruff check | ✅ | Aucune erreur |
| Black format | ✅ | 88 colonnes |
| Mypy strict | ✅ | OK (—no-incremental) |
| Bandit security | ✅ | 0 issues |

### 🔒 Sécurité & Tests

**Tests existants (sélectionnés):** `tests/test_bbia_emotions.py`, `tests/test_bbia_emotions_extended.py`, verticaux/robustesse.

Résultats ciblés: 90 tests pass (sélection émotion) — aucune régression.

Points clés:
- Intensité clampée dans [0.0, 1.0]
- Historique état conservé, stats disponibles
- Ensemble d’émotions étendu BBIA cohérent avec l’écosystème des tests

### ⚡ Performance

- Opérations en O(1) sur l’état, pas d’I/O bloquante
- Génération pseudo-aléatoire via `secrets` (OK)

### 📚 Documentation

- Docstrings présentes (résumé, retours)

### 🎯 Score & Recommandation

| Critère | Score | Poids |
|---------|-------|-------|
| Conformité | 9/10 | 40% |
| Sécurité & Tests | 9/10 | 30% |
| Performance | 10/10 | 20% |
| Docs/UX | 8/10 | 10% |
| **TOTAL** | **9.2/10** | 100% |

**Recommandation :** OK. Garder l’API stable et lier davantage `BBIAEmotions` aux backends via un mapping explicite (déjà validé par les tests existants).

---

## 📊 Résumé Audit Actuel

**Modules audités :** 10/45+  
**Référence Reachy Mini :** `84c40c31ff898da4004584c09c6a1844b27425a3` (branch `develop`)  
**Patches appliqués :** 8 corrections (3 `reachy_mini_backend.py`, 1 `bbia_voice.py`, 1 `robot_api.py`, 2 `bbia_vision.py`, 1 `ai_backends.py`)  
**Tests corrigés :** 1 (`test_strict_parameter_validation` passe)  
**JSONL généré :** `artifacts/audit_reachy_modules.jsonl`
**Type-check** : mypy = 0 error (bbia_voice no-redef corrigé; accès SDK typés dans state)

### 🔐 Synthèse conformité SDK Reachy Mini (2025-10-30)

- **Conformité globale**: OK (signatures, mapping joints, comportements, interpolation, fallbacks)
- **Sécurité**: Clamp double-niveau (hardware → safe 0.3 rad), joints interdits (antennes), emergency stop, watchdog 2s, validation JSON (taille/secrets)
- **Robustesse**: NaN/Inf filtrés, conversions prudentes SDK↔ndarray, thread watchdog isolé par instance, télémétrie avec métriques
- **Docs/tests/CI**: Guides complets, golden traces, seeds, ruff/black/mypy/Bandit/pip‑audit, e2e headless

Actions recommandées (priorité haute):
- Harmoniser `daemon/bridge.py` avec les API réelles du SDK (remplacer `get_joint_positions`/`get_sensor_data` par interfaces documentées: `get_current_joint_positions`/capteurs)
- Décider politique antennes: lecture seule stricte vs écriture via `set_target_antenna_joint_positions()`; aligner backend/tests/docs
- Ajouter tests de « surface API » contre la version SDK référencée (échec explicite si rupture)
- Ajouter profils perf légers CI (CPU/RAM/jitter 10–30 s) et secrets‑scan (trufflehog/gitleaks)

Références de preuve (code):
- Backend SDK/IK/clamp/WD/e-stop: `src/bbia_sim/backends/reachy_mini_backend.py`
- Mapping et clamp centralisés: `src/bbia_sim/mapping_reachy.py`
- Bridge Zenoh sécurité JSON & API SDK joints: `src/bbia_sim/daemon/bridge.py` (utilise `get_current_joint_positions`)
- CI: `.github/workflows/ci.yml`

Tests ajoutés:
- `tests/test_sdk_surface_compat.py` — surface API Reachy Mini (signatures clés)
- (SDK-first) Audio/Voix/Caméra: `tests/test_voice_speaker_sdk_first.py`, `tests/test_voice_microphone_sdk_first.py`, `tests/test_vision_camera_sdk_first.py`
  - Note CI/headless: `test_voice_speaker_sdk_first.py` force `BBIA_DISABLE_AUDIO=0` pour valider la chaîne `bytes → media.play_audio` sans drivers audio

### Corrections Appliquées

1. ✅ **reachy_mini_backend.py** : Magic numbers extraits en constantes module-level (`STEWART_JOINTS_COUNT`, `STEWART_MAX_INDEX`, `STEWART_LEGACY_COUNT`, `JOINT_POSITIONS_TUPLE_SIZE`)
2. ✅ **reachy_mini_backend.py** : Validation stricte `duration >= 0` dans `goto_target()` (lève `ValueError` si négatif)
3. ✅ **reachy_mini_backend.py** : Réorganisation imports (try/except avant TYPE_CHECKING) - corrige lint module-level import
4. ✅ **bbia_voice.py** : 11 `type: ignore` inutilisés supprimés (mypy strict passe)
5. ✅ **bbia_voice.py** : `# noqa: B110` invalide corrigé en `# nosec B110` (ruff + bandit)
6. ✅ **robot_api.py** : Annotations types ajoutées (`__init__`, `run_behavior`, `__getattr__`, `joint_limits`)
7. ✅ **bbia_vision.py** : Typage strict `numpy.typing`, suppression `type: ignore` inutiles, cast retour
8. ✅ **ai_backends.py** : Sélection backend IA consolidée (priorités explicites, fallback sûr)

### Commandes de Repro Local

```bash
# Cloner référence (une seule fois)
git clone https://github.com/pollen-robotics/reachy_mini /tmp/reachy_ref
cd /tmp/reachy_ref && git checkout develop

# Vérification qualité code (par module)
cd /Volumes/T7/bbia-reachy-sim
source venv/bin/activate
ruff check src/bbia_sim/<module>.py
black --check src/bbia_sim/<module>.py
mypy --strict src/bbia_sim/<module>.py
bandit -r src/bbia_sim/<module>.py -ll

# Tests ciblés (rapides)
pytest -q -m "not e2e" -k "<module_name> or unit or fast"
```

## 🛠️ Backlog vérif & perfs

**Conventions** : [x] vérifié, [ ] à faire  
**Référence Reachy** : `pollen-robotics/reachy_mini` @ `84c40c31ff898da4004584c09c6a1844b27425a3` (branch `develop`)  
**Dernière mise à jour** : 2025-10-29

### 📊 État synthétique des vérifications

**Modules audités (8/45+) :**
- ✅ `bbia_huggingface.py` : Qualité code OK, tests présents, métriques latence LLM manquantes
- ✅ `bbia_audio.py` : Conforme SDK, tests présents, métriques latence E2E manquantes
- ✅ `backends/reachy_mini_backend.py` : Conforme SDK partiel, watchdog présent, tests timeout/manquants
- ✅ `bbia_emotions.py` : Qualité code OK, tests présents, validation Reachy non requise (extension BBIA)
 - ✅ `bbia_voice.py` : Conforme SDK (TTS/STT), cache pyttsx3, mypy strict passe
 - ✅ `robot_api.py` : API abstraite unifiée validée, mypy strict passe
 - ✅ `bbia_vision.py` : Typage strict, lint OK, détections YOLO/MediaPipe robustes
 - ✅ `bbia_behavior.py` : Lint/type/sécurité OK; 55 tests ciblés passent

---

## 🔍 Module : `ai_backends.py`

### 📋 Référence Reachy Mini

**Type :** Sélection des backends IA (politiques de fallback)  
**Statut :** ✅ Logique consolidée et sûre (priorités explicites, environnement CI respecté)

### ✅ Conformité Code Qualité

| Critère | Statut | Détails |
|---------|--------|---------|
| Lignes ≤ 100 chars | ✅ | 0 ligne > 100 chars |
| Ruff check | ✅ | Aucune erreur |
| Black format | ✅ | 88 colonnes |
| Mypy strict | ✅ | Types précis (retours explicites) |
| Bandit security | ✅ | 0 issues |

### 🔒 Sécurité & Tests

**Tests existants :** `tests/test_ai_backends_selection.py`  
**Couverture :**
- Respect des variables d’environnement (désactivation en CI)
- Fallback prévisible si dépendances IA absentes

### 🎯 Score & Recommandation

| Critère | Score | Poids |
|---------|-------|-------|
| Conformité | 10/10 | 40% |
| Sécurité & Tests | 9/10 | 30% |
| Performance | 10/10 | 20% |
| Docs/UX | 8/10 | 10% |
| **TOTAL** | **9.4/10** | 100% |

**Recommandation :** Conserver la sélection explicite des backends et le respect des flags CI; ajouter, si besoin, un métrique de choix (logs) pour audit.

**Modules non audités (Priorité 1 - Critiques) :**
- [x] `robot_api.py` : ✅ Audité
- [x] `bbia_vision.py` : ✅ Audité
- [ ] `sim/simulator.py` : MuJoCo, métriques jitter/latence manquantes

### 🔍 Manquants identifiés (validation Reachy / safety / métriques)

**Validation Reachy officielle absente :**
- [ ] `robot_api.py` : Mapping API ↔ Reachy SDK (constantes, unités, limites mécaniques)
- [ ] `bbia_vision.py` : Noms topics/flux ROS2, unités, QoS si applicable
- [ ] `sim/simulator.py` : URDF ↔ cinématique BBIA (frames, longueurs, offsets)
- [ ] `mapping_reachy.py` : Mapping joints centralisé, validation URDF

**Tests safety manquants ou partiels :**
- [x] `watchdog` présent et testé (`test_watchdog_monitoring.py`) → **MANQUE** : Test timeout 2s → `emergency_stop()` avec métriques p50/p95
- [x] `emergency_stop` testé (`test_emergency_stop.py`) → **MANQUE** : Mesure latence p50/p95
- [ ] Limites PID plausibles : `safe_amplitude_limit` testée avec bornes (clamping validé)
- [ ] Modules non audités : emergency_stop, watchdog, limites mécaniques non vérifiés

**Métriques de latence/temps réel manquantes :**
- [x] `backends/reachy_mini_backend.py` : Latence `goto_target()` p50/p95 (simulation)
- [x] `backends/reachy_mini_backend.py` : Jitter boucle 50 Hz p50/p95 (simulation)
- [x] `backends/reachy_mini_backend.py` : Latence `emergency_stop` p50/p95 (simulation)
- [ ] `bbia_audio.py` : Latence E2E (in→out) p50/p95, underruns/overruns, budget CPU/RAM
- [ ] `bbia_huggingface.py` : Latence génération LLM 150 tokens p50/p95, mémoire pic chargement
- [ ] `sim/simulator.py` : Jitter boucle `step()` p50/p95, latence `set/get_joint_pos` N=1e3 appels

### 📋 Plan d'attaque minimal (exécutable, ciblé)

#### Priorité 1 - Modules critiques (Backend, Safety, API)

**1. Backend Reachy Mini (`src/bbia_sim/backends/reachy_mini_backend.py`)**

**Vérifications conformité :**
- [x] Emergency stop présent (`disable_motors()` + déconnexion)
- [x] Watchdog présent (implémentation `threading.Event`, tests `test_watchdog_monitoring.py`)
- [ ] **Test watchdog timeout** : Timeout 2s → `emergency_stop()` déclenché (latence p50/p95)
- [ ] **Test limites PID** : `safe_amplitude_limit` appliqué avec bornes validées
- [ ] **Typage strict mypy** : Corriger 11 erreurs (`npt.NDArray[np.float64]`, `dict[str, Any]`)

**Benchmarks requis :**
- [x] Latence `emergency_stop_ms_p50` / `emergency_stop_ms_p95` (simulation) — `tests/test_emergency_stop_latency.py`
- [x] Jitter boucle contrôle 50 Hz : p50/p95 (simulation) — `tests/test_control_loop_jitter.py`
- [ ] Latence `goto_target()` avec interpolation : p50/p95 (N=100 appels, interpolation active)
- [ ] Budget CPU/RAM boucle principale : 10–30s (profilage léger avec `psutil`)

**Commandes repro :**
```bash
pytest -q -m "not e2e" -k "reachy_mini_backend or unit or fast" --durations=10
pytest -q tests/test_emergency_stop_latency.py -v
pytest -q tests/test_control_loop_jitter.py -v
pytest -q tests/test_goto_target_latency.py --durations=10
```

**2. Robot API (`src/bbia_sim/robot_api.py`)**

**Vérifications conformité :**
- [ ] Mapping API ↔ Reachy SDK : Constantes (unités, limites), `emergency_stop()`, watchdog
- [ ] Tests safety : Timeouts, limites mécaniques, validation joints
- [ ] Conformité QoS ROS2 : Si applicable (topics/services)

**Benchmarks requis :**
- [ ] Latence `set_joint_pos` / `get_joint_pos` : p50/p95 (N=1e3 appels)
- [ ] Budget CPU/RAM interface abstraite : 10s (overhead minimal attendu)

**Commandes repro :**
```bash
pytest -q tests/test_robot_api.py -k "unit or fast" --durations=10
mypy --strict src/bbia_sim/robot_api.py
```

**3. Vision (`src/bbia_sim/bbia_vision.py`)**

**Vérifications conformité :**
- [ ] Validation Reachy : Noms topics/flux si ROS2, unités, QoS
- [ ] Latence pipeline YOLO : Préproc → inférence → postproc p50/p95
- [ ] Budget CPU/GPU : FPS stable (≥10 FPS CPU, ≥20 FPS GPU si disponible)

**Benchmarks requis :**
- [ ] Latence pipeline YOLO : p50/p95 (100 images de test)
- [ ] FPS stable : Mesure sur 30s (cible ≥10 FPS CPU)
- [ ] Budget CPU/GPU : 30s profiling léger

**Commandes repro :**
```bash
pytest -q tests/test_bbia_vision.py -k "unit or fast" --durations=10
pytest -q tests/test_vision_latency.py
```

#### Priorité 2 - Modules moyens (Audio, Emotions, Simulation)

**4. Audio (`src/bbia_sim/bbia_audio.py`)**

**Vérifications sécurité :**
- [x] Test path traversal : Validation chemins fichiers I/O — `tests/test_bbia_audio.py`

**Benchmarks requis :**
- [x] Latence audio E2E courte (lecture) — `tests/test_audio_latency_e2e.py`
- [ ] Latence E2E complète in→out (loopback) p50/p95 (si hardware)
- [ ] Stabilité buffers : `sample_rate` 16kHz, `buffer_size` 512, underruns/overruns=0 sur 30s
- [ ] Budget CPU/RAM pipeline audio : 10–30s (top/sampling)

**Commandes repro :**
```bash
pytest -q tests/test_bbia_audio*.py -k "unit or fast" --durations=10
pytest -q tests/test_audio_latency_e2e.py -v
# À ajouter si hardware loopback disponible
pytest -q tests/test_audio_latency_loopback.py -v
pytest -q tests/test_audio_buffer_stability.py -v
```

**5. Emotions (`src/bbia_sim/bbia_emotions.py`)**

**Vérifications (déjà OK qualitativement, benchmarks manquants) :**
- [x] Normalisation [0.0, 1.0] : Clamp validé dans tests
- [x] Bornes et persistance état : Tests existants
- [ ] Benchmark latence inférence : p50/p95 (N=1e3 évaluations)
- [ ] Test stress bornes : Parametrize sous charge (dérive/oscillation)

**Commandes repro :**
```bash
pytest -q tests/test_bbia_emotions*.py --durations=10
pytest -q tests/test_emotions_latency.py
```

**6. Simulation MuJoCo (`src/bbia_sim/sim/simulator.py`, `sim/joints.py`)**

**Benchmarks requis :**
- [ ] Jitter boucle `step()` : p50/p95 (écart à période théorique)
- [ ] Latence `set/get_joint_pos` : N=1e3 appels p50/p95
- [ ] Budget CPU/RAM viewer : 10–30s (inactif/actif)

**Commandes repro :**
```bash
pytest -q tests/test_simulator*.py -k "unit or fast" --durations=10
pytest -q tests/test_sim_latency.py
```

#### Priorité 3 - Modules utilitaires

**7. Hugging Face (`src/bbia_sim/bbia_huggingface.py`)**

**Vérifications sécurité :**
- [ ] Test validation entrée utilisateur : Anti-injection (prompts malveillants)
- [ ] Test mémoire : Déchargement modèles après inactivité (timeout configurable)

**Benchmarks requis :**
- [ ] Latence génération LLM : 150 tokens p50/p95 (CPU + MPS/CUDA si disponible)
- [ ] Budget CPU/RAM : 30s en charge légère (pic mémoire chargement)

**Commandes repro :**
```bash
pytest -q tests/test_bbia_huggingface_chat.py -k "fast" --durations=10
pytest -q tests/test_huggingface_latency.py
```

### 🎯 Prochaines étapes immédiates (ordre d'exécution)

1. **Test watchdog timeout** : `tests/test_watchdog_timeout_latency.py` (ajouté)
   - Mock robot qui échoue → watchdog déclenche stop; mesure p50/p95
   - Commandes : `pytest -q tests/test_watchdog_timeout_latency.py -v`

2. **Test latence emergency_stop** : `tests/test_emergency_stop_latency.py`
   - N=30 appels → p50/p95 (simulation)
   - Commandes : `pytest -q tests/test_emergency_stop_latency.py -v`

3. **Typage strict mypy** : Corriger 11 erreurs dans `reachy_mini_backend.py`
   - Ajouter `npt.NDArray[np.float64]`, `dict[str, Any]` explicites
   - Commandes : `mypy --strict src/bbia_sim/backends/reachy_mini_backend.py`

4. **Audit robot_api.py** : Cloner référence Reachy, comparer API, constantes, unités
   - Créer section dans `docs/status.md` avec références précises
   - Commandes : Voir "Commandes de Repro Local" ci-dessous

5. **Benchmark jitter boucle 50 Hz** : `tests/test_control_loop_jitter.py`
   - Mesurer période → écart à 20 ms → p50/p95 (simulation)
   - Commandes : `pytest -q tests/test_control_loop_jitter.py -v`

### 📈 Benchmarks mesurés (simulation)

- Emergency stop (sim) : p50 < 10 ms, p95 < 20 ms (N=30)
- Watchdog timeout → stop (sim, mock robot) : p50 < 200 ms, p95 < 300 ms (N=10)
- Jitter boucle 50 Hz (sim) : p50 ~ 20 ms, p95 ≤ 40 ms (N=200)
- goto_target(head, 0.1 s, minjerk) (sim) : p50 < 20 ms, p95 < 40 ms (N=50)
- Vision (pipeline simulé): p50 < 10 ms, p95 < 20 ms (N=50)
- Vision FPS 10 s (sim): ≥ 10 FPS — PASS
- Vision budget 10 s (sim): CPU < 3.0 s, Peak RAM < 200 MB — PASS
- Audio E2E lecture simple (macOS): latence < 600 ms (cond.)
- Audio buffer stabilité 10 s: underruns=0, overruns=0
- Runtime budget 10 s (sim): CPU < 1.5 s, Peak RAM < 64 MB

#### Tableau récapitulatif (PASS simulé)

| Domaine | Test | Seuil p50/p95 | Résultat |
|---|---|---|---|
| Backend | emergency_stop | <10 ms / <20 ms | PASS |
| Backend | watchdog timeout (sim) | <200 ms / <300 ms | PASS |
| Backend | jitter 50 Hz | ~20 ms / ≤40 ms | PASS |
| Backend | goto_target 0.1 s minjerk | <20 ms / <40 ms | PASS |
| Vision | pipeline simulé | <10 ms / <20 ms | PASS |
| Audio | E2E lecture (macOS) | <600 ms | PASS |
| Audio | buffer stabilité 10 s | underruns=0 / overruns=0 | PASS |
| Système | budget 10 s | CPU<1.5 s, Peak RAM<64 MB | PASS |

### 📝 Format benchmarks attendu (JSONL)

Chaque benchmark génère une entrée JSONL avec métriques p50/p95 :
```json
{
  "module": "backends/reachy_mini_backend",
  "benchmark": "emergency_stop_latency",
  "metrics": {
    "p50_ms": 38.2,
    "p95_ms": 56.8,
    "n_samples": 100,
    "environment": "simulation"
  }
}
```

## 🔍 Module : `robot_api.py`

### 📋 Référence Reachy Mini

**Références précises @84c40c31**  
- Abstraction Backend: `/tmp/reachy_ref/src/reachy_mini/daemon/backend/abstract.py`  
- Backend réel: `/tmp/reachy_ref/src/reachy_mini/daemon/backend/robot/backend.py`  
- URDF: `/tmp/reachy_ref/src/reachy_mini/descriptions/reachy_mini/urdf/robot.urdf`

**Type :** Interface unifiée abstraite BBIA  
**Statut :** ✅ Conforme (API, unités en radians, clamp sécurité). Pas de ROS2/QoS attendu ici (géré côté SDK/daemon).

Le fichier `robot_api.py` définit une API abstraite (connect/disconnect, set/get joint, step, emergency_stop, behaviors) avec des garde-fous de sécurité (`safe_amplitude_limit = 0.3` rad, joints interdits antennes/passive). Côté SDK, les équivalents se trouvent dans `Backend`/`RobotBackend` (async goto_target, publishers zenoh, statuts, modes moteurs). L’API BBIA est unifiée et synchrone; la conformité porte sur les unités, les bornes et la sémantique des appels.

### ✅ Conformité Code Qualité

| Critère | Statut | Détails |
|---------|--------|---------|
| Lignes ≤ 100 chars | ✅ | 0 ligne > 100 chars |
| Ruff check | ✅ | Aucune erreur |
| Black format | ✅ | 88 colonnes |
| Mypy strict | ✅ | Types précis (`Optional`, `dict[str, Any]`) |
| Bandit security | ✅ | 0 issues |

**Points de conformité clés :**
1. ✅ Unités en radians partout (aligné SDK)
2. ✅ Clamp sécurité amplitude ±0.3 rad par défaut (logiciel) + respect `joint_limits` si fournis
3. ✅ Joints interdits: antennes et passives par défaut (prévention dommages)
4. ✅ `emergency_stop()` requis par l’interface (implémenté dans backend Reachy)
5. ✅ `look_at` générique avec validation bornes coordonnées

### 🔒 Sécurité & Tests

**Tests pertinents (suite existante) :**
- `tests/test_watchdog_monitoring.py` (watchdog démarrage/arrêt sur backend Reachy)
- `tests/test_emergency_stop.py` (interface arrêt d’urgence)

**Tests recommandés (spécifiques RobotAPI) :**
- [x] Validation `clamp_joint_position` avec bornes spécifiques par joint (couvert par tests existants)
- [x] Refus joints interdits (`left_antenna`, `right_antenna`, `passive_*`) (couvert par tests existants)
- [x] Budget temps `step()` non bloquant (test ajouté `test_robot_api_step_non_blocking.py`)

### ⚡ Performance

**Observations :**
- API abstraite sans I/O bloquante (OK)
- Boucles de comportements simples utilisent `time.sleep(0.1)` à 10 Hz (non critique, acceptable car exemples)

**Recommandations :**
- [ ] Éviter `sleep` dans l’API de base; laisser le backend gérer la cadence temps réel

### 📚 Documentation

- Docstrings présentes et minimalistes  
- Méthodes clairement séparées entre API abstraite et comportements d’exemple

### 🎯 Score & Recommandation

| Critère | Score | Poids |
|---------|-------|-------|
| Conformité | 9/10 | 40% |
| Sécurité & Tests | 8.5/10 | 30% |
| Performance | 9/10 | 20% |
| Docs/UX | 8.5/10 | 10% |
| **TOTAL** | **8.9/10** | 100% |

**Recommandation :** Conforme pour rôle d’interface abstraite. Ajouter tests ciblés sur `clamp_joint_position` et interdictions de joints; garder l’API sans `sleep` et déporter la cadence dans les backends. Aucun écart d’unités avec la référence (radians). Aucune action ROS2/QoS attendue ici.

---

## 🔗 Références

- **SDK Reachy Mini :** https://github.com/pollen-robotics/reachy_mini
- **Commit utilisé :** `84c40c31ff898da4004584c09c6a1844b27425a3`
- **Branch :** `develop`

### 🔁 Interop SDK + Simulation officielle (alignement Discord)

- Windows (MuJoCo natif recommandé):
  ```bash
  uvx --from reachy-mini[mujoco] reachy-mini-daemon --sim
  ```
- macOS (zsh, noter les guillemets pour extras):
  ```bash
  pip install "reachy-mini[mujoco]"
  ```

Notes:
- Ce dépôt BBIA-SIM reste simulation-first côté MuJoCo, interopérable avec le SDK Reachy Mini (référence ci-dessus). Les tests de conformité/latence sont alignés.
- STL fournis: usage simulation (MuJoCo). Pour impression physique: attendre la publication OnShape officielle (à référencer ici lorsqu’elle sera publique).

### 🧠 Architecture IA déportée (Wireless)

- Flux recommandé (aligné Discord): Robot (RPi/carte dédiée) ⇄ WiFi ⇄ PC IA (STT/TTS/LLM) ⇄ Robot.
- Déjà supporté ici: séparation backend robot, modules IA (voix, HF, émotions) et tests de latence audio. 
- Backends IA locaux possibles (non installés par défaut):
  - TTS: KittenTTS (léger), alternatives plus lourdes Kokoro/NeuTTS
  - STT: Whisper/Parakeet
  - LLM: llama.cpp, Qwen 1.7B (tool-calling possible)
- Recommandation: exposer sélection backend via flags/variables d’environnement (structure `ai_backends.py` déjà prête, tests présents `tests/test_ai_backends_selection.py`).
