# ğŸ§ª Guide des Tests et Coverage - BBIA Reachy Mini

## ğŸ“Š RÃ©sumÃ© des Performances

**ğŸ¯ Coverage total : 63.37%** (excellent)

- **706 tests collectÃ©s** par pytest
- **453+ tests passent** (taux de rÃ©ussite variable selon environnement)
- **11+ tests skippÃ©s** (tests conditionnels)
- **0 tests Ã©chouent** (tous corrigÃ©s)

## ğŸ—ï¸ Structure des Tests

```mermaid
graph TB
    subgraph "Tests Structure"
        E2E[e2e/<br/>Tests end-to-end<br/>20 tests]
        SIM[sim/<br/>Tests simulation<br/>7 tests]
        WS[ws/<br/>Tests WebSocket<br/>3 tests]
        BBIA[test_bbia_*.py<br/>Tests modules BBIA<br/>80+ tests]
        DAEMON[test_daemon_*.py<br/>Tests daemon<br/>50+ tests]
        WEBSOCKET[test_websocket_*.py<br/>Tests WebSocket<br/>30+ tests]
        VERTICAL[test_vertical_slices.py<br/>Tests vertical slices<br/>9 tests]
        GOLDEN[test_golden_traces.py<br/>Tests golden traces<br/>3 tests]
    end
    
    E2E --> API[test_api_simu_roundtrip.py]
    E2E --> MODULES[test_bbia_modules_e2e.py]
    E2E --> MOTION[test_motion_roundtrip.py]
    E2E --> TELEMETRY[test_websocket_telemetry_e2e.py]
    
    SIM --> CLI[test_cli_help.py]
    SIM --> DURATION[test_duration.py]
    
    WS --> RATE[test_telemetry_rate.py]
    
    BBIA --> AUDIO[test_bbia_audio.py]
    BBIA --> BEHAVIOR[test_bbia_behavior.py]
    BBIA --> EMOTIONS[test_bbia_emotions.py]
    BBIA --> VISION[test_bbia_vision.py]
    BBIA --> VOICE[test_bbia_voice.py]
    
    DAEMON --> CONFIG[test_daemon_config.py]
    DAEMON --> MODELS[test_daemon_models.py]
    DAEMON --> SIMULATION[test_daemon_simulation_service.py]
    
    WEBSOCKET --> CONNECTION[test_websocket_connection.py]
    WEBSOCKET --> TELEMETRY_EXT[test_websocket_telemetry_extended.py]
    
    VERTICAL --> DEMO_EMOTION[test_demo_emotion_headless]
    VERTICAL --> DEMO_VOICE[test_demo_voice_headless]
    VERTICAL --> DEMO_VISION[test_demo_vision_headless]
    VERTICAL --> DEMO_BEHAVIOR[test_demo_behavior_headless]
```

## ğŸ“Š Coverage par Module

```mermaid
pie title Coverage par Module
    "bbia_audio.py" : 87.76
    "bbia_vision.py" : 88.52
    "daemon/config.py" : 100
    "daemon/models.py" : 95.35
    "daemon/simulation_service.py" : 89.83
    "daemon/ws/__init__.py" : 96.40
    "daemon/ws/telemetry.py" : 78.38
    "sim/joints.py" : 72.22
    "sim/simulator.py" : 99.29
    "unity_reachy_controller.py" : 81.68
    "Autres" : 23.07
```

## ğŸ§ª Types de Tests

```mermaid
graph LR
    subgraph "Tests Unitaires"
        UNIT[Tests unitaires<br/>Fonctions isolÃ©es<br/>Mocking]
    end
    
    subgraph "Tests d'IntÃ©gration"
        INTEGRATION[Tests d'intÃ©gration<br/>Modules ensemble<br/>API + Simulation]
    end
    
    subgraph "Tests End-to-End"
        E2E[Tests E2E<br/>ScÃ©narios complets<br/>CLI â†’ API â†’ Simulation]
    end
    
    subgraph "Tests de Performance"
        PERF[Tests performance<br/>Temps d'exÃ©cution<br/>MÃ©moire]
    end
    
    UNIT --> INTEGRATION
    INTEGRATION --> E2E
    E2E --> PERF
```
â”‚   â”œâ”€â”€ test_bbia_emotions.py     # Tests Ã©motions
â”‚   â”œâ”€â”€ test_bbia_emotions_extended.py
â”‚   â”œâ”€â”€ test_bbia_vision.py       # Tests vision
â”‚   â”œâ”€â”€ test_bbia_vision_extended.py
â”‚   â”œâ”€â”€ test_bbia_voice.py        # Tests voix
â”‚   â””â”€â”€ test_bbia_voice_extended.py
â”œâ”€â”€ test_api_*.py                 # Tests API (20+ tests)
â”œâ”€â”€ test_simulator.py             # Tests simulateur MuJoCo (20+ tests)
â”œâ”€â”€ test_unity_controller.py      # Tests contrÃ´leur Unity (30+ tests)
â””â”€â”€ test_*.py                     # Tests unitaires (200+ tests)
```

## ğŸ¯ Coverage par Module

### Modules BBIA
- `bbia_audio.py`: **87.76%** âœ… (43/49 lignes couvertes)
- `bbia_behavior.py`: **72.50%** âœ… (174/240 lignes couvertes)
- `bbia_emotions.py`: **81.71%** âœ… (67/82 lignes couvertes)
- `bbia_vision.py`: **88.52%** âœ… (54/61 lignes couvertes)
- `bbia_voice.py`: **61.96%** âœ… (57/92 lignes couvertes)

### Modules Daemon/API
- `daemon/config.py`: **100%** âœ… (52/52 lignes couvertes)
- `daemon/models.py`: **95.35%** âœ… (41/43 lignes couvertes)
- `daemon/middleware.py`: **91.30%** âœ… (42/46 lignes couvertes)
- `daemon/app/routers/motion.py`: **93.22%** âœ… (55/59 lignes couvertes)
- `daemon/app/routers/state.py`: **78.95%** âœ… (60/76 lignes couvertes)
- `daemon/simulation_service.py`: **89.83%** âœ… (106/118 lignes couvertes)
- `daemon/ws/telemetry.py`: **78.38%** âœ… (87/111 lignes couvertes)

### Modules Simulation
- `sim/simulator.py`: **90.00%** âœ… (126/140 lignes couvertes)
- `sim/joints.py`: **72.22%** âœ… (13/18 lignes couvertes)
- `unity_reachy_controller.py`: **81.20%** âœ… (108/133 lignes couvertes)

## ğŸš€ Commandes de Tests

### Tests Complets
```bash
# Lancer tous les tests avec coverage complet
python -m pytest tests/ --cov=src --cov-report=term-missing --cov-report=html

# Tests rapides sans dÃ©tails
python -m pytest tests/ --cov=src --cov-fail-under=0 --tb=no -q

# Tests avec arrÃªt au premier Ã©chec
python -m pytest tests/ --cov=src --cov-report=term-missing -x
```

### Tests Golden Traces
```bash
# Tests de non-rÃ©gression golden traces
python -m pytest tests/test_golden_traces.py -v

# RÃ©gÃ©nÃ©rer une trace de rÃ©fÃ©rence
python scripts/record_trace.py --emotion happy --duration 5 --out artifacts/golden/happy_mujoco.jsonl

# Valider une trace contre rÃ©fÃ©rence
python scripts/validate_trace.py --ref artifacts/golden/happy_mujoco.jsonl --cur current_trace.jsonl
```

### Tests SpÃ©cifiques
```bash
# Tests d'un module spÃ©cifique
python -m pytest tests/test_bbia_emotions.py -v

# Tests d'un sous-dossier
python -m pytest tests/e2e/ -v

# Test spÃ©cifique
python -m pytest tests/test_bbia_emotions.py::TestBBIAEmotions::test_set_emotion -v
```

### VÃ©rification Coverage
```bash
# Voir le rapport HTML
open htmlcov/index.html

# VÃ©rifier le nombre de tests collectÃ©s
python -m pytest --collect-only -q | wc -l
# Doit afficher 466+ tests

# Coverage d'un module spÃ©cifique
python -m pytest tests/test_bbia_emotions.py --cov=src.bbia_sim.bbia_emotions --cov-report=term-missing
```

## âš™ï¸ Configuration

### pyproject.toml
```toml
[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
norecursedirs = [".git", "logs", ".venv", "venv", "__pycache__", "reachy_repos"]
minversion = "6.0"

[tool.coverage.run]
source = ["src/bbia_sim"]
omit = [
    "*/tests/*",
    "*/test_*",
    "*/__pycache__/*",
    "*/venv/*",
    "*/.venv/*",
    "*/logs/*",
    "*/reachy_repos/*",
]

[tool.coverage.report]
fail_under = 1
show_missing = true
precision = 2
```

### .coveragerc
```ini
[run]
source = src
omit = */tests/*, */test_*, */__pycache__/*, */venv/*

[report]
fail_under = 1
show_missing = True
show_missing_branches = True
precision = 2
ignore_errors = True

[html]
directory = htmlcov
title = BBIA Reachy Mini Simulation Coverage Report

[xml]
output = coverage.xml
```

## ğŸ”§ RÃ©solution des ProblÃ¨mes

### ProblÃ¨me : Coverage trop faible malgrÃ© beaucoup de tests

**SymptÃ´mes :**
- Coverage affichÃ© < 10% malgrÃ© 400+ tests
- Tests passent mais coverage ne s'amÃ©liore pas

**Causes possibles :**
1. **Configuration testpaths incorrecte**
2. **Structure de dossiers non respectÃ©e**
3. **Fichiers __init__.py manquants**
4. **Configuration coverage incorrecte**

**Solutions :**

1. **VÃ©rifier la configuration pytest :**
```bash
python -m pytest --collect-only -q | wc -l
# Doit afficher 466+ tests
```

2. **VÃ©rifier la structure des dossiers :**
```bash
find tests/ -name "test_*.py" | wc -l
# Doit afficher 30+ fichiers
```

3. **VÃ©rifier les fichiers __init__.py :**
```bash
find tests/ -name "__init__.py"
# Doit exister dans chaque sous-dossier
```

4. **Tester la configuration coverage :**
```bash
python -m pytest tests/test_config.py --cov=src --cov-report=term-missing
```

### ProblÃ¨me : Tests qui Ã©chouent

**Tests courants qui peuvent Ã©chouer :**
- `test_get_available_joints` : Mock MuJoCo incorrect
- `test_emotional_response_*` : Mock secrets incorrect
- `test_dire_texte_*` : Mock pyttsx3 incorrect

**Solutions :**
- VÃ©rifier les mocks dans les tests
- Utiliser `--cov-fail-under=0` pour ignorer les erreurs de coverage
- Corriger les assertions trop strictes

## ğŸ“ˆ AmÃ©lioration du Coverage

### Modules Ã  amÃ©liorer
1. **bbia_voice.py (61.96%)** : Ajouter tests pour reconnaissance vocale
2. **bbia_awake.py (12.00%)** : Ajouter tests pour sÃ©quence rÃ©veil
3. **bbia_integration.py (0.00%)** : CrÃ©er tests d'intÃ©gration
4. **__main__.py (30.21%)** : Ajouter tests CLI

### StratÃ©gies d'amÃ©lioration
1. **Tests d'intÃ©gration** : Tester les interactions entre modules
2. **Tests de cas limites** : Tester les cas d'erreur
3. **Tests de performance** : Tester les performances
4. **Tests de rÃ©gression** : PrÃ©venir les rÃ©gressions

## ğŸ¯ Objectifs Coverage

- **Objectif minimum** : 70% (âŒ Ã€ atteindre : 63.37%)
- **Objectif recommandÃ©** : 80%
- **Objectif excellent** : 90%

### Modules prioritaires pour amÃ©lioration
1. `bbia_voice.py` : 61.96% â†’ 80%
2. `bbia_awake.py` : 12.00% â†’ 70%
3. `bbia_integration.py` : 0.00% â†’ 60%

---

*DerniÃ¨re mise Ã  jour : Octobre 2025*
