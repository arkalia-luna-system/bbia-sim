# Simulation BBIA complÃ¨te - tous les modes

> CompatibilitÃ© Python et CI
>
> - Python requis: 3.11+
> - CI: `.github/workflows/ci.yml`
> - Setup rapide:
>   ```bash
>   pyenv install 3.11.9 && pyenv local 3.11.9
>   python -m pip install --upgrade pip
>   pip install -e .
>   ```

## Ã‰tat actuel - phase 1 terminÃ©e

### DÃ©pÃ´ts installÃ©s avec succÃ¨s
- `reachy-docs` : documentation officielle complÃ¨te
- `reachy-unity-package` : simulation Unity
- `pollen-vision` : vision par ordinateur (testÃ©)
- `reachy2-sdk-audio-server-rs` : serveur audio
- `reachy2-behaviors-dev` : comportements
- `reachy-dashboard` : interface web
- `reachy-face-tracking` : suivi de visage
- `reachy2-tutorials` : tutoriels et exemples

---

## Architecture simulation BBIA

```mermaid
graph TB
    subgraph "Modes de Simulation"
        BASIC[Simulation BBIA de Base<br/>Ã‰motions + Mouvements]
        ADVANCED[Simulation AvancÃ©e<br/>Vision + Audio + IA]
        UNITY[Simulation Unity<br/>3D Interactive]
        MUJOCO[Simulation MuJoCo<br/>Physique rÃ©aliste]
    end

    subgraph "Modules BBIA"
        EMOTIONS[Module Ã‰motions<br/>8 Ã©motions]
        VISION[Module Vision<br/>Reconnaissance objets]
        AUDIO[Module Audio<br/>4 microphones]
        VOICE[Module Voix<br/>TTS/STT]
        BEHAVIOR[Module Comportements<br/>Actions complexes]
    end

    subgraph "IntÃ©gration"
        API[BBIA API<br/>Interface unifiÃ©e]
        SIMULATOR[Simulateur<br/>Environnement virtuel]
    end

    BASIC --> EMOTIONS
    ADVANCED --> VISION
    ADVANCED --> AUDIO
    ADVANCED --> VOICE
    UNITY --> BEHAVIOR
    MUJOCO --> SIMULATOR

    EMOTIONS --> API
    VISION --> API
    AUDIO --> API
    VOICE --> API
    BEHAVIOR --> API

    API --> SIMULATOR
```

## Workflow de simulation

```mermaid
sequenceDiagram
    participant USER as Utilisateur
    participant BBIA as BBIA System
    participant SIM as Simulateur
    participant ROBOT as Robot Virtuel

    USER->>BBIA: Lancer simulation
    BBIA->>SIM: Initialiser environnement
    SIM->>ROBOT: Charger modÃ¨le 3D

    Note over USER,ROBOT: Phase d'Ã©motions
    USER->>BBIA: Ã‰motion "happy"
    BBIA->>SIM: Appliquer Ã©motion
    SIM->>ROBOT: Animer robot

    Note over USER,ROBOT: Phase de vision
    USER->>BBIA: Reconnaissance objet
    BBIA->>SIM: Analyser scÃ¨ne
    SIM->>ROBOT: RÃ©action visuelle

    Note over USER,ROBOT: Phase audio
    USER->>BBIA: Commande vocale
    BBIA->>SIM: Traiter audio
    SIM->>ROBOT: RÃ©ponse vocale
```

## Comparaison des modes de simulation

```mermaid
graph LR
    subgraph "Simulation BBIA de Base"
        BASE_FEATURES[âœ… Ã‰motions<br/>âœ… Mouvements<br/>âœ… Audio basique<br/>âŒ Vision avancÃ©e<br/>âŒ IA complexe]
    end

    subgraph "Simulation AvancÃ©e"
        ADV_FEATURES[âœ… Ã‰motions<br/>âœ… Mouvements<br/>âœ… Audio complet<br/>âœ… Vision IA<br/>âœ… IA avancÃ©e]
    end

    subgraph "Simulation Unity"
        UNITY_FEATURES[âœ… 3D Interactive<br/>âœ… Physique<br/>âœ… Graphiques<br/>âŒ IA limitÃ©e<br/>âŒ Performance]
    end

    subgraph "Simulation MuJoCo"
        MUJOCO_FEATURES[âœ… Physique rÃ©aliste<br/>âœ… Performance<br/>âœ… PrÃ©cision<br/>âŒ Interface<br/>âŒ ComplexitÃ©]
    end

    BASE_FEATURES -.->|Ã‰volution| ADV_FEATURES
    ADV_FEATURES -.->|Choix| UNITY_FEATURES
    ADV_FEATURES -.->|Choix| MUJOCO_FEATURES
```

## Modes de simulation disponibles
```
**Ce que vous verrez :**
- ğŸ® ModÃ¨le 3D complet de Reachy
- ğŸ­ Expressions faciales animÃ©es
- ğŸ¤– Mouvements fluides en temps rÃ©el
- ğŸª Environnement 3D interactif
- ğŸ¯ ContrÃ´le via interface Unity

### 3. Interface web dashboard
```bash
cd reachy_repos/reachy-dashboard
# Suivre les instructions du README
```
**Ce que vous verrez :**
- ğŸ“Š Interface web de contrÃ´le
- ğŸ“ˆ Visualisation en temps rÃ©el
- ğŸ›ï¸ ContrÃ´les avancÃ©s
- ğŸ“± Interface responsive

### 4. Vision par ordinateur
```bash
python3 -c "
import pollen_vision
print('pollen-vision disponible')
print('FonctionnalitÃ©s :')
print('  â€¢ Reconnaissance d\'objets')
print('  â€¢ DÃ©tection de visages')
print('  â€¢ Analyse d\'expressions')
print('  â€¢ Suivi de mouvements')
"
```
**Ce que vous verrez :**
- ğŸ‘ï¸ Reconnaissance d'objets en temps rÃ©el
- ğŸ­ DÃ©tection d'expressions faciales
- ğŸ¯ Suivi de visages
- ğŸ“Š Analyse de mouvements

### 5. Suivi de visage
```bash
cd reachy_repos/reachy-face-tracking
# Suivre les instructions du README
```
**Ce que vous verrez :**
- ğŸ¯ Suivi automatique des visages
- ğŸ‘ï¸ Regard qui suit l'utilisateur
- ğŸ­ DÃ©tection d'expressions
- ğŸ¤– Mouvements de tÃªte automatiques

### 6. Comportements avancÃ©s
```bash
cd reachy_repos/reachy2-behaviors-dev
# Explorer les exemples de comportements
```
**Ce que vous verrez :**
- ğŸª Comportements prÃ©-programmÃ©s
- ğŸ­ RÃ©actions automatiques
- ğŸ¤– Actions complexes
- ğŸ¯ Interactions naturelles

---

## Guide de dÃ©marrage rapide

### Option 1 : Simulation complÃ¨te (recommandÃ©e)
```bash
# 1. Lancer BBIA de base
python3 test_bbia_reachy.py

# 2. Dans un autre terminal, lancer Unity
./quick_start.sh
# Choisir l'option 6

# 3. Ouvrir le dashboard web
cd reachy_repos/reachy-dashboard
# Suivre les instructions
```

### Option 2 : Menu interactif
```bash
./quick_start.sh
```
**Options disponibles :**
- Option 1 : Tester BBIA (simulation rapide)
- Option 6 : Lancer Unity
- Option 7 : Tester Unity
- Option 10 : Installer dÃ©pÃ´ts (dÃ©jÃ  fait)

### Option 3 : Simulation avancÃ©e
```bash
# 1. Tester pollen-vision
python3 -c "import pollen_vision; print('Vision OK')"

# 2. Explorer les tutoriels
cd reachy_repos/reachy2-tutorials
ls -la

# 3. Tester le suivi de visage
cd reachy_repos/reachy-face-tracking
ls -la
```

---

## DÃ©tails des simulations

### Simulation BBIA de base
```
ğŸ¤–============================================================ğŸ¤–
ğŸŒŸ BBIA - Brain-Based Interactive Agent
ğŸ¤– Robot: Reachy Mini Wireless
ğŸ“… Date: Oct / Oct / Nov. 20255
ğŸ’» SystÃ¨me: darwin
ğŸ¤–============================================================ğŸ¤–

ğŸ“‹ SpÃ©cifications Reachy Mini Wireless:
  Height: 28cm (23cm veille)
  Width: 16cm
  Weight: 1.5kg
  Processor: Raspberry Pi 5
  Microphones: 4
  Speaker Power: 5W
  Head Dof: 6
  Camera: Grand angle
  Battery: IntÃ©grÃ©e + USB-C
  Connectivity: Wi-Fi intÃ©grÃ©

ğŸš€ DÃ©marrage de la simulation BBIA...

ğŸ¤ Test des 4 microphones...
  Microphone 1: âœ… Actif
  Microphone 2: âœ… Actif
  Microphone 3: âœ… Actif
  Microphone 4: âœ… Actif

ğŸ“· CamÃ©ra grand angle: Active
  ğŸ‘ï¸ Reconnaissance d'objets: En cours...
  ğŸ¯ Objets dÃ©tectÃ©s: fenÃªtre

ğŸ­ Test des Ã©motions:
ğŸ˜ Ã‰motion changÃ©e: neutral
ğŸ¤– Mouvement tÃªte (6 DOF): TÃªte droite, regard neutre
ğŸ“¡ Note: Les antennes sont animables avec limites de sÃ©curitÃ© (-0.3 Ã  0.3 rad) - utilisez yaw_body pour animations principales

ğŸ˜Š Ã‰motion changÃ©e: happy
ğŸ¤– Mouvement tÃªte (6 DOF): TÃªte lÃ©gÃ¨rement relevÃ©e, regard joyeux
ğŸ“¡ Animation corps: Rotation yaw_body joyeuse (+ antennes animables)

ğŸ¤” Ã‰motion changÃ©e: curious
ğŸ¤– Mouvement tÃªte (6 DOF): TÃªte inclinÃ©e, regard attentif
ğŸ“¡ Animation corps: Rotation yaw_body lÃ©gÃ¨re (antennes bloquÃ©es)

ğŸ¤© Ã‰motion changÃ©e: excited
ğŸ¤– Mouvement tÃªte (6 DOF): TÃªte relevÃ©e, regard enthousiaste
ğŸ“¡ Animation corps: Rotation yaw_body rapide (antennes bloquÃ©es)

ğŸ˜¢ Ã‰motion changÃ©e: sad
ğŸ¤– Mouvement tÃªte (6 DOF): TÃªte baissÃ©e, regard triste
ğŸ“¡ Animation corps: Rotation yaw_body lente (antennes bloquÃ©es)

ğŸ˜  Ã‰motion changÃ©e: angry
ğŸ¤– Mouvement tÃªte (6 DOF): TÃªte penchÃ©e, regard dur
ğŸ“¡ Animation corps: Rotation yaw_body rigide (antennes bloquÃ©es)

ğŸ—£ï¸ Test d'interaction vocale:
ğŸ—£ï¸ Reconnaissance vocale active...
  ğŸ¤ Entendu: 'Que puis-je faire pour vous ?'
ğŸ”Š Haut-parleur 5W: 'J'ai compris: Que puis-je faire pour vous ?'

ğŸ”‹ Test de la batterie:
ğŸ”‹ Batterie: 100% â†’ 93%

ğŸ‰ Simulation terminÃ©e !
```

### Simulation Unity 3D
- **ModÃ¨le 3D** : Reachy Mini Wireless complet
- **Environnement** : Salle d'interaction
- **ContrÃ´les** : Souris + clavier
- **FonctionnalitÃ©s** :
  - ğŸ­ Expressions faciales animÃ©es
  - ğŸ¤– Mouvements de tÃªte fluides
  - ğŸ“¡ Note: Antennes animables (-0.3 Ã  0.3 rad) - utiliser yaw_body pour animations principales
  - ğŸ¯ Suivi de visage
  - ğŸ—£ï¸ Reconnaissance vocale
  - ğŸ“· Vision par ordinateur

### Dashboard web
- **Interface** : Web responsive
- **FonctionnalitÃ©s** :
  - ğŸ“ˆ Visualisation temps rÃ©el
  - ğŸ›ï¸ ContrÃ´les avancÃ©s
  - ğŸ“Š Graphiques de performance
  - ğŸ¯ Configuration des paramÃ¨tres
  - ğŸ“± Compatible mobile

---

## Prochaines Ã©tapes - phase 2

### Semaine prochaine : intÃ©gration
1. **IntÃ©grer** `pollen-vision` dans BBIA
2. **IntÃ©grer** les comportements avancÃ©s
3. **Configurer** le serveur audio
4. **Tester** en simulation Unity

### Dans 2 semaines : comportements
1. **Ã‰tudier** `reachy2-behaviors-dev`
2. **CrÃ©er** des comportements personnalisÃ©s
3. **IntÃ©grer** le suivi de visage
4. **DÃ©velopper** l'interface dashboard

---

## Commandes rapides

### Lancer toutes les simulations
```bash
# Terminal 1 : BBIA de base
python3 test_bbia_reachy.py

# Terminal 2 : Unity
./quick_start.sh
# Option 6

# Terminal 3 : Dashboard
cd reachy_repos/reachy-dashboard
# Suivre README
```

### VÃ©rifier les installations
```bash
# VÃ©rifier les dÃ©pÃ´ts
ls -la reachy_repos/

# VÃ©rifier les packages
pip list | grep -i reachy
pip list | grep -i pollen

# Tester pollen-vision
python3 -c "import pollen_vision; print('âœ… Vision OK')"
```

### Explorer la documentation
```bash
# Documentation officielle
cd reachy_repos/reachy-docs
ls -la content/

# Tutoriels
cd reachy_repos/reachy2-tutorials
ls -la
```

---

## RÃ©sumÃ©

### Phase 1 terminÃ©e
- Tous les dÃ©pÃ´ts GitHub installÃ©s
- `pollen-vision` testÃ© et fonctionnel
- Documentation officielle disponible
- Tutoriels et exemples accessibles

### Simulations disponibles
- ğŸ¤– BBIA de base (Ã©motions, mouvements, voix)
- ğŸ® Unity 3D (modÃ¨le complet interactif)
- ğŸ“Š Dashboard web (interface avancÃ©e)
- ğŸ‘ï¸ Vision par ordinateur (reconnaissance)
- ğŸ¯ Suivi de visage (interaction naturelle)
- ğŸª Comportements avancÃ©s (actions complexes)

### ğŸš€ **PrÃªt pour la Phase 2**
Vous pouvez maintenant commencer l'intÃ©gration des composants dans BBIA !

---

**BBIA** - Brain-Based Interactive Agent
*Guide de simulation complet* ğŸ®âœ¨

**Phase 1** : âœ… TERMINÃ‰E
**Phase 2** : ï¿½ï¿½ PRÃŠT Ã€ COMMENCER

## ğŸ¤– SÃ©quence de RÃ©veil RÃ©aliste BBIA

La simulation BBIA intÃ¨gre dÃ©sormais une sÃ©quence de rÃ©veil immersive, fidÃ¨le au robot Reachy Mini Wirelessâ€¯:
- LumiÃ¨re progressive, halo bleu, respiration simulÃ©e
- Son de dÃ©marrage, mouvements de tÃªte et bras, expression, parole
- Synchronisation possible avec Unity pour une expÃ©rience complÃ¨te

**Pour lancer la sÃ©quenceâ€¯:**
- Version Pythonâ€¯: `python src/bbia_sim/bbia_awake.py`
- Version Unityâ€¯: via le contrÃ´leur (`python src/bbia_sim/unity_reachy_controller.py awake`)

**Exemple de sortieâ€¯:**
```
âœ¨ [BBIA] Initialisation du rÃ©veil...
ğŸ’¡ LumiÃ¨re blanche faible...
ğŸ’¡ LumiÃ¨re qui s'intensifie doucement...
ğŸ’™ Halo bleu : BBIA s'Ã©veille.
ğŸ«§ Respiration simulÃ©e : inspiration...
ğŸ«§ Respiration simulÃ©e : expiration...
ğŸ”Š LÃ©ger son de dÃ©marrage...
ğŸ¤– Mouvements de tÃªte lents (simulation)...
ğŸ¤– Mouvements de bras lÃ©gers (simulation)...
ğŸ˜Š Expression : sourire doux.
ğŸ—£ï¸ PremiÃ¨re pensÃ©e : 'Je suis lÃ , Athalia.'
âœ¨ BBIA est complÃ¨tement rÃ©veillÃ© et prÃªt !
```
