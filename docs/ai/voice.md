# ðŸŽ¤ Analyse ComplÃ¨te : Voix & Intelligence BBIA

**Date :** 8 DÃ©cembre 2025  
**DerniÃ¨re mise Ã  jour :** 8 DÃ©cembre 2025  
**Auteur :** Analyse Expert  
**Objectif :** Identifier blocages macOS, solutions voix alternatives, et Ã©tat intelligence BBIA

---

## ðŸ“‹ Table des MatiÃ¨res

1. [Ã‰tat Actuel : Voix BBIA](#-Ã©tat-actuel--voix-bbia)
2. [Solutions Alternatives : GÃ©nÃ©rateurs de Voix AvancÃ©s](#-solutions-alternatives--gÃ©nÃ©rateurs-de-voix-avancÃ©s)
3. [Ã‰tat Actuel : Intelligence BBIA](#-Ã©tat-actuel--intelligence-bbia)
4. [Recommandations ProposÃ©es](#-recommandations-proposÃ©es)
5. [Plan d'ImplÃ©mentation](#-plan-dimplÃ©mentation)
6. [RÃ©sumÃ© des Blocages](#-rÃ©sumÃ©-des-blocages)
7. [Navigation](#-navigation)

---

## ðŸ“Š Ã‰tat actuel : Voix BBIA

### ImplÃ©mentation actuelle (`bbia_voice.py`)

**Technologie** : `pyttsx3` (wrapper autour des voix systÃ¨me macOS)

**Blocages macOS identifiÃ©s (confirmÃ©s par test) :**

âŒ **Pitch non contrÃ´lable**

- **Message d'erreur** : `"Pitch adjustment not supported when using NSSS"`
- **Impact** : Impossible de modifier la tonalitÃ©/hauteur de voix

âŒ **ContrÃ´le Ã©motionnel inexistant**

- `pyttsx3` ne permet pas d'ajuster l'Ã©motion (joyeux, triste, excitÃ©, etc.)
- Seule la vitesse et le volume sont contrÃ´lables

âŒ **Voix forcÃ©e Ã  "AmÃ©lie"**

- Actuellement, le code force l'utilisation d'AmÃ©lie
- 197 voix disponibles sur macOS mais non exploitables avec pyttsx3

âŒ **Vitesse limitÃ©e**

- Rate = 170 (fixe)
- Pas de variation dynamique selon le contexte

---

## ðŸ” Solutions alternatives : GÃ©nÃ©rateurs de voix avancÃ©s

### Option 1 : â­ Coqui TTS (RecommandÃ©)

**Repository** : `https://github.com/coqui-ai/TTS`

**Avantages :**

- âœ… ContrÃ´le pitch/tonalitÃ© complet
- âœ… ContrÃ´le Ã©motionnel (happy, sad, excited, etc.)
- âœ… Multi-langues (franÃ§ais inclus)
- âœ… Voix prÃ©-entraÃ®nÃ©es disponibles
- âœ… Installation simple : `pip install TTS`
- âœ… Support Apple Silicon (MPS)

**FonctionnalitÃ©s clÃ©s :**

```python
# Exemple d'utilisation
from TTS.api import TTS

tts = TTS("tts_models/fr/css10/vits")
tts.tts_to_file(
    text="Bonjour, je suis BBIA",
    file_path="output.wav",
    speaker_wav="reference_voice.wav",  # Clonage voix optionnel
    emotion="happy",  # Ã‰motion contrÃ´lable
    pitch=0.2  # Pitch contrÃ´lable
)

```

**ModÃ¨les franÃ§ais disponibles :**

- `tts_models/fr/css10/vits` - Voix franÃ§aise de qualitÃ©
- `tts_models/multilingual/multi-dataset/your_tts` - Multi-langues + clonage

**Installation :**

```bash
pip install TTS
# Optionnel : pour voix haute qualitÃ©
pip install TTS[all]

```

---

### Option 2 : Piper TTS (LÃ©ger et rapide)

**Repository** : `https://github.com/rhasspy/piper`

**Avantages :**

- âœ… TrÃ¨s lÃ©ger (modÃ¨les ~10-20MB)
- âœ… TrÃ¨s rapide (temps rÃ©el garanti)
- âœ… ContrÃ´le pitch via SSML
- âœ… Installation : `pip install piper-tts`

**Limitations :**

- âš ï¸ Pas de contrÃ´le Ã©motionnel direct
- âš ï¸ QualitÃ© vocale infÃ©rieure Ã  Coqui TTS

**FonctionnalitÃ©s :**

```python
from piper import PiperVoice

voice = PiperVoice.load("fr_FR-amÃ©lie-medium")
audio = voice.synthesize(
    "Bonjour",
    speaker_id=0,
    length_scale=1.0,  # Vitesse
    noise_scale=0.667,  # Variation
    noise_w=0.8
)

```

---

### Option 3 : XTTS v2 (Clonage voix avancÃ©)

**Repository** : `https://github.com/coqui-ai/TTS` (partie XTTS)

**Avantages :**

- âœ… Clonage voix avec 3 secondes d'audio seulement
- âœ… ContrÃ´le Ã©motionnel complet
- âœ… Multi-langues
- âœ… QualitÃ© professionnelle

**Limitations :**

- âš ï¸ Plus lourd (modÃ¨le ~1.5GB)
- âš ï¸ Plus lent (gÃ©nÃ©ration ~2-5 secondes)

**Utilisation :**

```python
from TTS.api import TTS

tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")
tts.tts_to_file(
    text="Bonjour",
    file_path="output.wav",
    speaker_wav="reference_voice.wav",  # Clone voix
    language="fr",
    emotion="happy"
)

```

---

### Option 4 : **Bark** (Voix naturelles avec bruitages)

**Repository :** `https://github.com/suno-ai/bark`

**Avantages :**

- âœ… Voix trÃ¨s naturelles
- âœ… Support bruitages (rire, soupir, etc.)
- âœ… ContrÃ´le style vocal

**Limitations :**

- âš ï¸ Pas de franÃ§ais natif (anglais principalement)
- âš ï¸ TrÃ¨s lent (gÃ©nÃ©ration ~10-30 secondes)
- âš ï¸ ModÃ¨le trÃ¨s lourd (~1GB)

---

## ðŸ§  Ã‰TAT ACTUEL : Intelligence BBIA

### Architecture Intelligence Actuelle

#### 1. **Intelligence Verbale (Conversation)**

**Module :** `bbia_huggingface.py` â†’ `BBIAHuggingFace.chat()`

**ProblÃ¨me identifiÃ© :**

- âœ… Analyse sentiment : `cardiffnlp/twitter-roberta-base-sentiment-latest`
- âœ… Analyse Ã©motion : `j-hartmann/emotion-english-distilroberta-base`
- âŒ **PAS de vrai LLM conversationnel** - Utilise seulement des rÃ¨gles et sentiment analysis

**Fonctionnement actuel :**

```python
# Actuellement dans bbia_huggingface.py :
def chat(self, user_message: str) -> str:
    # 1. Analyse sentiment (âœ…)
    sentiment = self.analyze_sentiment(user_message)

    # 2. GÃ©nÃ©ration rÃ©ponse (âŒ RÃ¨gles basiques)
    response = self._generate_response_from_sentiment(sentiment)
    # â†’ Pas de vrai modÃ¨le de langage !

```

**Ce qui manque :**

- âŒ LLM prÃ©-entraÃ®nÃ© pour conversation naturelle
- âŒ ComprÃ©hension contextuelle avancÃ©e
- âŒ GÃ©nÃ©ration de texte intelligente

---

#### 2. Intelligence Ã©motionnelle

**Module** : `bbia_emotions.py` + `bbia_integration.py`

**Ã‰tat actuel :**

- âœ… 12 Ã©motions BBIA dÃ©finies
- âœ… Mapping vers 6 Ã©motions SDK Reachy Mini
- âœ… Application Ã©motions au robot via `set_emotion()` ou `goto_target()`
- âœ… Transitions fluides avec interpolation minjerk
- âœ… DurÃ©e adaptative selon intensitÃ©

**FonctionnalitÃ©s :**

```python
# Dans bbia_integration.py
def apply_emotion_to_robot(self, emotion: str, intensity: float):
    # 1. Mapping 12 BBIA â†’ 6 SDK
    sdk_emotion = self._map_bbia_to_sdk_emotion(emotion)

    # 2. Application avec goto_target (optimisÃ©)
    self.robot_api.goto_target(
        head=pose, body_yaw=yaw,
        duration=adaptive_duration(intensity),
        method="minjerk"
    )

```

**âœ… Ã‰tat : Fonctionnel et optimisÃ©**

---

#### 3. Intelligence audio (STT/Reconnaissance)

**Module** : `bbia_voice.py` + `voice_whisper.py`

**Ã‰tat actuel :**

- âœ… **Basique** : `speech_recognition` + Google API (gratuit, limitÃ©)
- âœ… **AvancÃ©** : Whisper OpenAI via `voice_whisper.py` (si disponible)

**FonctionnalitÃ©s :**

```python
# Dans bbia_voice.py
def reconnaitre_parole(duree=3):
    # Utilise speech_recognition + Google API
    texte = r.recognize_google(audio, language="fr-FR")
    return texte

# Dans voice_whisper.py (optionnel)
whisper_stt = WhisperSTT(model_size="tiny")
texte = whisper_stt.transcribe(audio)

```

**âœ… Ã‰tat : Fonctionnel (Whisper = meilleure qualitÃ© si disponible)**

---

#### 4. Intelligence visuelle

**Module** : `bbia_vision.py` + `bbia_huggingface.py`

**Ã‰tat actuel :**

- âœ… DÃ©tection objets : YOLOv8n
- âœ… Reconnaissance visages : MediaPipe
- âœ… Description images : BLIP via `bbia_huggingface.py`
- âœ… Vision avancÃ©e : CLIP pour classification

**âœ… Ã‰tat** : TrÃ¨s fonctionnel

---

## ðŸ’¡ Recommandations proposÃ©es

### 1. Remplacer pyttsx3 par Coqui TTS â­

**Pourquoi :**

- ContrÃ´le pitch/tonalitÃ© complet (rÃ©sout blocage macOS)
- ContrÃ´le Ã©motionnel (happy, sad, excited, etc.)
- QualitÃ© vocale supÃ©rieure
- Support franÃ§ais natif

**Migration :**

```python
# Nouveau bbia_voice_advanced.py
from TTS.api import TTS

class BBIAVoiceAdvanced:
    def __init__(self):
        self.tts = TTS("tts_models/fr/css10/vits")
        self.current_emotion = "neutral"

    def say(self, text: str, emotion: str = None, pitch: float = 0.0):
        emotion = emotion or self.current_emotion
        self.tts.tts_to_file(
            text=text,
            file_path="temp_audio.wav",
            emotion=emotion,
            pitch=pitch
        )
        # Jouer audio
        playsound("temp_audio.wav")

```

---

### 2. Ajouter LLM prÃ©-entraÃ®nÃ© pour conversation â­â­

**Options :**

#### A. Mistral 7B Instruct (RecommandÃ©)

- âœ… LÃ©ger (7B paramÃ¨tres)
- âœ… FranÃ§ais excellent
- âœ… Open-source
- âœ… Support Apple Silicon (MPS)

**Installation :**

```bash
pip install transformers accelerate

```

**IntÃ©gration :**

```python
# Dans bbia_huggingface.py
from transformers import AutoModelForCausalLM, AutoTokenizer

class BBIAHuggingFace:
    def __init__(self):
        # ... code existant ...
        self.chat_model = None

    def load_chat_model(self):
        model_name = "mistralai/Mistral-7B-Instruct-v0.2"
        self.chat_tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.chat_model = AutoModelForCausalLM.from_pretrained(
            model_name,
            device_map="auto"  # Auto-dÃ©tecte MPS/CPU
        )

    def chat(self, user_message: str) -> str:
        if not self.chat_model:
            self.load_chat_model()

        # Conversation avec contexte
        messages = [
            {"role": "system", "content": "Tu es BBIA, un robot Reachy Mini amical et curieux."},
            {"role": "user", "content": user_message}
        ]

        inputs = self.chat_tokenizer.apply_chat_template(
            messages, return_tensors="pt"
        ).to(self.device)

        outputs = self.chat_model.generate(
            inputs, max_new_tokens=100, temperature=0.7
        )

        response = self.chat_tokenizer.decode(
            outputs[0][inputs.shape[1]:], skip_special_tokens=True
        )

        # Analyser sentiment pour Ã©motion robot
        sentiment = self.analyze_sentiment(user_message)
        self._apply_sentiment_to_robot(sentiment)

        return response

```

#### B. Llama 3 8B (Alternative)

- âœ… Open-source
- âœ… QualitÃ© excellente
- âš ï¸ Plus lourd que Mistral 7B

#### C. API OpenAI (GPT-4o-mini) (Simple mais payant)

- âœ… TrÃ¨s facile Ã  intÃ©grer
- âœ… QualitÃ© maximale
- âŒ CoÃ»t (~$0.15/M tokens)
- âŒ DÃ©pendance externe

---

### 3. IntÃ©gration voix + intelligence combinÃ©e

**Architecture proposÃ©e :**

```python
# bbia_voice_advanced.py
class BBIAVoiceAdvanced:
    def __init__(self):
        self.tts = TTS("tts_models/fr/css10/vits")
        self.emotion_map = {
            "happy": {"emotion": "happy", "pitch": 0.3},
            "sad": {"emotion": "sad", "pitch": -0.2},
            "excited": {"emotion": "excited", "pitch": 0.4},
            "neutral": {"emotion": "neutral", "pitch": 0.0}
        }

    def say_with_emotion(self, text: str, bbia_emotion: str):
        """SynthÃ©tise voix avec Ã©motion correspondante."""
        voice_config = self.emotion_map.get(bbia_emotion, self.emotion_map["neutral"])

        self.tts.tts_to_file(
            text=text,
            file_path="temp_audio.wav",
            emotion=voice_config["emotion"],
            pitch=voice_config["pitch"]
        )

        # Jouer + synchroniser avec mouvements robot
        playsound("temp_audio.wav")

```

---

## ðŸ“‹ Plan d'implÃ©mentation

### Phase 1 : Migration voix (PrioritÃ© haute)

1. âœ… Installer Coqui TTS : `pip install TTS`
2. âœ… CrÃ©er `bbia_voice_advanced.py` avec Coqui TTS
3. âœ… Tester contrÃ´le pitch/Ã©motion
4. âœ… IntÃ©grer dans `bbia_behavior.py` et `bbia_integration.py`
5. âœ… DÃ©prÃ©cier `bbia_voice.py` (garder en fallback)

### Phase 2 : Ajouter LLM conversation (PrioritÃ© moyenne)

1. âœ… Installer Mistral 7B : `pip install transformers accelerate`
2. âœ… Modifier `BBIAHuggingFace.chat()` pour utiliser vrai LLM
3. âœ… Tester conversations longues avec contexte
4. âœ… Optimiser pour Apple Silicon (MPS)

### Phase 3 : IntÃ©gration complÃ¨te (PrioritÃ© basse)

1. âœ… Synchroniser voix Ã©motionnelle avec mouvements robot
2. âœ… Ajouter contrÃ´le fin pitch selon contexte
3. âœ… Optimiser latence (cache modÃ¨les)

---

## ðŸŽ¯ RÃ©sumÃ© des blocages

### Blocages macOS avec pyttsx3 :

- âŒ Pitch non contrÃ´lable
- âŒ ContrÃ´le Ã©motionnel inexistant
- âŒ Voix limitÃ©es (197 dispo mais non exploitables)
- âŒ Vitesse fixe

### Solutions proposÃ©es :

- âœ… **Coqui TTS** : RÃ©sout tous les blocages
- âœ… **Piper TTS** : Alternative lÃ©gÃ¨re (pas d'Ã©motion)
- âœ… **XTTS v2** : Clonage voix (si besoin voix personnalisÃ©e)

### Intelligence conversationnelle :

- âŒ **Actuellement** : RÃ¨gles + sentiment analysis uniquement
- âœ… **Solution** : Mistral 7B Instruct ou Llama 3 8B
- âœ… **Alternative simple** : API OpenAI (payant)

---

## ðŸ“š RESSOURCES

- **Coqui TTS :** https://github.com/coqui-ai/TTS
- **Piper TTS :** https://github.com/rhasspy/piper
- **Mistral 7B :** https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2
- **Llama 3 :** https://huggingface.co/meta-llama/Llama-3-8B-Instruct

---

**Prochaine Ã©tape :** ImplÃ©menter Phase 1 (Coqui TTS) pour rÃ©soudre blocages macOS immÃ©diatement.

## ðŸŽ§ IntÃ©gration SDK Reachy Mini (media.speaker)

- **Nouveau**: `bbia_voice_advanced.py` supporte `robot_api.media.play_audio` quand disponible.
- **PrioritÃ© d'exÃ©cution**:
  1. `robot.media.play_audio(bytes, volume)` (si exposÃ© par le backend Reachy Mini)
  2. `robot.media.speaker.play_file(path)` ou `robot.media.speaker.play(bytes)`
  3. Fallback local `playsound()`
- **BÃ©nÃ©fices**:
  - Latence plus faible et rendu audio matÃ©riel direct du Reachy Mini
  - Volume gÃ©rÃ© cÃ´tÃ© robot
  - Alignement avec la pile officielle (rÃ©fÃ©rence: SDK `reachy_mini`)

> Note: Aucun changement de date; cette section documente l'alignement avec le SDK officiel.

---

## ðŸŽ¯ Navigation

**Retour Ã ** : [README Documentation](../README.md)  
**Voir aussi** : [Modules IA](modules.md) â€¢ [Intelligence LLM](llm.md) â€¢ [Index ThÃ©matique](../reference/INDEX_THEMATIQUE.md)
