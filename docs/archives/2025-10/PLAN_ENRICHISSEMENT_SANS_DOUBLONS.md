# üéØ PLAN D'ENRICHISSEMENT BBIA - SANS DOUBLONS

**Date :** 28 Octobre 2025  
**Objectif :** Enrichir modules existants au lieu de cr√©er des doublons  
**R√®gle d'or :** Prolonger > Cr√©er

---

## üìä ANALYSE - CE QUI EXISTE D√âJ√Ä

### ‚úÖ **bbia_huggingface.py** (EXISTE)

**Fonctionnalit√©s actuelles :**
- ‚úÖ Analyse sentiment (`analyze_sentiment`)
- ‚úÖ Analyse √©motion (`analyze_emotion`)
- ‚úÖ Description images (`describe_image`)
- ‚úÖ Transcription audio (`transcribe_audio`)
- ‚úÖ VQA : `answer_question`
- ‚úÖ Support Device Auto (CUDA/MPS/CPU)

**Ce qui MANQUE (√† ajouter) :**
- ‚ùå Chat intelligent contextuel
- ‚ùå Historique conversation
- ‚ùå R√©ponses contextuelles BBIA
- ‚ùå Fusion √©motions d√©tect√©es ‚Üí r√©ponses

---

### ‚úÖ **dashboard_advanced.py** (EXISTE)

**Fonctionnalit√©s actuelles :**
- ‚úÖ M√©triques temps r√©el
- ‚úÖ Graphiques Chart.js
- ‚úÖ Contr√¥les joints dynamiques
- ‚úÖ Vision temps r√©el
- ‚úÖ Logs live

**Ce qui MANQUE (√† ajouter) :**
- ‚ùå Chat avec BBIA
- ‚ùå Reconnaissance vocale web
- ‚ùå Historique conversations

---

## üéØ PLAN D'ACTION (ENRICHIR L'EXISTANT)

### ‚úÖ **T√ÇCHE 1 : Enrichir `bbia_huggingface.py`**

**Fichier √† modifier :** `src/bbia_sim/bbia_huggingface.py`

**Ajouts propos√©s :**

```python
# Ajouter dans BBIAHuggingFace

class BBIAHuggingFace:
    # ... code existant ...
    
    # ‚úÖ NOUVEAU : Historique conversation
    def __init__(self, ...):
        # ... code existant ...
        self.conversation_history: list[dict[str, Any]] = []
        self.context: dict[str, Any] = {}
        self.bbia_personality = "friendly_robot"
    
    # ‚úÖ NOUVEAU : Chat intelligent
    def chat(self, user_message: str, use_context: bool = True) -> str:
        """Chat intelligent avec BBIA avec contexte."""
        try:
            # 1. Analyser sentiment du message
            sentiment = self.analyze_sentiment(user_message)
            
            # 2. R√©cup√©rer contexte si demand√©
            if use_context:
                context_text = self._build_context_string()
                full_message = f"{context_text}\nUser: {user_message}"
            else:
                full_message = user_message
            
            # 3. Charger LLM l√©ger (GPT-2 ou phi-2)
            if "chat_model_pipeline" not in self.models:
                self.load_model("gpt2", "nlp")  # LLM l√©ger
            
            # 4. G√©n√©rer r√©ponse
            pipeline = self.models["gpt2_pipeline"]
            response = pipeline(full_message, max_length=100, num_return_sequences=1)
            bbia_response = response[0]["generated_text"].split("User:")[-1].strip()
            
            # 5. Sauvegarder dans historique
            self.conversation_history.append({
                "user": user_message,
                "bbia": bbia_response,
                "sentiment": sentiment,
                "timestamp": datetime.now().isoformat()
            })
            
            # 6. Adapter r√©ponse selon personnalit√© BBIA
            adapted_response = self._adapt_response_to_personality(bbia_response, sentiment)
            
            return adapted_response
            
        except Exception as e:
            logger.error(f"Erreur chat: {e}")
            return "Je ne comprends pas bien, peux-tu reformuler ?"
    
    # ‚úÖ NOUVEAU : Adapter r√©ponse selon personnalit√©
    def _adapt_response_to_personality(self, response: str, sentiment: dict) -> str:
        """Adapte la r√©ponse selon la personnalit√© BBIA."""
        personality_responses = {
            "friendly_robot": f"ü§ñ {response}",
            "curious": f"ü§î {response}",
            "enthusiastic": f"üéâ {response}",
            "calm": f"üòå {response}",
        }
        return personality_responses.get(self.bbia_personality, f"üí¨ {response}")
    
    # ‚úÖ NOUVEAU : Construire contexte
    def _build_context_string(self) -> str:
        """Construit le contexte pour la conversation."""
        if not self.conversation_history:
            return "Conversation avec BBIA (robot Reachy Mini). Soyez amical et curieux."
        
        context = "Historique conversation:\n"
        for entry in self.conversation_history[-3:]:  # Derniers 3 √©changes
            context += f"User: {entry['user']}\n"
            context += f"BBIA: {entry['bbia']}\n"
        return context
```

**Estimation :** 2-3 heures

---

### ‚úÖ **T√ÇCHE 2 : Enrichir `dashboard_advanced.py`**

**Fichier √† modifier :** `src/bbia_sim/dashboard_advanced.py`

**Ajouts propos√©s :**

```javascript
// Dans le HTML de dashboard_advanced.py, ajouter :

<!-- ‚úÖ NOUVEAU : Panel Chat -->
<div class="panel">
    <h3>üí¨ Chat avec BBIA</h3>
    <div class="chat-container">
        <div class="chat-messages" id="chat-messages"></div>
        <div class="chat-input">
            <input type="text" id="chat-input" placeholder="Tapez votre message...">
            <button onclick="sendChatMessage()">Envoyer</button>
        </div>
    </div>
</div>
```

Et dans le JavaScript existant :

```javascript
// ‚úÖ NOUVEAU : Fonction chat
function sendChatMessage() {
    const input = document.getElementById('chat-input');
    const message = input.value.trim();
    if (message && ws && ws.readyState === WebSocket.OPEN) {
        const command = {
            type: 'chat',
            message: message,
            timestamp: new Date().toISOString()
        };
        ws.send(JSON.stringify(command));
        addChatMessage('user', message);
        input.value = '';
    }
}

// ‚úÖ NOUVEAU : Afficher message chat
function addChatMessage(sender, message) {
    const container = document.getElementById('chat-messages');
    const entry = document.createElement('div');
    entry.className = `chat-message chat-${sender}`;
    entry.innerHTML = `
        <div class="chat-author">${sender === 'user' ? 'Vous' : 'BBIA'}</div>
        <div class="chat-text">${message}</div>
    `;
    container.appendChild(entry);
    container.scrollTop = container.scrollHeight;
}
```

**Estimation :** 2 heures

---

## üìã FICHIERS √Ä MODIFIER (2 SEULEMENT)

### 1Ô∏è‚É£ **Enrichir `src/bbia_sim/bbia_huggingface.py`**

**Lignes √† ajouter :** ~150 lignes de code

**Fonctionnalit√©s :**
- `chat(user_message)` - Chat intelligent
- `_build_context_string()` - Contexte conversation
- `_adapt_response_to_personality()` - Personnalit√© BBIA
- `conversation_history` - Historique

**Impact :** BBIA devient capable de conversations intelligentes

---

### 2Ô∏è‚É£ **Enrichir `src/bbia_sim/dashboard_advanced.py`**

**Lignes √† ajouter :** ~50 lignes (HTML + JS)

**Fonctionnalit√©s :**
- Panel chat dans dashboard
- Interface chat interactive
- Int√©gration WebSocket existante

**Impact :** Dashboard permet de chatter avec BBIA

---

## üöÄ COMMANDES √Ä EX√âCUTER

```bash
# Activer venv
source venv/bin/activate

# 1. Pre-commit
pre-commit run --all-files

# 2. Lint
ruff check src/bbia_sim/bbia_huggingface.py src/bbia_sim/dashboard_advanced.py

# 3. Format
black src/bbia_sim/bbia_huggingface.py src/bbia_sim/dashboard_advanced.py

# 4. Types
mypy src/bbia_sim/bbia_huggingface.py src/bbia_sim/dashboard_advanced.py

# 5. Tests
python -m pytest tests/test_bbia_huggingface.py -v
python -m pytest tests/test_dashboard.py -v  # si existe

# 6. S√©curit√©
bandit -r src/bbia_sim/bbia_huggingface.py

# 7. Coverage
python -m pytest tests/test_bbia_huggingface.py --cov=src.bbia_sim.bbia_huggingface --cov-report=term-missing
```

---

## ‚úÖ ACCEPTANCE CRITERIA

- [ ] Z√©ro doublon cr√©√© (fichiers r√©utilis√©s)
- [ ] `bbia_huggingface.py` enrichi avec chat intelligent
- [ ] `dashboard_advanced.py` enrichi avec chat interactif
- [ ] Tests passent (incl. nouveaux)
- [ ] Coverage ‚â• 85% sur modifications
- [ ] Lint OK, Format OK, Types OK, S√©curit√© OK
- [ ] CI verte

---

## üéØ ESTIMATION TOTALE

**Temps requis :** ~4-5 heures  
**Impact :** Forte valeur ajout√©e sans duplicata

**R√©sultat :**
- BBIA devient conversationnel intelligent
- Dashboard devient interactif avec chat
- Portfolio enrichi
- Pr√™t avant r√©ception robot (d√©cembre)

---

**Veux-tu que je commence maintenant ?** üöÄ

*Plan cr√©√© le 28 Octobre 2025*

