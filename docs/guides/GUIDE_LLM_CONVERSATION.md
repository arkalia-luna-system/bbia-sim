# üß† Guide LLM Conversationnel BBIA

**Derni√®re mise √† jour** : 26 Janvier 2026
**Version BBIA** : 1.4.0
**Objectif** : Guide complet pour utiliser l'intelligence conversationnelle de BBIA

---

## üéØ Introduction

BBIA utilise un **LLM conversationnel** (Phi-2 ou TinyLlama) pour remplacer les r√®gles par une compr√©hension contextuelle et des r√©ponses adapt√©es.

### Fonctionnalit√©s

- ‚úÖ **Compr√©hension contextuelle** : Historique de 10 messages
- ‚úÖ **Actions robot via conversation** : "Tourne la t√™te √† droite"
- ‚úÖ **Int√©gration √©motions** : D√©tection et application automatique
- ‚úÖ **5 personnalit√©s** : Friendly, Professional, Playful, Calm, Enthusiastic
- ‚úÖ **Apprentissage pr√©f√©rences** : Adaptation selon utilisateur

---

## üì¶ Installation

### D√©pendances

```bash
pip install transformers torch accelerate
```

### Mod√®les

BBIA charge automatiquement :
1. **Phi-2 2.7B** (Microsoft) - Recommand√©
2. **TinyLlama 1.1B** - Fallback si Phi-2 indisponible
3. **Hugging Face Inference API** - Fallback si mod√®les locaux indisponibles

---

## üöÄ Utilisation Basique

### Exemple Simple

```python
from bbia_sim.bbia_chat import BBIAChat
from bbia_sim.robot_api import RobotAPI

# Cr√©er instance chat
robot_api = RobotAPI()
chat = BBIAChat(robot_api=robot_api)

# Conversation
response = chat.chat("Bonjour !")
print(response)  # "Bonjour ! Comment puis-je vous aider aujourd'hui ?"

response = chat.chat("Comment vas-tu ?")
print(response)  # R√©ponse contextuelle avec r√©f√©rence √† la conversation pr√©c√©dente
```

### Avec Actions Robot

```python
# BBIA comprend et ex√©cute des actions
response = chat.chat("Tourne la t√™te √† droite")
# ‚Üí BBIA tourne la t√™te ET r√©pond : "D'accord, je tourne la t√™te √† droite."

response = chat.chat("Maintenant √† gauche")
# ‚Üí BBIA comprend "Maintenant" = r√©f√©rence √† l'action pr√©c√©dente
```

---

## üé≠ Personnalit√©s

### Changer de Personnalit√©

```python
# Personnalit√©s disponibles
chat.set_personality("friendly")      # Amical et chaleureux (d√©faut)
chat.set_personality("professional")  # Formel et efficace
chat.set_personality("playful")       # D√©contract√© et humoristique
chat.set_personality("calm")          # Calme et apaisant
chat.set_personality("enthusiastic")  # √ânergique et enthousiaste
```

### Exemple par Personnalit√©

```python
chat.set_personality("professional")
response = chat.chat("Bonjour")
# ‚Üí "Bonjour. Comment puis-je vous assister aujourd'hui ?"

chat.set_personality("playful")
response = chat.chat("Bonjour")
# ‚Üí "Salut ! Pr√™t pour une nouvelle aventure ? üòä"
```

---

## üéØ Actions Robot via Conversation

BBIA d√©tecte automatiquement 6 actions dans la conversation :

1. **look_right** : "Tourne la t√™te √† droite", "Regarde √† droite"
2. **look_left** : "Tourne la t√™te √† gauche", "Regarde √† gauche"
3. **look_up** : "Regarde en haut", "L√®ve la t√™te"
4. **look_down** : "Regarde en bas", "Baisse la t√™te"
5. **wake_up** : "R√©veille-toi", "Allume-toi"
6. **sleep** : "Endors-toi", "√âteins-toi"

### Exemple

```python
response = chat.chat("Tourne la t√™te √† droite puis regarde en haut")
# ‚Üí BBIA ex√©cute les deux actions et confirme
```

---

## üí° Apprentissage Pr√©f√©rences

### Apprendre Pr√©f√©rences

```python
# Utilisateur pr√©f√®re r√©ponses courtes
chat.learn_preference("court", {"response_length": "short"})

# Utilisateur pr√©f√®re r√©ponses rapides
chat.learn_preference("rapide", {"response_speed": "fast"})
```

### Adaptation Automatique

BBIA adapte automatiquement ses r√©ponses selon les pr√©f√©rences :

```python
# Apr√®s avoir appris "court"
response = chat.chat("Explique-moi comment fonctionne le robot")
# ‚Üí R√©ponse courte et concise (2-3 phrases max)
```

---

## üîß Configuration

### Historique Conversation

```python
# Acc√©der √† l'historique
history = list(chat.context)
print(f"Nombre de messages : {len(history)}")

# Historique contient :
# [
#   {"user": "Bonjour", "assistant": "Bonjour !", "timestamp": ...},
#   {"user": "Comment vas-tu ?", "assistant": "...", "timestamp": ...},
#   ...
# ]
```

### Timeout et Performance

```python
# Timeout pour g√©n√©ration (d√©faut: 5s)
chat.llm_timeout = 10.0  # 10 secondes

# Mod√®le Whisper pour STT (d√©faut: "tiny")
chat.whisper_model = "base"  # Plus pr√©cis mais plus lent
```

---

## üß™ Tests

### Tests Unitaires

```bash
# Tests basiques
pytest tests/test_bbia_chat_llm.py

# Tests personnalit√©s
pytest tests/test_bbia_chat_personalities.py
```

### Exemple de Test

```python
def test_chat_context():
    chat = BBIAChat()
    
    # Premier message
    response1 = chat.chat("Bonjour")
    assert "bonjour" in response1.lower()
    
    # Deuxi√®me message avec r√©f√©rence
    response2 = chat.chat("Comment vas-tu ?")
    assert len(chat.context) == 2
    assert response2 != response1  # R√©ponses diff√©rentes
```

---

## üìö API R√©f√©rence

### Classe BBIAChat

```python
class BBIAChat:
    def __init__(self, robot_api: RobotAPI | None = None)
    def chat(self, user_message: str) -> str
    def set_personality(self, personality: str) -> None
    def learn_preference(self, user_action: str, context: dict) -> None
    def _detect_action(self, user_message: str) -> dict | None
    def _execute_action(self, action: dict) -> None
    def _extract_emotion(self, user_message: str) -> str | None
    def _apply_emotion(self, emotion: str) -> None
```

### Attributs

- `context` : `deque` (maxlen=10) - Historique conversation
- `personality` : `str` - Personnalit√© actuelle
- `user_preferences` : `dict` - Pr√©f√©rences utilisateur
- `llm_model` : Mod√®le LLM charg√©
- `llm_tokenizer` : Tokenizer associ√©

---

## üêõ D√©pannage

### Probl√®me : LLM ne charge pas

**Solution :**
```python
# V√©rifier d√©pendances
import torch
print(torch.__version__)  # Doit √™tre >= 2.0.0

# V√©rifier RAM disponible
import psutil
print(f"RAM disponible: {psutil.virtual_memory().available / 1024**3:.1f} GB")
# Doit √™tre >= 6GB pour Phi-2
```

### Probl√®me : Latence √©lev√©e

**Solution :**
```python
# Utiliser mod√®le plus l√©ger
chat = BBIAChat()
# TinyLlama sera charg√© automatiquement si Phi-2 √©choue

# Ou utiliser Hugging Face Inference API (fallback)
# N√©cessite connexion internet
```

### Probl√®me : Actions robot non d√©tect√©es

**Solution :**
```python
# V√©rifier que robot_api est fourni
chat = BBIAChat(robot_api=robot_api)

# Tester d√©tection manuelle
action = chat._detect_action("Tourne la t√™te √† droite")
print(action)  # {"action": "look_right", "confidence": 0.9}
```

---

## üéâ Exemples Complets

### Conversation Compl√®te

```python
from bbia_sim.bbia_chat import BBIAChat
from bbia_sim.robot_api import RobotAPI

robot_api = RobotAPI()
chat = BBIAChat(robot_api=robot_api)

# Conversation naturelle
chat.chat("Bonjour !")
chat.chat("Comment vas-tu ?")
chat.chat("Peux-tu tourner la t√™te √† droite ?")
chat.chat("Maintenant √† gauche")
chat.chat("Merci !")

# BBIA comprend le contexte et ex√©cute les actions
```

### Avec Personnalit√©

```python
chat.set_personality("playful")

chat.chat("Raconte-moi une blague")
# ‚Üí R√©ponse humoristique et d√©contract√©e

chat.set_personality("professional")
chat.chat("Raconte-moi une blague")
# ‚Üí R√©ponse plus formelle (peut refuser poliment)
```

---

## üìñ Ressources

- **Code source** : `src/bbia_sim/bbia_chat.py`
- **Tests** : `tests/test_bbia_chat_llm.py`
- **Plan d√©taill√©** : `docs/quality/audits/PLAN_INTELLIGENCE_CONVERSATIONNELLE.md`

---

---

## ü§ó Hugging Face Chat - Guide Complet (Issue #384)

### Introduction

BBIA int√®gre **Hugging Face Chat** via le module `BBIAHuggingFace` pour des conversations avec LLM. Ce guide explique comment utiliser cette fonctionnalit√©.

### Activation du Chat HF

```python
from bbia_sim.bbia_huggingface import BBIAHuggingFace

# Cr√©er instance
hf = BBIAHuggingFace()

# Activer LLM conversationnel (optionnel, lourd)
hf.enable_llm_chat(model_name="phi2")  # ou "mistral", "llama", "tinyllama"

# Chat simple
response = hf.chat("Bonjour, comment allez-vous ?")
print(response["response"])

# Chat avec outils (function calling)
response = hf.chat("Tourne la t√™te √† droite", enable_tools=True)
```

### Mod√®les Disponibles

| Mod√®le | Taille | RAM Requise | Recommandation |
|--------|--------|-------------|----------------|
| **phi2** | 2.7B | ~5GB | ‚úÖ Recommand√© pour RPi 5 |
| **tinyllama** | 1.1B | ~2GB | ‚úÖ Ultra-l√©ger |
| **mistral** | 7B | ~14GB | ‚ùå Trop lourd pour RPi |
| **llama** | 8B | ~16GB | ‚ùå Trop lourd pour RPi |

### Configuration

```python
# Utiliser mod√®le l√©ger par d√©faut
os.environ["BBIA_HF_CHAT_MODEL"] = "phi2"

# D√©sactiver LLM pour √©conomiser m√©moire
hf.disable_llm_chat()

# R√©activer
hf.enable_llm_chat("phi2")
```

### Utilisation

```python
# Chat avec contexte
response = hf.chat(
    "Qu'est-ce que j'ai dit avant ?",
    use_context=True  # Utilise historique conversation
)

# Analyser sentiment
sentiment = hf.analyze_sentiment("Je suis tr√®s heureux !")
print(sentiment["sentiment"])  # "positive"

# Historique conversation
history = hf.get_conversation_history(limit=10)
for entry in history:
    print(f"{entry['role']}: {entry['content']}")
```

### Int√©gration avec Robot

```python
from bbia_sim.bbia_huggingface import BBIAHuggingFace
from bbia_sim.bbia_tools import BBIATools

# Cr√©er outils robot
tools = BBIATools(robot_api=robot_api, hf_chat=hf)

# Chat avec actions robot automatiques
response = hf.chat("Regarde √† droite", enable_tools=True)
# Le robot tourne automatiquement la t√™te !
```

### Troubleshooting

**Probl√®me** : Mod√®le ne charge pas
**Solution** : V√©rifier RAM disponible, utiliser mod√®le plus l√©ger

**Probl√®me** : Latence √©lev√©e
**Solution** : Utiliser `tinyllama` ou d√©sactiver LLM (`disable_llm_chat()`)

**Probl√®me** : Mod√®le non trouv√©
**Solution** : V√©rifier connexion internet, mod√®les t√©l√©charg√©s automatiquement

### R√©f√©rences

- Module : `src/bbia_sim/bbia_huggingface.py`
- M√©thode principale : `enable_llm_chat()`, `chat()`, `disable_llm_chat()`
- Exemples : `examples/demo_chat_bbia_3d.py`

---

**Document cr√©√© le :** 26 Janvier 2026
**Derni√®re mise √† jour :** 26 Janvier 2026 (Issue #384)
**Version BBIA :** 1.3.2
**Auteur :** Arkalia Luna System

