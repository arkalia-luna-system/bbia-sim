#!/usr/bin/env python3
"""
Test MediaPipe Pose - D√©tection postures/gestes

Usage:
    # Dans venv-vision-py310 (o√π MediaPipe est install√©)
    source venv-vision-py310/bin/activate

    # Test avec webcam
    python scripts/test_pose_detection.py --webcam

    # Test avec image
    python scripts/test_pose_detection.py --image photo.jpg
"""

import argparse
import sys
from pathlib import Path

# Ajouter src au path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

try:
    from bbia_sim.pose_detection import create_pose_detector

    MEDIAPIPE_POSE_AVAILABLE = True
except ImportError:
    print("‚ùå MediaPipe Pose non disponible")
    print("üí° MediaPipe est d√©j√† install√© dans venv-vision-py310")
    print("   V√©rifier: pip install mediapipe")
    sys.exit(1)


def test_webcam(pose_detector, complexity: int = 1):
    """Test avec webcam en temps r√©el."""
    try:
        import cv2
    except ImportError:
        print("‚ùå OpenCV non disponible")
        return 1

    # Ouvrir webcam
    camera_index = int(__import__("os").environ.get("BBIA_CAMERA_INDEX", "0"))
    cap = cv2.VideoCapture(camera_index)

    if not cap.isOpened():
        print(f"‚ùå Impossible d'ouvrir la cam√©ra (index {camera_index})")
        return 1

    print("üìπ Webcam ouverte. Appuie sur 'q' pour quitter")
    print("üí° Affiche-toi devant la cam√©ra pour tester la d√©tection de posture")

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # D√©tecter la pose
        pose_result = pose_detector.detect_pose(frame)

        if pose_result:
            # Afficher les r√©sultats
            posture = pose_result["posture"]
            gestures = pose_result["gestures"]
            landmarks_count = pose_result["num_landmarks"]

            # Afficher sur l'image
            cv2.putText(
                frame,
                f"Posture: {posture}",
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                (0, 255, 0),
                2,
            )

            gesture_text = []
            if gestures.get("bras_lev√©s"):
                gesture_text.append("Bras lev√©s")
            if gestures.get("bras_gauche_lev√©"):
                gesture_text.append("Bras gauche lev√©")
            if gestures.get("bras_droit_lev√©"):
                gesture_text.append("Bras droit lev√©")
            if gestures.get("mains_sur_tete"):
                gesture_text.append("Mains sur t√™te")

            if gesture_text:
                cv2.putText(
                    frame,
                    ", ".join(gesture_text),
                    (10, 70),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    (255, 255, 0),
                    2,
                )

            cv2.putText(
                frame,
                f"Landmarks: {landmarks_count}/33",
                (10, 110),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2,
            )
        else:
            cv2.putText(
                frame,
                "Aucune posture detectee",
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                (0, 0, 255),
                2,
            )

        cv2.imshow("BBIA Pose Detection", frame)

        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()
    return 0


def test_image(pose_detector, image_path: str):
    """Test avec une image."""
    try:
        import cv2
    except ImportError:
        print("‚ùå OpenCV non disponible")
        return 1

    if not Path(image_path).exists():
        print(f"‚ùå Image introuvable: {image_path}")
        return 1

    # Charger l'image
    image = cv2.imread(image_path)
    if image is None:
        print(f"‚ùå Impossible de charger l'image: {image_path}")
        return 1

    print(f"üîç Analyse de l'image: {image_path}")

    # D√©tecter la pose
    pose_result = pose_detector.detect_pose(image)

    if pose_result:
        print("\n‚úÖ Posture d√©tect√©e:")
        print(f"   ‚Ä¢ Posture: {pose_result['posture']}")
        print(f"   ‚Ä¢ Landmarks: {pose_result['num_landmarks']}/33")
        print("\n   Gestes d√©tect√©s:")
        for gesture, detected in pose_result["gestures"].items():
            status = "‚úÖ" if detected else "‚ùå"
            print(f"      {status} {gesture}")

        # Sauvegarder l'image avec r√©sultats (optionnel)
        # cv2.imwrite("output_pose.jpg", image)
    else:
        print("‚ùå Aucune posture d√©tect√©e dans l'image")
        print("üí° Assure-toi que l'image contient une personne visible")

    return 0


def main():
    parser = argparse.ArgumentParser(description="Test MediaPipe Pose Detection BBIA")
    parser.add_argument(
        "--webcam",
        action="store_true",
        help="Test avec webcam en temps r√©el",
    )
    parser.add_argument(
        "--image",
        type=str,
        help="Test avec une image (chemin vers fichier)",
    )
    parser.add_argument(
        "--complexity",
        type=int,
        default=1,
        choices=[0, 1, 2],
        help="Complexit√© du mod√®le (0=rapide, 1=√©quilibr√©, 2=pr√©cis)",
    )

    args = parser.parse_args()

    # Cr√©er le d√©tecteur
    pose_detector = create_pose_detector(model_complexity=args.complexity)
    if not pose_detector or not pose_detector.is_initialized:
        print("‚ùå Impossible de cr√©er le d√©tecteur MediaPipe Pose")
        return 1

    print(f"‚úÖ D√©tecteur Pose cr√©√© (complexit√©: {args.complexity})")

    # Test webcam
    if args.webcam:
        return test_webcam(pose_detector, complexity=args.complexity)

    # Test image
    if args.image:
        return test_image(pose_detector, args.image)

    # Aucune action, afficher aide
    parser.print_help()
    return 1


if __name__ == "__main__":
    sys.exit(main())
