#!/usr/bin/env python3
"""Validateur de traces golden pour RobotAPI
Compare une trace courante avec une rÃ©fÃ©rence et valide les tolÃ©rances
"""

import argparse
import json
from statistics import mean


def load(path):
    """Charge une trace JSONL."""
    with open(path, encoding="utf-8") as f:
        return [json.loads(x) for x in f]


def compare(ref, cur, tol_q=0.05, tol_rate=0.15):
    """Compare deux traces avec tolÃ©rances.

    Args:
        ref: Trace de rÃ©fÃ©rence
        cur: Trace courante
        tol_q: TolÃ©rance position (rad)
        tol_rate: TolÃ©rance cadence (%)

    Returns:
        tuple: (ok, metrics)

    """
    assert len(ref) > 10 and len(cur) > 10, "Traces trop courtes"

    # Aligner par index (simple & robuste)
    n = min(len(ref), len(cur))
    dq = [abs(ref[i]["qpos"] - cur[i]["qpos"]) for i in range(n)]
    ok_q = max(dq) <= tol_q

    # Cadence (approx): moyenne dt
    def cadence(tr):
        dt = [tr[i + 1]["t"] - tr[i]["t"] for i in range(len(tr) - 1)]
        return 1.0 / (mean(dt) or 1e-6)

    r_rate, c_rate = cadence(ref), cadence(cur)
    ok_rate = abs(c_rate - r_rate) / max(r_rate, 1e-6) <= tol_rate

    metrics = {
        "max_abs_qpos_err": max(dq),
        "ref_hz": r_rate,
        "cur_hz": c_rate,
        "rate_diff_pct": abs(c_rate - r_rate) / max(r_rate, 1e-6) * 100,
        "frames_ref": len(ref),
        "frames_cur": len(cur),
        "frames_compared": n,
    }

    return ok_q and ok_rate, metrics


def main():
    ap = argparse.ArgumentParser(description="Validateur de traces golden")
    ap.add_argument("--ref", required=True, help="Fichier de rÃ©fÃ©rence")
    ap.add_argument("--cur", required=True, help="Fichier courant")
    ap.add_argument(
        "--tol-q",
        type=float,
        default=0.05,
        help="TolÃ©rance position (rad)",
    )
    ap.add_argument(
        "--tol-rate",
        type=float,
        default=0.15,
        help="TolÃ©rance cadence (%)",
    )
    args = ap.parse_args()

    print("ðŸ” Validation trace:")
    print(f"   â€¢ RÃ©fÃ©rence: {args.ref}")
    print(f"   â€¢ Courante: {args.cur}")
    print(f"   â€¢ TolÃ©rance position: Â±{args.tol_q} rad")
    print(f"   â€¢ TolÃ©rance cadence: Â±{args.tol_rate * 100:.1f}%")

    try:
        ref, cur = load(args.ref), load(args.cur)
        ok, metrics = compare(ref, cur, args.tol_q, args.tol_rate)

        print("\nðŸ“Š MÃ©triques:")
        print(f"   â€¢ Erreur max position: {metrics['max_abs_qpos_err']:.4f} rad")
        print(f"   â€¢ Cadence rÃ©fÃ©rence: {metrics['ref_hz']:.1f} Hz")
        print(f"   â€¢ Cadence courante: {metrics['cur_hz']:.1f} Hz")
        print(f"   â€¢ DiffÃ©rence cadence: {metrics['rate_diff_pct']:.1f}%")
        print(f"   â€¢ Frames comparÃ©es: {metrics['frames_compared']}")

        if ok:
            print("\nâœ… Validation rÃ©ussie")
            return 0
        print("\nâŒ Validation Ã©chouÃ©e")
        return 1

    except Exception as e:
        print(f"\nâŒ Erreur validation: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
