#!/usr/bin/env python3
"""
stt_demo.py - D√©mo Speech-to-Text avec Whisper
Script CLI pour tester les commandes vocales ‚Üí actions RobotAPI
"""

import argparse
import logging
import sys
import time
from pathlib import Path

# Ajouter le chemin src pour les imports
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from bbia_sim.robot_api import RobotFactory
from bbia_sim.voice_whisper import WHISPER_AVAILABLE, VoiceCommandMapper, WhisperSTT

logger = logging.getLogger(__name__)


def test_voice_command(text: str, backend: str = "mujoco") -> bool:
    """
    Teste une commande vocale avec le robot.

    Args:
        text: Commande vocale √† tester
        backend: Backend robot ("mujoco" ou "reachy")

    Returns:
        True si succ√®s, False sinon
    """
    try:
        # Initialisation
        mapper = VoiceCommandMapper()
        robot = RobotFactory.create_backend(backend)

        # Connexion robot
        robot.connect()

        # Mapping commande
        action_data = mapper.map_command(text)
        if not action_data:
            logger.error(f"‚ùå Commande non reconnue: '{text}'")
            return False

        action = action_data["action"]
        confidence = action_data["confidence"]

        logger.info(f"üéØ Ex√©cution action: {action} (confiance: {confidence})")

        # Ex√©cution action
        if action == "greet":
            robot.set_emotion("happy", intensity=0.8)
            time.sleep(2)
            robot.set_emotion("neutral", intensity=0.5)

        elif action == "look_at":
            # Mouvement de t√™te simple
            robot.set_joint_pos("yaw_body", 0.2)
            time.sleep(1)
            robot.set_joint_pos("yaw_body", -0.2)
            time.sleep(1)
            robot.set_joint_pos("yaw_body", 0.0)

        elif action == "happy":
            robot.set_emotion("happy", intensity=0.9)
            time.sleep(3)

        elif action == "sad":
            robot.set_emotion("sad", intensity=0.8)
            time.sleep(3)

        elif action == "excited":
            robot.set_emotion("excited", intensity=0.9)
            time.sleep(3)

        elif action == "wake_up":
            robot.set_emotion("excited", intensity=0.7)
            time.sleep(1)
            robot.set_joint_pos("yaw_body", 0.1)
            time.sleep(0.5)
            robot.set_joint_pos("yaw_body", -0.1)
            time.sleep(0.5)
            robot.set_joint_pos("yaw_body", 0.0)
            robot.set_emotion("happy", intensity=0.8)
            time.sleep(2)

        # D√©connexion
        robot.disconnect()

        logger.info(f"‚úÖ Action '{action}' ex√©cut√©e avec succ√®s")
        return True

    except Exception as e:
        logger.error(f"‚ùå Erreur ex√©cution action: {e}")
        return False


def test_whisper_transcription(audio_file: str) -> bool:
    """
    Teste la transcription Whisper sur un fichier audio.

    Args:
        audio_file: Chemin vers le fichier audio

    Returns:
        True si succ√®s, False sinon
    """
    if not WHISPER_AVAILABLE:
        logger.error("‚ùå Whisper non disponible")
        return False

    try:
        # Initialisation Whisper
        stt = WhisperSTT(model_size="tiny", language="fr")

        # Test transcription
        start_time = time.time()
        text = stt.transcribe_audio(audio_file)
        transcription_time = time.time() - start_time

        if text:
            logger.info(
                f"‚úÖ Transcription r√©ussie en {transcription_time:.1f}s: '{text}'"
            )

            # Test mapping
            mapper = VoiceCommandMapper()
            action_data = mapper.map_command(text)

            if action_data:
                logger.info(f"üéØ Action mapp√©e: {action_data}")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è Commande non reconnue: '{text}'")
                return False
        else:
            logger.error("‚ùå Transcription √©chou√©e")
            return False

    except Exception as e:
        logger.error(f"‚ùå Erreur test Whisper: {e}")
        return False


def main():
    """Point d'entr√©e principal."""
    parser = argparse.ArgumentParser(description="D√©mo Speech-to-Text BBIA")
    parser.add_argument(
        "--backend",
        choices=["mujoco", "reachy"],
        default="mujoco",
        help="Backend robot √† utiliser",
    )
    parser.add_argument(
        "--lang", choices=["fr", "en"], default="fr", help="Langue des commandes"
    )
    parser.add_argument(
        "--command",
        type=str,
        help="Commande vocale √† tester (ex: 'salue', 'regarde-moi')",
    )
    parser.add_argument("--audio-file", type=str, help="Fichier audio √† transcrire")
    parser.add_argument(
        "--test-microphone", action="store_true", help="Test avec microphone (3s)"
    )
    parser.add_argument(
        "--list-commands",
        action="store_true",
        help="Lister toutes les commandes disponibles",
    )

    args = parser.parse_args()

    # Configuration logging
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
    )

    print("üé§ D√©mo Speech-to-Text BBIA")
    print("=" * 40)

    # Test disponibilit√© Whisper
    print(f"Whisper disponible: {WHISPER_AVAILABLE}")

    if args.list_commands:
        print("\nüìã Commandes disponibles:")
        mapper = VoiceCommandMapper()
        for cmd, action in mapper.commands.items():
            print(f"  '{cmd}' ‚Üí {action}")
        return

    if args.test_microphone:
        if not WHISPER_AVAILABLE:
            print("‚ùå Whisper requis pour le test microphone")
            return

        print("üé§ Test microphone (3s)...")
        stt = WhisperSTT(model_size="tiny", language=args.lang)
        text = stt.transcribe_microphone(duration=3.0)

        if text:
            print(f"‚úÖ Transcription: '{text}'")
            # Test action
            success = test_voice_command(text, args.backend)
            print(f"üéØ Action ex√©cut√©e: {'‚úÖ' if success else '‚ùå'}")
        else:
            print("‚ùå Transcription √©chou√©e")

    elif args.audio_file:
        print(f"üéµ Test fichier audio: {args.audio_file}")
        success = test_whisper_transcription(args.audio_file)
        print(f"üéØ Test termin√©: {'‚úÖ' if success else '‚ùå'}")

    elif args.command:
        print(f"üó£Ô∏è Test commande: '{args.command}'")
        success = test_voice_command(args.command, args.backend)
        print(f"üéØ Action ex√©cut√©e: {'‚úÖ' if success else '‚ùå'}")

    else:
        print("‚ùì Aucune action sp√©cifi√©e. Utilisez --help pour voir les options.")
        print("\nExemples:")
        print("  python scripts/stt_demo.py --command 'salue' --backend mujoco")
        print("  python scripts/stt_demo.py --test-microphone --lang fr")
        print("  python scripts/stt_demo.py --list-commands")


if __name__ == "__main__":
    main()
