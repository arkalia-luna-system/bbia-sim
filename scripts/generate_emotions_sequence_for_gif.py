#!/usr/bin/env python3
"""Script pour g√©n√©rer s√©quence d'√©motions pour GIF
Encha√Æne automatiquement : happy (2s) ‚Üí neutral (1s) ‚Üí curious (2s) ‚Üí excited (2s) ‚Üí calm (1s)
Total : 8 secondes, pr√™t pour enregistrement √©cran

Configuration :
- Cam√©ra orient√©e face au robot (azimuth configurable via --azimuth)
- Note : Le fond noir est une limitation de MuJoCo viewer (utiliser post-production pour fond pastel)
"""

import math
import sys
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from bbia_sim.robot_factory import RobotFactory


def emotion_to_pose(
    emotion: str,
    intensity: float,
    step: int,
    total_steps: int,
) -> float:
    """Convertit une √©motion en position d'articulation."""
    t = step / total_steps

    emotion_patterns = {
        # Happy : mouvement √©nergique et joyeux avec variation d'amplitude
        "happy": (
            lambda t: 0.15
            * math.sin(2 * math.pi * 0.12 * t)
            * (1 + 0.6 * math.sin(4 * math.pi * t))
            + 0.03 * math.cos(8 * math.pi * t)
        ),
        # Sad : mouvement lent vers le bas avec oscillation douce
        "sad": (
            lambda t: -0.10 * math.sin(2 * math.pi * 0.25 * t)
            - 0.05 * math.sin(6 * math.pi * t)
            - 0.02 * (1 - math.cos(2 * math.pi * 0.5 * t))
        ),
        # Angry : mouvement rapide et saccad√©
        "angry": (
            lambda t: 0.20 * math.sin(2 * math.pi * 0.9 * t)
            + 0.06 * math.sin(10 * math.pi * t)
            + 0.04 * math.cos(15 * math.pi * t)
        ),
        # Surprised : mouvement brusque avec rebond
        "surprised": (
            lambda t: 0.18
            * math.sin(2 * math.pi * 0.18 * t)
            * math.cos(3 * math.pi * t)
            + 0.05 * math.exp(-5 * (t - 0.5) ** 2)  # Pics de surprise
        ),
        # Neutral : mouvement minimal et r√©gulier
        "neutral": (
            lambda t: 0.06 * math.sin(2 * math.pi * 0.08 * t)
            + 0.02 * math.sin(6 * math.pi * t)
            + 0.01 * math.cos(12 * math.pi * t)
        ),
        # Curious : mouvement exploratoire avec variations
        "curious": (
            lambda t: 0.12
            * math.sin(2 * math.pi * 0.14 * t)
            * (1 + 0.4 * math.sin(3 * math.pi * t))
            + 0.04 * math.sin(7 * math.pi * t) * math.cos(5 * math.pi * t)
        ),
        # Excited : mouvement rapide et dynamique
        "excited": (
            lambda t: 0.18
            * math.sin(2 * math.pi * 0.15 * t)
            * (1 + 0.9 * math.sin(5 * math.pi * t))
            + 0.05 * math.sin(10 * math.pi * t)
            + 0.03 * math.cos(12 * math.pi * t)
        ),
        # Calm : mouvement tr√®s doux et lent
        "calm": (
            lambda t: 0.05 * math.sin(2 * math.pi * 0.06 * t)
            + 0.02 * math.sin(4 * math.pi * t) * math.exp(-0.5 * t)
        ),
    }

    base_movement = emotion_patterns.get(emotion, emotion_patterns["neutral"])(t)
    return base_movement * intensity


def main():
    import argparse

    parser = argparse.ArgumentParser(description="G√©n√®re s√©quence d'√©motions pour GIF")
    parser.add_argument(
        "--azimuth",
        type=float,
        default=180.0,
        help="Angle azimuth cam√©ra (0=droite, 90=face, 180=face optimal, 270=dos). D√©faut: 180",
    )
    args = parser.parse_args()

    # S√©quence d'√©motions avec dur√©es
    sequence = [
        ("happy", 2.0, 0.8),
        ("neutral", 1.0, 0.5),
        ("curious", 2.0, 0.7),
        ("excited", 2.0, 0.9),
        ("calm", 1.0, 0.6),
    ]

    # Cr√©er le robot
    robot = RobotFactory.create_backend("mujoco")
    if not robot or not robot.connect():
        print("‚ùå Impossible de se connecter")
        return 1

    print("‚úÖ Robot connect√©")

    # Acc√©der au mod√®le et donn√©es MuJoCo directement
    if (
        not hasattr(robot, "model")
        or not hasattr(robot, "data")
        or robot.model is None
        or robot.data is None
    ):
        print("‚ùå Impossible d'acc√©der au mod√®le MuJoCo")
        return 1

    # Lancer viewer via le backend du robot
    print("‚úÖ Lancement viewer MuJoCo...")
    if not robot.launch_viewer(passive=True):
        print("‚ùå Impossible de lancer le viewer")
        return 1

    # Acc√©der au viewer IMM√âDIATEMENT et configurer la cam√©ra AVANT le premier affichage
    if not hasattr(robot, "viewer") or robot.viewer is None:
        print("‚ùå Viewer non disponible")
        return 1

    viewer = robot.viewer

    # Configurer cam√©ra IMM√âDIATEMENT (avant le premier sync) pour √©viter la mauvaise premi√®re vue
    # 0¬∞ = c√¥t√© droit, 90¬∞ = face, 180¬∞ = face optimal, 270¬∞ = dos
    viewer.cam.azimuth = args.azimuth
    viewer.cam.elevation = -15.0  # L√©g√®rement au-dessus
    viewer.cam.distance = 1.2  # Rapproch√© de 20% (√©tait 1.5, maintenant 1.2)
    viewer.cam.lookat[:] = [0.0, 0.0, 0.3]

    # Premi√®re synchronisation avec la bonne cam√©ra d√©j√† configur√©e
    viewer.sync()
    time.sleep(0.3)  # Laisser le viewer se stabiliser avec la bonne cam√©ra

    print(f"‚úÖ Cam√©ra configur√©e (azimuth={args.azimuth}¬∞, distance=1.2)")
    print("‚úÖ Fond pastel configur√© dans le mod√®le XML (skybox gradient)")
    print("üí° Si le robot est encore de c√¥t√©, testez: --azimuth 90, 180, 270, ou -90")

    print("\nüé¨ D√âBUT S√âQUENCE (8 secondes)")
    print("üìπ Pr√©parez votre enregistrement d'√©cran maintenant !\n")
    time.sleep(2)  # Temps pour d√©marrer l'enregistrement

    fps = 10
    total_duration = sum(duration for _, duration, _ in sequence)

    print(f"‚è±Ô∏è  Dur√©e totale : {total_duration}s\n")

    step_count = 0
    for emotion, duration, intensity in sequence:
        total_steps = int(duration * fps)
        print(f"üé≠ {emotion.upper()} ({duration}s, intensit√© {intensity})")

        for step in range(total_steps):
            angle = emotion_to_pose(emotion, intensity, step, total_steps)
            robot.set_joint_pos("yaw_body", angle)
            robot.step()

            # Maintenir la configuration de la cam√©ra √† chaque frame
            viewer.cam.azimuth = args.azimuth
            viewer.cam.elevation = -15.0
            viewer.cam.distance = 1.2  # Rapproch√© de 20%
            viewer.cam.lookat[:] = [0.0, 0.0, 0.3]

            # Mettre √† jour la simulation
            viewer.sync()

            step_count += 1
            time.sleep(1.0 / fps)

    print(f"\n‚úÖ S√©quence termin√©e ({total_duration}s)")
    print("‚è∏Ô∏è  Arr√™tez votre enregistrement d'√©cran")
    print("üíæ Puis convertissez la vid√©o en GIF avec ffmpeg")
    print("\nüí° Pour le fond pastel : utilisez un filtre vid√©o (chromakey/fond color√©)")
    time.sleep(2)

    # Fermer proprement le viewer (sans force kill qui peut causer des probl√®mes)
    print("\nüîÑ Fermeture du viewer...")
    try:
        if hasattr(robot, "viewer") and robot.viewer is not None:
            # Fermeture simple et s√ªre
            try:
                if hasattr(robot.viewer, "close"):
                    robot.viewer.close()
                    time.sleep(0.3)  # Laisser le temps de fermer
                    print("‚úÖ Viewer ferm√©")
            except AttributeError:
                # Si le viewer n'a pas de m√©thode close, il se fermera avec le contexte
                pass
            except Exception as e:
                print(f"‚ö†Ô∏è  Viewer d√©j√† ferm√© ou erreur mineure: {e}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Note: {e}")

    # D√©connecter le robot
    try:
        robot.disconnect()
        print("‚úÖ Robot d√©connect√©")
    except Exception as e:
        print(f"‚ö†Ô∏è  Note lors de la d√©connexion: {e}")

    print("\nüí° Si une fen√™tre MuJoCo reste ouverte, fermez-la avec Cmd+Q")

    return 0


if __name__ == "__main__":
    exit(main())
